{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "494af168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoring the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ba4287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014/10/17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006/06/27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000/09/06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990/05/25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014/06/06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014/10/17           OH   \n",
       "1                 228   42         342868       2006/06/27           IN   \n",
       "2                 134   29         687698       2000/09/06           OH   \n",
       "3                 256   41         227811       1990/05/25           IL   \n",
       "4                 228   44         367455       2014/06/06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Boston housing data\n",
    "\n",
    "InsClaims = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\45 season 20-jul-2021\\insurance_claims.csv\", header=0)\n",
    "InsClaims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a146dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variable '_c39'\n",
    "\n",
    "del InsClaims['_c39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c11dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace target variable 'police_report_available', 'Yes' to 1 , 'No' to 0 and '?' to 0 & convert values to integer.\n",
    "\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].str.replace('Y', '1')\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].str.replace('N', '0')\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f25afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2047.59\n",
      "433.33\n"
     ]
    }
   ],
   "source": [
    "# Display the max and min values of policy_annual_premium\n",
    "\n",
    "print(InsClaims.policy_annual_premium.max())\n",
    "print(InsClaims.policy_annual_premium.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "648d59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Display the max and min values of months_as_customer\n",
    "\n",
    "print(InsClaims.months_as_customer.max())\n",
    "print(InsClaims.months_as_customer.min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a127fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range for months_as_customer\n",
    "\n",
    "InsClaims['Range-mac'] = pd.cut(x=InsClaims['months_as_customer'], bins=[-1, 20, 40, 60, 80, 100, 500],\n",
    "labels=['0 to 20', '21 to 40', '41 to 60', '61 to 80', '81 to 100', '101 to 500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6e2457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert th 'policy_state' into integer value\n",
    "\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('OH', '1')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('IN', '2')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('IL', '3')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5b875b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert th 'policy_state' into integer value\n",
    "\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('100/300', '1')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('250/500', '2')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('500/1000', '3')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e2cd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'insured_education_level' into interger\n",
    "\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('High School', '1')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('College', '2')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('Associate', '3')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('JD', '3')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('Masters', '4')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('MD', '4')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('PhD', '5')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8966813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'insured_relationship' into integer\n",
    "\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('own-child', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('other-relative', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('husband', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('wife', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('not-in-family', '2')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('unmarried', '2')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3a14167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'umbrella_limit' variable into numeric\n",
    "\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([-1000000], 1)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([2000000], 2)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([3000000], 3)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([4000000], 4)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([5000000], 5)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([6000000], 6)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([7000000], 7)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([8000000], 8)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([9000000], 9)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([10000000], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa3424fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capital gains ranges\n",
    "\n",
    "InsClaims['CG_Range'] = pd.cut(x=InsClaims['capital-gains'], bins=[-1, 1, 10000, 20000, 30000, 40000, 50000,\n",
    "75000, 105000],\n",
    "labels=['0', '< 10K', '10K TO 20K', '20K TO 30K', '30K TO 40K', '40K TO 50K',\n",
    "'50K TO 75K', '> 75K' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0c38362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capital gains ranges\n",
    "\n",
    "InsClaims['CL_Range'] = pd.cut(x=InsClaims['capital-loss'], bins=[-115000, -75000, -50000, -40000,\n",
    "-30000, -20000, -10000, -1, 1],\n",
    "labels=['> -75K', '-50K TO -75K', '-40K TO -50K', '-30K TO -40K',\n",
    "'-20K TO -30K', '-10K TO -20K', '< -10K', '0'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efe2cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'incident_type' to intergers\n",
    "\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Parked Car', '1')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Single Vehicle Collision', '2')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Multi-vehicle Collision', '3')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Vehicle Theft', '4')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].astype(int)\n",
    "\n",
    "# Convert the 'collision_type' to intergers\n",
    "\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Rear Collision', '1')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('?', '1')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Side Collision', '2')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Front Collision', '3')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf855613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'incident_severity' to intergers\n",
    "\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Minor Damage', '1')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Trivial Damage', '2')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Major Damage', '3')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Total Loss', '4')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f24171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'authorities_contacted' to intergers\n",
    "\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Police', '1')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Fire', '2')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Ambulance', '3')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Other', '4')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('None', '4')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6b30d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'incident_hour_of_the_day' into ranges\n",
    "\n",
    "InsClaims['Incident_Hour_Range'] = pd.cut(x=InsClaims['incident_hour_of_the_day'], bins=[-1, 4, 8, 12, 16, 20, 24],\n",
    "labels=['12:00 AM to 04:00 AM', '04:00 AM to 08:00 AM', '08:00 AM to 12:00 PM',\n",
    "'12:00 PM to 04:00 PM', '04:00 PM to 08:00 PM', '08:00 PM to 12:00 AM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "048d2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'property_damage' into integers\n",
    "\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('NO', '0')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('YES', '1')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('?', '1')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fba451e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'police_report_available' into integers\n",
    "\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('NO', '2')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('YES', '1')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('?', '2')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca8e1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to new file which will used for classification analysis\n",
    "\n",
    "InsClaimsF1 = InsClaims.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d451e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables which are impacting the target variable\n",
    "\n",
    "InsClaimsF1 = InsClaimsF1.drop(['policy_number', 'months_as_customer', 'policy_bind_date', 'insured_zip',\n",
    "'insured_occupation', 'insured_hobbies', 'capital-gains', 'capital-loss',\n",
    "'incident_date', 'incident_state', 'incident_city', 'incident_location',\n",
    "'incident_hour_of_the_day', 'auto_make', 'auto_model', 'auto_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e3189f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_state</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_csl</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <td>1406.91</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>1583.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_damage</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodily_injuries</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>71610.00</td>\n",
       "      <td>5070.00</td>\n",
       "      <td>34650.00</td>\n",
       "      <td>63400.00</td>\n",
       "      <td>6500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injury_claim</th>\n",
       "      <td>6510.00</td>\n",
       "      <td>780.00</td>\n",
       "      <td>7700.00</td>\n",
       "      <td>6340.00</td>\n",
       "      <td>1300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_claim</th>\n",
       "      <td>13020.00</td>\n",
       "      <td>780.00</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>6340.00</td>\n",
       "      <td>650.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_claim</th>\n",
       "      <td>52080.00</td>\n",
       "      <td>3510.00</td>\n",
       "      <td>23100.00</td>\n",
       "      <td>50720.00</td>\n",
       "      <td>4550.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_0 to 20</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_21 to 40</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_41 to 60</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_61 to 80</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_81 to 100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_101 to 500</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_&lt; 10K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_10K TO 20K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_20K TO 30K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_30K TO 40K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_40K TO 50K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_50K TO 75K</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_&gt; 75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_&gt; -75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-50K TO -75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-40K TO -50K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-30K TO -40K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-20K TO -30K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-10K TO -20K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_&lt; -10K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_12:00 AM to 04:00 AM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_04:00 AM to 08:00 AM</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_08:00 AM to 12:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_12:00 PM to 04:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_04:00 PM to 08:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_08:00 PM to 12:00 AM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_FEMALE</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_MALE</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0        1         2  \\\n",
       "age                                          48.00    42.00     29.00   \n",
       "policy_state                                  1.00     2.00      1.00   \n",
       "policy_csl                                    2.00     2.00      1.00   \n",
       "policy_deductable                          1000.00  2000.00   2000.00   \n",
       "policy_annual_premium                      1406.91  1197.22   1413.14   \n",
       "umbrella_limit                                0.00     5.00      5.00   \n",
       "insured_education_level                       4.00     4.00      5.00   \n",
       "insured_relationship                          1.00     1.00      1.00   \n",
       "incident_type                                 2.00     4.00      3.00   \n",
       "collision_type                                2.00     1.00      1.00   \n",
       "incident_severity                             3.00     1.00      1.00   \n",
       "authorities_contacted                         1.00     1.00      1.00   \n",
       "number_of_vehicles_involved                   1.00     1.00      3.00   \n",
       "property_damage                               1.00     1.00      0.00   \n",
       "bodily_injuries                               1.00     0.00      2.00   \n",
       "witnesses                                     2.00     0.00      3.00   \n",
       "police_report_available                       1.00     2.00      2.00   \n",
       "total_claim_amount                        71610.00  5070.00  34650.00   \n",
       "injury_claim                               6510.00   780.00   7700.00   \n",
       "property_claim                            13020.00   780.00   3850.00   \n",
       "vehicle_claim                             52080.00  3510.00  23100.00   \n",
       "fraud_reported                                1.00     1.00      0.00   \n",
       "Range-mac_0 to 20                             0.00     0.00      0.00   \n",
       "Range-mac_21 to 40                            0.00     0.00      0.00   \n",
       "Range-mac_41 to 60                            0.00     0.00      0.00   \n",
       "Range-mac_61 to 80                            0.00     0.00      0.00   \n",
       "Range-mac_81 to 100                           0.00     0.00      0.00   \n",
       "Range-mac_101 to 500                          1.00     1.00      1.00   \n",
       "CG_Range_0                                    0.00     1.00      0.00   \n",
       "CG_Range_< 10K                                0.00     0.00      0.00   \n",
       "CG_Range_10K TO 20K                           0.00     0.00      0.00   \n",
       "CG_Range_20K TO 30K                           0.00     0.00      0.00   \n",
       "CG_Range_30K TO 40K                           0.00     0.00      1.00   \n",
       "CG_Range_40K TO 50K                           0.00     0.00      0.00   \n",
       "CG_Range_50K TO 75K                           1.00     0.00      0.00   \n",
       "CG_Range_> 75K                                0.00     0.00      0.00   \n",
       "CL_Range_> -75K                               0.00     0.00      0.00   \n",
       "CL_Range_-50K TO -75K                         0.00     0.00      0.00   \n",
       "CL_Range_-40K TO -50K                         0.00     0.00      0.00   \n",
       "CL_Range_-30K TO -40K                         0.00     0.00      0.00   \n",
       "CL_Range_-20K TO -30K                         0.00     0.00      0.00   \n",
       "CL_Range_-10K TO -20K                         0.00     0.00      0.00   \n",
       "CL_Range_< -10K                               0.00     0.00      0.00   \n",
       "CL_Range_0                                    1.00     1.00      1.00   \n",
       "Incident_Hour_Range_12:00 AM to 04:00 AM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_04:00 AM to 08:00 AM      1.00     1.00      1.00   \n",
       "Incident_Hour_Range_08:00 AM to 12:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_12:00 PM to 04:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_04:00 PM to 08:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_08:00 PM to 12:00 AM      0.00     0.00      0.00   \n",
       "insured_sex_FEMALE                            0.00     0.00      1.00   \n",
       "insured_sex_MALE                              1.00     1.00      0.00   \n",
       "\n",
       "                                                 3        4  \n",
       "age                                          41.00    44.00  \n",
       "policy_state                                  3.00     3.00  \n",
       "policy_csl                                    2.00     3.00  \n",
       "policy_deductable                          2000.00  1000.00  \n",
       "policy_annual_premium                      1415.74  1583.91  \n",
       "umbrella_limit                                6.00     6.00  \n",
       "insured_education_level                       5.00     3.00  \n",
       "insured_relationship                          2.00     2.00  \n",
       "incident_type                                 2.00     4.00  \n",
       "collision_type                                3.00     1.00  \n",
       "incident_severity                             3.00     1.00  \n",
       "authorities_contacted                         1.00     4.00  \n",
       "number_of_vehicles_involved                   1.00     1.00  \n",
       "property_damage                               1.00     0.00  \n",
       "bodily_injuries                               1.00     0.00  \n",
       "witnesses                                     2.00     1.00  \n",
       "police_report_available                       2.00     2.00  \n",
       "total_claim_amount                        63400.00  6500.00  \n",
       "injury_claim                               6340.00  1300.00  \n",
       "property_claim                             6340.00   650.00  \n",
       "vehicle_claim                             50720.00  4550.00  \n",
       "fraud_reported                                1.00     0.00  \n",
       "Range-mac_0 to 20                             0.00     0.00  \n",
       "Range-mac_21 to 40                            0.00     0.00  \n",
       "Range-mac_41 to 60                            0.00     0.00  \n",
       "Range-mac_61 to 80                            0.00     0.00  \n",
       "Range-mac_81 to 100                           0.00     0.00  \n",
       "Range-mac_101 to 500                          1.00     1.00  \n",
       "CG_Range_0                                    0.00     0.00  \n",
       "CG_Range_< 10K                                0.00     0.00  \n",
       "CG_Range_10K TO 20K                           0.00     0.00  \n",
       "CG_Range_20K TO 30K                           0.00     0.00  \n",
       "CG_Range_30K TO 40K                           0.00     0.00  \n",
       "CG_Range_40K TO 50K                           1.00     0.00  \n",
       "CG_Range_50K TO 75K                           0.00     1.00  \n",
       "CG_Range_> 75K                                0.00     0.00  \n",
       "CL_Range_> -75K                               0.00     0.00  \n",
       "CL_Range_-50K TO -75K                         1.00     0.00  \n",
       "CL_Range_-40K TO -50K                         0.00     1.00  \n",
       "CL_Range_-30K TO -40K                         0.00     0.00  \n",
       "CL_Range_-20K TO -30K                         0.00     0.00  \n",
       "CL_Range_-10K TO -20K                         0.00     0.00  \n",
       "CL_Range_< -10K                               0.00     0.00  \n",
       "CL_Range_0                                    0.00     0.00  \n",
       "Incident_Hour_Range_12:00 AM to 04:00 AM      0.00     0.00  \n",
       "Incident_Hour_Range_04:00 AM to 08:00 AM      1.00     0.00  \n",
       "Incident_Hour_Range_08:00 AM to 12:00 PM      0.00     0.00  \n",
       "Incident_Hour_Range_12:00 PM to 04:00 PM      0.00     0.00  \n",
       "Incident_Hour_Range_04:00 PM to 08:00 PM      0.00     1.00  \n",
       "Incident_Hour_Range_08:00 PM to 12:00 AM      0.00     0.00  \n",
       "insured_sex_FEMALE                            1.00     0.00  \n",
       "insured_sex_MALE                              0.00     1.00  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for all range values\n",
    "\n",
    "InsClaimsF1 = pd.get_dummies(InsClaimsF1, columns=['Range-mac', 'CG_Range', 'CL_Range',\n",
    "'Incident_Hour_Range', 'insured_sex'])\n",
    "InsClaimsF1.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a085d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in InsClaimsF1.columns:\n",
    "    if col != 'fraud_reported':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'fraud_reported'\n",
    "\n",
    "x = InsClaimsF1[IndepVar]\n",
    "y = InsClaimsF1[TargetVar]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5871e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 6)\n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f7b29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Conver x_train values\n",
    "\n",
    "x_train['age'] = sc.fit_transform(x_train['age'].values.reshape(-1, 1))\n",
    "x_train['policy_annual_premium'] = sc.fit_transform(x_train['policy_annual_premium'].values.reshape(-1, 1))\n",
    "x_train['total_claim_amount'] = sc.fit_transform(x_train['total_claim_amount'].values.reshape(-1, 1))\n",
    "x_train['injury_claim'] = sc.fit_transform(x_train['injury_claim'].values.reshape(-1, 1))\n",
    "x_train['property_claim'] = sc.fit_transform(x_train['property_claim'].values.reshape(-1, 1))\n",
    "x_train['vehicle_claim'] = sc.fit_transform(x_train['vehicle_claim'].values.reshape(-1, 1))\n",
    "\n",
    "# Conver x_test values\n",
    "\n",
    "x_test['age'] = sc.fit_transform(x_test['age'].values.reshape(-1, 1))\n",
    "x_test['policy_annual_premium'] = sc.fit_transform(x_test['policy_annual_premium'].values.reshape(-1, 1))\n",
    "x_test['total_claim_amount'] = sc.fit_transform(x_test['total_claim_amount'].values.reshape(-1, 1))\n",
    "x_test['injury_claim'] = sc.fit_transform(x_test['injury_claim'].values.reshape(-1, 1))\n",
    "x_test['property_claim'] = sc.fit_transform(x_test['property_claim'].values.reshape(-1, 1))\n",
    "x_test['vehicle_claim'] = sc.fit_transform(x_test['vehicle_claim'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert to dataframes\n",
    "\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed84353",
   "metadata": {},
   "source": [
    "# Random Forest without LDA/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb3910d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   0]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.66       300\n",
      "\n",
      "Accuracy: 76.0 %\n",
      "Precision: 76.0 %\n",
      "Recall: 76.0 %\n",
      "f1-score: 76.0 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                criterion='entropy', max_depth=2, max_features='auto',\n",
    "                                max_leaf_nodes=None, max_samples=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,\n",
    "                                min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                                n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelRF.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y1_pred))\n",
    "print(classification_report(y_test, y1_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y1_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a7633",
   "metadata": {},
   "source": [
    "# Decision Tree without LDA/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeca97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186  42]\n",
      " [ 41  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       228\n",
      "           1       0.42      0.43      0.43        72\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.62      0.62      0.62       300\n",
      "weighted avg       0.72      0.72      0.72       300\n",
      "\n",
      "Accuracy: 72.33 %\n",
      "Precision: 42.47 %\n",
      "Recall: 43.06 %\n",
      "f1-score: 42.76 %\n",
      "roc_auc_score: 0.623\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y2_pred = modelDT.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y2_pred))\n",
    "print(classification_report(y_test, y2_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3e77c",
   "metadata": {},
   "source": [
    "# Logistic Regression without LDA/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c98fe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[217  11]\n",
      " [ 70   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       228\n",
      "           1       0.15      0.03      0.05        72\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.45      0.49      0.44       300\n",
      "weighted avg       0.61      0.73      0.65       300\n",
      "\n",
      "Accuracy: 73.0 %\n",
      "Precision: 73.0 %\n",
      "Recall: 73.0 %\n",
      "f1-score: 73.0 %\n",
      "roc_auc_score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y3_pred))\n",
    "print(classification_report(y_test, y3_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y3_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y3_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f2ebb7",
   "metadata": {},
   "source": [
    "# SVM - Gaussian without LDA/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad3f4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   0]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.66       300\n",
      "\n",
      "Accuracy: 76.0 %\n",
      "Precision: 76.0 %\n",
      "Recall: 76.0 %\n",
      "f1-score: 76.0 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, \n",
    "                          tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, \n",
    "                          decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y4_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y4_pred))\n",
    "print(classification_report(y_test,y4_pred))\n",
    "\n",
    "# Evalution metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y4_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y4_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b640",
   "metadata": {},
   "source": [
    "# Appling PCA to all 5 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bc37bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99933893e-01 1.42918479e-05 9.66717712e-06 4.20294432e-06\n",
      " 3.91395381e-06 3.69419067e-06 3.23001691e-06 3.12195255e-06\n",
      " 2.76507673e-06 2.57753268e-06 1.90156998e-06 1.77888007e-06\n",
      " 1.64639768e-06 1.47946731e-06 1.28697259e-06 1.17180331e-06\n",
      " 8.70611864e-07 8.46752708e-07 8.07834582e-07 6.49108087e-07\n",
      " 5.97970144e-07 5.51424916e-07 5.39476523e-07 5.16052045e-07\n",
      " 4.51725292e-07 4.21046423e-07 4.12879521e-07 3.84596179e-07\n",
      " 3.63822635e-07 3.39180272e-07 3.01374769e-07 2.61512274e-07\n",
      " 2.11885891e-07 1.32663943e-07 1.26286156e-07 1.04269069e-07\n",
      " 9.95637795e-08 9.32069326e-08 8.27998760e-08 7.29010915e-08\n",
      " 6.44487095e-08 2.85685545e-08 2.50238000e-08 1.21647472e-08\n",
      " 7.93970109e-09 9.96407041e-33 9.96407041e-33 9.96407041e-33\n",
      " 9.96407041e-33 9.96407041e-33 9.96407041e-33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "applyPCA = PCA()\n",
    "\n",
    "x_train = applyPCA.fit_transform(x_train)\n",
    "x_test = applyPCA.transform(x_test)\n",
    "explained_variance = applyPCA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50544510",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb91b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   0]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.66       300\n",
      "\n",
      "Accuracy: 76.0 %\n",
      "Precision: 76.0 %\n",
      "Recall: 76.0 %\n",
      "f1-score: 76.0 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                criterion='entropy', max_depth=2, max_features='auto',\n",
    "                                max_leaf_nodes=None, max_samples=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,\n",
    "                                min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                                n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelRF.predict(x_test)\n",
    "-\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y1_pred))\n",
    "print(classification_report(y_test, y1_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y1_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca99503",
   "metadata": {},
   "source": [
    "# Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d1b6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[171  57]\n",
      " [ 40  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       228\n",
      "           1       0.36      0.44      0.40        72\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.58      0.60      0.59       300\n",
      "weighted avg       0.70      0.68      0.69       300\n",
      "\n",
      "Accuracy: 67.67 %\n",
      "Precision: 35.96 %\n",
      "Recall: 44.44 %\n",
      "f1-score: 39.75 %\n",
      "roc_auc_score: 0.597\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y2_pred = modelDT.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y2_pred))\n",
    "print(classification_report(y_test, y2_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f254e4e",
   "metadata": {},
   "source": [
    "# Logistic Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d1cab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[219   9]\n",
      " [ 69   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       228\n",
      "           1       0.25      0.04      0.07        72\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.51      0.50      0.46       300\n",
      "weighted avg       0.64      0.74      0.66       300\n",
      "\n",
      "Accuracy: 74.0 %\n",
      "Precision: 74.0 %\n",
      "Recall: 74.0 %\n",
      "f1-score: 74.0 %\n",
      "roc_auc_score: 0.501\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y3_pred))\n",
    "print(classification_report(y_test, y3_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y3_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y3_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3c3e6",
   "metadata": {},
   "source": [
    "# SVM Gaussian with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "262156be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   0]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.66       300\n",
      "\n",
      "Accuracy: 76.0 %\n",
      "Precision: 76.0 %\n",
      "Recall: 76.0 %\n",
      "f1-score: 76.0 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, \n",
    "                          tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, \n",
    "                          decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y4_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y4_pred))\n",
    "print(classification_report(y_test,y4_pred))\n",
    "\n",
    "# Evalution metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y4_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y4_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7744b04",
   "metadata": {},
   "source": [
    "# Appling all LCA algorithm with all 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "852acc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# Random forest with 'Linear Discriminant Analysis' technique to reduce the dimentionality\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "applyLDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "x_train = applyLDA.fit_transform(x_train, y_train)\n",
    "x_test = applyLDA.transform(x_test)\n",
    "\n",
    "explained_variance = applyLDA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806af118",
   "metadata": {},
   "source": [
    "# Random Forest with LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c536517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227   1]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.65       300\n",
      "\n",
      "Accuracy: 75.67 %\n",
      "Precision: 75.67 %\n",
      "Recall: 75.67 %\n",
      "f1-score: 75.67 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                criterion='entropy', max_depth=2, max_features='auto',\n",
    "                                max_leaf_nodes=None, max_samples=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,\n",
    "                                min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                                n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelRF.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y1_pred))\n",
    "print(classification_report(y_test, y1_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y1_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7ebda",
   "metadata": {},
   "source": [
    "# Decision Tree with LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ed8b77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  48]\n",
      " [ 54  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       228\n",
      "           1       0.27      0.25      0.26        72\n",
      "\n",
      "    accuracy                           0.66       300\n",
      "   macro avg       0.52      0.52      0.52       300\n",
      "weighted avg       0.65      0.66      0.65       300\n",
      "\n",
      "Accuracy: 66.0 %\n",
      "Precision: 27.27 %\n",
      "Recall: 25.0 %\n",
      "f1-score: 26.09 %\n",
      "roc_auc_score: 0.52\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y2_pred = modelDT.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y2_pred))\n",
    "print(classification_report(y_test, y2_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y2_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b29e6",
   "metadata": {},
   "source": [
    "# Logistic Regression with LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e854e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216  12]\n",
      " [ 69   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       228\n",
      "           1       0.20      0.04      0.07        72\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.48      0.49      0.46       300\n",
      "weighted avg       0.62      0.73      0.66       300\n",
      "\n",
      "Accuracy: 73.0 %\n",
      "Precision: 73.0 %\n",
      "Recall: 73.0 %\n",
      "f1-score: 73.0 %\n",
      "roc_auc_score: 0.495\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y3_pred))\n",
    "print(classification_report(y_test, y3_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y3_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y3_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y3_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd450fe",
   "metadata": {},
   "source": [
    "# SVM Gaussian with LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "324d58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227   1]\n",
      " [ 72   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       228\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.38      0.50      0.43       300\n",
      "weighted avg       0.58      0.76      0.65       300\n",
      "\n",
      "Accuracy: 75.67 %\n",
      "Precision: 75.67 %\n",
      "Recall: 75.67 %\n",
      "f1-score: 75.67 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, \n",
    "                          tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, \n",
    "                          decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y4_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y4_pred))\n",
    "print(classification_report(y_test,y4_pred))\n",
    "\n",
    "# Evalution metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y4_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y4_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e901e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f96607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85f891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257332c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
