{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8b4226",
   "metadata": {},
   "source": [
    "# insurance_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dead72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoring the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b333759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014/10/17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006/06/27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000/09/06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990/05/25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014/06/06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014/10/17           OH   \n",
       "1                 228   42         342868       2006/06/27           IN   \n",
       "2                 134   29         687698       2000/09/06           OH   \n",
       "3                 256   41         227811       1990/05/25           IL   \n",
       "4                 228   44         367455       2014/06/06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the Boston housing data\n",
    "\n",
    "InsClaims = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\45 season 20-jul-2021\\insurance_claims.csv\", header=0)\n",
    "InsClaims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc179717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the variable '_c39'\n",
    "\n",
    "del InsClaims['_c39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ad4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace target variable 'police_report_available', 'Yes' to 1 , 'No' to 0 and '?' to 0 & convert values to integer.\n",
    "\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].str.replace('Y', '1')\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].str.replace('N', '0')\n",
    "InsClaims['fraud_reported'] = InsClaims['fraud_reported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e7a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2047.59\n",
      "433.33\n"
     ]
    }
   ],
   "source": [
    "# Display the max and min values of policy_annual_premium\n",
    "\n",
    "print(InsClaims.policy_annual_premium.max())\n",
    "print(InsClaims.policy_annual_premium.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807f3a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Display the max and min values of months_as_customer\n",
    "\n",
    "print(InsClaims.months_as_customer.max())\n",
    "print(InsClaims.months_as_customer.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd23cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range for months_as_customer\n",
    "\n",
    "InsClaims['Range-mac'] = pd.cut(x=InsClaims['months_as_customer'], bins=[-1, 20, 40, 60, 80, 100, 500],\n",
    "labels=['0 to 20', '21 to 40', '41 to 60', '61 to 80', '81 to 100', '101 to 500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b352a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert th 'policy_state' into integer value\n",
    "\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('OH', '1')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('IN', '2')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].str.replace('IL', '3')\n",
    "InsClaims['policy_state'] = InsClaims['policy_state'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ace389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert th 'policy_state' into integer value\n",
    "\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('100/300', '1')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('250/500', '2')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].str.replace('500/1000', '3')\n",
    "InsClaims['policy_csl'] = InsClaims['policy_csl'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d01e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'insured_education_level' into interger\n",
    "\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('High School', '1')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('College', '2')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('Associate', '3')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('JD', '3')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('Masters', '4')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('MD', '4')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].str.replace('PhD', '5')\n",
    "InsClaims['insured_education_level'] = InsClaims['insured_education_level'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993d39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'insured_relationship' into integer\n",
    "\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('own-child', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('other-relative', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('husband', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('wife', '1')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('not-in-family', '2')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].str.replace('unmarried', '2')\n",
    "InsClaims['insured_relationship'] = InsClaims['insured_relationship'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055ba202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'umbrella_limit' variable into numeric\n",
    "\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([-1000000], 1)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([2000000], 2)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([3000000], 3)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([4000000], 4)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([5000000], 5)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([6000000], 6)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([7000000], 7)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([8000000], 8)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([9000000], 9)\n",
    "InsClaims['umbrella_limit'] = InsClaims['umbrella_limit'].replace([10000000], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95549e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capital gains ranges\n",
    "\n",
    "InsClaims['CG_Range'] = pd.cut(x=InsClaims['capital-gains'], bins=[-1, 1, 10000, 20000, 30000, 40000, 50000,\n",
    "75000, 105000],\n",
    "labels=['0', '< 10K', '10K TO 20K', '20K TO 30K', '30K TO 40K', '40K TO 50K',\n",
    "'50K TO 75K', '> 75K' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28697aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create capital gains ranges\n",
    "\n",
    "InsClaims['CL_Range'] = pd.cut(x=InsClaims['capital-loss'], bins=[-115000, -75000, -50000, -40000,\n",
    "-30000, -20000, -10000, -1, 1],\n",
    "labels=['> -75K', '-50K TO -75K', '-40K TO -50K', '-30K TO -40K',\n",
    "'-20K TO -30K', '-10K TO -20K', '< -10K', '0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "766046e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'incident_type' to intergers\n",
    "\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Parked Car', '1')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Single Vehicle Collision', '2')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Multi-vehicle Collision', '3')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].str.replace('Vehicle Theft', '4')\n",
    "InsClaims['incident_type'] = InsClaims['incident_type'].astype(int)\n",
    "\n",
    "# Convert the 'collision_type' to intergers\n",
    "\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Rear Collision', '1')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('?', '1')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Side Collision', '2')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].str.replace('Front Collision', '3')\n",
    "InsClaims['collision_type'] = InsClaims['collision_type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3774e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'incident_severity' to intergers\n",
    "\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Minor Damage', '1')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Trivial Damage', '2')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Major Damage', '3')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].str.replace('Total Loss', '4')\n",
    "InsClaims['incident_severity'] = InsClaims['incident_severity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35bb633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'authorities_contacted' to intergers\n",
    "\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Police', '1')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Fire', '2')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Ambulance', '3')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('Other', '4')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].str.replace('None', '4')\n",
    "InsClaims['authorities_contacted'] = InsClaims['authorities_contacted'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facb2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'incident_hour_of_the_day' into ranges\n",
    "\n",
    "InsClaims['Incident_Hour_Range'] = pd.cut(x=InsClaims['incident_hour_of_the_day'], bins=[-1, 4, 8, 12, 16, 20, 24],\n",
    "labels=['12:00 AM to 04:00 AM', '04:00 AM to 08:00 AM', '08:00 AM to 12:00 PM',\n",
    "'12:00 PM to 04:00 PM', '04:00 PM to 08:00 PM', '08:00 PM to 12:00 AM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "007a68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'property_damage' into integers\n",
    "\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('NO', '0')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('YES', '1')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].str.replace('?', '1')\n",
    "InsClaims['property_damage'] = InsClaims['property_damage'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7e855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'police_report_available' into integers\n",
    "\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('NO', '2')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('YES', '1')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].str.replace('?', '2')\n",
    "InsClaims['police_report_available'] = InsClaims['police_report_available'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86bb70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to new file which will used for classification analysis\n",
    "\n",
    "InsClaimsF1 = InsClaims.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6febe0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables which are impacting the target variable\n",
    "\n",
    "InsClaimsF1 = InsClaimsF1.drop(['policy_number', 'months_as_customer', 'policy_bind_date', 'insured_zip',\n",
    "'insured_occupation', 'insured_hobbies', 'capital-gains', 'capital-loss',\n",
    "'incident_date', 'incident_state', 'incident_city', 'incident_location',\n",
    "'incident_hour_of_the_day', 'auto_make', 'auto_model', 'auto_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaf7dafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>44.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_state</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_csl</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <td>1406.91</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>1583.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_education_level</th>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_relationship</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_type</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_type</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_severity</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authorities_contacted</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_damage</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodily_injuries</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police_report_available</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>71610.00</td>\n",
       "      <td>5070.00</td>\n",
       "      <td>34650.00</td>\n",
       "      <td>63400.00</td>\n",
       "      <td>6500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>injury_claim</th>\n",
       "      <td>6510.00</td>\n",
       "      <td>780.00</td>\n",
       "      <td>7700.00</td>\n",
       "      <td>6340.00</td>\n",
       "      <td>1300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_claim</th>\n",
       "      <td>13020.00</td>\n",
       "      <td>780.00</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>6340.00</td>\n",
       "      <td>650.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_claim</th>\n",
       "      <td>52080.00</td>\n",
       "      <td>3510.00</td>\n",
       "      <td>23100.00</td>\n",
       "      <td>50720.00</td>\n",
       "      <td>4550.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_0 to 20</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_21 to 40</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_41 to 60</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_61 to 80</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_81 to 100</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Range-mac_101 to 500</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_&lt; 10K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_10K TO 20K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_20K TO 30K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_30K TO 40K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_40K TO 50K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_50K TO 75K</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG_Range_&gt; 75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_&gt; -75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-50K TO -75K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-40K TO -50K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-30K TO -40K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-20K TO -30K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_-10K TO -20K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_&lt; -10K</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL_Range_0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_12:00 AM to 04:00 AM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_04:00 AM to 08:00 AM</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_08:00 AM to 12:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_12:00 PM to 04:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_04:00 PM to 08:00 PM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incident_Hour_Range_08:00 PM to 12:00 AM</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_FEMALE</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insured_sex_MALE</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0        1         2  \\\n",
       "age                                          48.00    42.00     29.00   \n",
       "policy_state                                  1.00     2.00      1.00   \n",
       "policy_csl                                    2.00     2.00      1.00   \n",
       "policy_deductable                          1000.00  2000.00   2000.00   \n",
       "policy_annual_premium                      1406.91  1197.22   1413.14   \n",
       "umbrella_limit                                0.00     5.00      5.00   \n",
       "insured_education_level                       4.00     4.00      5.00   \n",
       "insured_relationship                          1.00     1.00      1.00   \n",
       "incident_type                                 2.00     4.00      3.00   \n",
       "collision_type                                2.00     1.00      1.00   \n",
       "incident_severity                             3.00     1.00      1.00   \n",
       "authorities_contacted                         1.00     1.00      1.00   \n",
       "number_of_vehicles_involved                   1.00     1.00      3.00   \n",
       "property_damage                               1.00     1.00      0.00   \n",
       "bodily_injuries                               1.00     0.00      2.00   \n",
       "witnesses                                     2.00     0.00      3.00   \n",
       "police_report_available                       1.00     2.00      2.00   \n",
       "total_claim_amount                        71610.00  5070.00  34650.00   \n",
       "injury_claim                               6510.00   780.00   7700.00   \n",
       "property_claim                            13020.00   780.00   3850.00   \n",
       "vehicle_claim                             52080.00  3510.00  23100.00   \n",
       "fraud_reported                                1.00     1.00      0.00   \n",
       "Range-mac_0 to 20                             0.00     0.00      0.00   \n",
       "Range-mac_21 to 40                            0.00     0.00      0.00   \n",
       "Range-mac_41 to 60                            0.00     0.00      0.00   \n",
       "Range-mac_61 to 80                            0.00     0.00      0.00   \n",
       "Range-mac_81 to 100                           0.00     0.00      0.00   \n",
       "Range-mac_101 to 500                          1.00     1.00      1.00   \n",
       "CG_Range_0                                    0.00     1.00      0.00   \n",
       "CG_Range_< 10K                                0.00     0.00      0.00   \n",
       "CG_Range_10K TO 20K                           0.00     0.00      0.00   \n",
       "CG_Range_20K TO 30K                           0.00     0.00      0.00   \n",
       "CG_Range_30K TO 40K                           0.00     0.00      1.00   \n",
       "CG_Range_40K TO 50K                           0.00     0.00      0.00   \n",
       "CG_Range_50K TO 75K                           1.00     0.00      0.00   \n",
       "CG_Range_> 75K                                0.00     0.00      0.00   \n",
       "CL_Range_> -75K                               0.00     0.00      0.00   \n",
       "CL_Range_-50K TO -75K                         0.00     0.00      0.00   \n",
       "CL_Range_-40K TO -50K                         0.00     0.00      0.00   \n",
       "CL_Range_-30K TO -40K                         0.00     0.00      0.00   \n",
       "CL_Range_-20K TO -30K                         0.00     0.00      0.00   \n",
       "CL_Range_-10K TO -20K                         0.00     0.00      0.00   \n",
       "CL_Range_< -10K                               0.00     0.00      0.00   \n",
       "CL_Range_0                                    1.00     1.00      1.00   \n",
       "Incident_Hour_Range_12:00 AM to 04:00 AM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_04:00 AM to 08:00 AM      1.00     1.00      1.00   \n",
       "Incident_Hour_Range_08:00 AM to 12:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_12:00 PM to 04:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_04:00 PM to 08:00 PM      0.00     0.00      0.00   \n",
       "Incident_Hour_Range_08:00 PM to 12:00 AM      0.00     0.00      0.00   \n",
       "insured_sex_FEMALE                            0.00     0.00      1.00   \n",
       "insured_sex_MALE                              1.00     1.00      0.00   \n",
       "\n",
       "                                                 3        4  \n",
       "age                                          41.00    44.00  \n",
       "policy_state                                  3.00     3.00  \n",
       "policy_csl                                    2.00     3.00  \n",
       "policy_deductable                          2000.00  1000.00  \n",
       "policy_annual_premium                      1415.74  1583.91  \n",
       "umbrella_limit                                6.00     6.00  \n",
       "insured_education_level                       5.00     3.00  \n",
       "insured_relationship                          2.00     2.00  \n",
       "incident_type                                 2.00     4.00  \n",
       "collision_type                                3.00     1.00  \n",
       "incident_severity                             3.00     1.00  \n",
       "authorities_contacted                         1.00     4.00  \n",
       "number_of_vehicles_involved                   1.00     1.00  \n",
       "property_damage                               1.00     0.00  \n",
       "bodily_injuries                               1.00     0.00  \n",
       "witnesses                                     2.00     1.00  \n",
       "police_report_available                       2.00     2.00  \n",
       "total_claim_amount                        63400.00  6500.00  \n",
       "injury_claim                               6340.00  1300.00  \n",
       "property_claim                             6340.00   650.00  \n",
       "vehicle_claim                             50720.00  4550.00  \n",
       "fraud_reported                                1.00     0.00  \n",
       "Range-mac_0 to 20                             0.00     0.00  \n",
       "Range-mac_21 to 40                            0.00     0.00  \n",
       "Range-mac_41 to 60                            0.00     0.00  \n",
       "Range-mac_61 to 80                            0.00     0.00  \n",
       "Range-mac_81 to 100                           0.00     0.00  \n",
       "Range-mac_101 to 500                          1.00     1.00  \n",
       "CG_Range_0                                    0.00     0.00  \n",
       "CG_Range_< 10K                                0.00     0.00  \n",
       "CG_Range_10K TO 20K                           0.00     0.00  \n",
       "CG_Range_20K TO 30K                           0.00     0.00  \n",
       "CG_Range_30K TO 40K                           0.00     0.00  \n",
       "CG_Range_40K TO 50K                           1.00     0.00  \n",
       "CG_Range_50K TO 75K                           0.00     1.00  \n",
       "CG_Range_> 75K                                0.00     0.00  \n",
       "CL_Range_> -75K                               0.00     0.00  \n",
       "CL_Range_-50K TO -75K                         1.00     0.00  \n",
       "CL_Range_-40K TO -50K                         0.00     1.00  \n",
       "CL_Range_-30K TO -40K                         0.00     0.00  \n",
       "CL_Range_-20K TO -30K                         0.00     0.00  \n",
       "CL_Range_-10K TO -20K                         0.00     0.00  \n",
       "CL_Range_< -10K                               0.00     0.00  \n",
       "CL_Range_0                                    0.00     0.00  \n",
       "Incident_Hour_Range_12:00 AM to 04:00 AM      0.00     0.00  \n",
       "Incident_Hour_Range_04:00 AM to 08:00 AM      1.00     0.00  \n",
       "Incident_Hour_Range_08:00 AM to 12:00 PM      0.00     0.00  \n",
       "Incident_Hour_Range_12:00 PM to 04:00 PM      0.00     0.00  \n",
       "Incident_Hour_Range_04:00 PM to 08:00 PM      0.00     1.00  \n",
       "Incident_Hour_Range_08:00 PM to 12:00 AM      0.00     0.00  \n",
       "insured_sex_FEMALE                            1.00     0.00  \n",
       "insured_sex_MALE                              0.00     1.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for all range values\n",
    "\n",
    "InsClaimsF1 = pd.get_dummies(InsClaimsF1, columns=['Range-mac', 'CG_Range', 'CL_Range',\n",
    "'Incident_Hour_Range', 'insured_sex'])\n",
    "InsClaimsF1.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f3df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in InsClaimsF1.columns:\n",
    "    if col != 'fraud_reported':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'fraud_reported'\n",
    "\n",
    "x = InsClaimsF1[IndepVar]\n",
    "y = InsClaimsF1[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb7debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)\n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc3a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Conver x_train values\n",
    "\n",
    "x_train['age'] = sc.fit_transform(x_train['age'].values.reshape(-1, 1))\n",
    "x_train['policy_annual_premium'] = sc.fit_transform(x_train['policy_annual_premium'].values.reshape(-1, 1))\n",
    "x_train['total_claim_amount'] = sc.fit_transform(x_train['total_claim_amount'].values.reshape(-1, 1))\n",
    "x_train['injury_claim'] = sc.fit_transform(x_train['injury_claim'].values.reshape(-1, 1))\n",
    "x_train['property_claim'] = sc.fit_transform(x_train['property_claim'].values.reshape(-1, 1))\n",
    "x_train['vehicle_claim'] = sc.fit_transform(x_train['vehicle_claim'].values.reshape(-1, 1))\n",
    "\n",
    "# Conver x_test values\n",
    "\n",
    "x_test['age'] = sc.fit_transform(x_test['age'].values.reshape(-1, 1))\n",
    "x_test['policy_annual_premium'] = sc.fit_transform(x_test['policy_annual_premium'].values.reshape(-1, 1))\n",
    "x_test['total_claim_amount'] = sc.fit_transform(x_test['total_claim_amount'].values.reshape(-1, 1))\n",
    "x_test['injury_claim'] = sc.fit_transform(x_test['injury_claim'].values.reshape(-1, 1))\n",
    "x_test['property_claim'] = sc.fit_transform(x_test['property_claim'].values.reshape(-1, 1))\n",
    "x_test['vehicle_claim'] = sc.fit_transform(x_test['vehicle_claim'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert to dataframes\n",
    "\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cde0b",
   "metadata": {},
   "source": [
    "# Random Forest without LDA & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3024177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  0  80]\n",
      " [  0 220]]\n",
      "Outcome Values : \n",
      " 0 80 0 220\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        80\n",
      "           0       0.73      1.00      0.85       220\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.37      0.50      0.42       300\n",
      "weighted avg       0.54      0.73      0.62       300\n",
      "\n",
      "Accuracy : 73.3 %\n",
      "Precision : nan %\n",
      "Recall : 0.0 %\n",
      "F1 Score : 0.0\n",
      "Balanced Accuracy : 50.0 %\n",
      "MCC nan\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y_pred = modelRF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83185062",
   "metadata": {},
   "source": [
    "# Logistic Regression without LDA & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d111f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  5  75]\n",
      " [ 13 207]]\n",
      "Outcome Values : \n",
      " 5 75 13 207\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.06      0.10        80\n",
      "           0       0.73      0.94      0.82       220\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.51      0.50      0.46       300\n",
      "weighted avg       0.61      0.71      0.63       300\n",
      "\n",
      "Accuracy : 70.7 %\n",
      "Precision : 27.8 %\n",
      "Recall : 6.2 %\n",
      "F1 Score : 0.102\n",
      "Balanced Accuracy : 50.1 %\n",
      "MCC 0.006\n",
      "roc_auc_score: 0.502\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelLR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y1_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c574284",
   "metadata": {},
   "source": [
    "# Decision Tree without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e750d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 34  46]\n",
      " [ 46 174]]\n",
      "Outcome Values : \n",
      " 34 46 46 174\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.42      0.42        80\n",
      "           0       0.79      0.79      0.79       220\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.61      0.61      0.61       300\n",
      "weighted avg       0.69      0.69      0.69       300\n",
      "\n",
      "Accuracy : 69.3 %\n",
      "Precision : 42.5 %\n",
      "Recall : 42.5 %\n",
      "F1 Score : 0.425\n",
      "Balanced Accuracy : 60.8 %\n",
      "MCC 0.216\n",
      "roc_auc_score: 0.608\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y2_pred = modelDT.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y2_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2da37",
   "metadata": {},
   "source": [
    "# SVM without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd834f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 25  55]\n",
      " [ 62 158]]\n",
      "Outcome Values : \n",
      " 25 55 62 158\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.31      0.30        80\n",
      "           0       0.74      0.72      0.73       220\n",
      "\n",
      "    accuracy                           0.61       300\n",
      "   macro avg       0.51      0.52      0.51       300\n",
      "weighted avg       0.62      0.61      0.62       300\n",
      "\n",
      "Accuracy : 61.0 %\n",
      "Precision : 28.7 %\n",
      "Recall : 31.2 %\n",
      "F1 Score : 0.299\n",
      "Balanced Accuracy : 51.5 %\n",
      "MCC 0.03\n",
      "roc_auc_score: 0.515\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y3_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y3_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624fd1a",
   "metadata": {},
   "source": [
    "# KNN Without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be1b03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  7  73]\n",
      " [ 20 200]]\n",
      "Outcome Values : \n",
      " 7 73 20 200\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.09      0.13        80\n",
      "           0       0.73      0.91      0.81       220\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.50      0.50      0.47       300\n",
      "weighted avg       0.61      0.69      0.63       300\n",
      "\n",
      "Accuracy : 69.0 %\n",
      "Precision : 25.9 %\n",
      "Recall : 8.8 %\n",
      "F1 Score : 0.131\n",
      "Balanced Accuracy : 49.8 %\n",
      "MCC -0.005\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y4_pred = modelKNN.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y4_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273752d",
   "metadata": {},
   "source": [
    "# Train the Principal Component Analysis (PCA) with train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4c65ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99934460e-01 1.38797669e-05 9.80884984e-06 4.07588245e-06\n",
      " 3.77091404e-06 3.69080997e-06 3.45142776e-06 3.07898441e-06\n",
      " 2.77370919e-06 2.52349489e-06 1.91419028e-06 1.75189336e-06\n",
      " 1.65187652e-06 1.43487034e-06 1.27821938e-06 1.12457717e-06\n",
      " 8.88735908e-07 8.66798858e-07 7.83644510e-07 6.63383799e-07\n",
      " 6.09697856e-07 5.53639543e-07 5.41540709e-07 4.81560044e-07\n",
      " 4.40320450e-07 4.29882078e-07 4.23345268e-07 3.69798681e-07\n",
      " 3.49069256e-07 3.38098661e-07 2.96215126e-07 2.49890911e-07\n",
      " 2.16403411e-07 1.22226654e-07 1.16937460e-07 1.11219338e-07\n",
      " 9.21476741e-08 8.50906640e-08 7.51922246e-08 6.54486078e-08\n",
      " 6.36418816e-08 4.32473422e-08 3.67486050e-08 1.22110409e-08\n",
      " 4.00035433e-09 9.96842540e-33 9.96842540e-33 9.96842540e-33\n",
      " 9.96842540e-33 9.96842540e-33 9.96842540e-33]\n"
     ]
    }
   ],
   "source": [
    "# Principal component analysis (PCA) is a statistical technique to convert high dimensional data to low dimensional data\n",
    "# by selecting the most important features that capture maximum information about the dataset. The features are selected\n",
    "# on the basis of variance that they cause in the output. The feature that causes highest variance is the first principal\n",
    "# component. The feature that is responsible for second highest variance is considered the second principal component,\n",
    "# and so on. It is important to mention that principal components do not have any correlation with each other.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "applyPCA = PCA()\n",
    "\n",
    "x1_train = applyPCA.fit_transform(x_train)\n",
    "x1_test = applyPCA.transform(x_test)\n",
    "explained_variance = applyPCA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656963e",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ce9ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  0  80]\n",
      " [  0 220]]\n",
      "Outcome Values : \n",
      " 0 80 0 220\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        80\n",
      "           0       0.73      1.00      0.85       220\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.37      0.50      0.42       300\n",
      "weighted avg       0.54      0.73      0.62       300\n",
      "\n",
      "Accuracy : 73.3 %\n",
      "Precision : nan %\n",
      "Recall : 0.0 %\n",
      "F1 Score : 0.0\n",
      "Balanced Accuracy : 50.0 %\n",
      "MCC nan\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x1_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y5_pred = modelRF.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y5_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb1b338",
   "metadata": {},
   "source": [
    "# Logistic Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8407ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  8  72]\n",
      " [ 15 205]]\n",
      "Outcome Values : \n",
      " 8 72 15 205\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.10      0.16        80\n",
      "           0       0.74      0.93      0.82       220\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.54      0.52      0.49       300\n",
      "weighted avg       0.64      0.71      0.65       300\n",
      "\n",
      "Accuracy : 71.0 %\n",
      "Precision : 34.8 %\n",
      "Recall : 10.0 %\n",
      "F1 Score : 0.155\n",
      "Balanced Accuracy : 51.6 %\n",
      "MCC 0.053\n",
      "roc_auc_score: 0.516\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x1_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y6_pred = modelLR.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y6_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6747e",
   "metadata": {},
   "source": [
    "# Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb5dc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 21  59]\n",
      " [ 62 158]]\n",
      "Outcome Values : \n",
      " 21 59 62 158\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.26      0.26        80\n",
      "           0       0.73      0.72      0.72       220\n",
      "\n",
      "    accuracy                           0.60       300\n",
      "   macro avg       0.49      0.49      0.49       300\n",
      "weighted avg       0.60      0.60      0.60       300\n",
      "\n",
      "Accuracy : 59.7 %\n",
      "Precision : 25.3 %\n",
      "Recall : 26.2 %\n",
      "F1 Score : 0.258\n",
      "Balanced Accuracy : 49.0 %\n",
      "MCC -0.019\n",
      "roc_auc_score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x1_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y7_pred = modelDT.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y7_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y7_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2198ea",
   "metadata": {},
   "source": [
    "# SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92438af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 54  26]\n",
      " [134  86]]\n",
      "Outcome Values : \n",
      " 54 26 134 86\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.68      0.40        80\n",
      "           0       0.77      0.39      0.52       220\n",
      "\n",
      "    accuracy                           0.47       300\n",
      "   macro avg       0.53      0.53      0.46       300\n",
      "weighted avg       0.64      0.47      0.49       300\n",
      "\n",
      "Accuracy : 46.7 %\n",
      "Precision : 28.7 %\n",
      "Recall : 67.5 %\n",
      "F1 Score : 0.403\n",
      "Balanced Accuracy : 53.3 %\n",
      "MCC 0.06\n",
      "roc_auc_score: 0.533\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "\n",
    "modelSVMGaussian.fit(x1_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y8_pred = modelSVMGaussian.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y8_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y8_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef6a7be",
   "metadata": {},
   "source": [
    "# KNN with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bef78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  7  73]\n",
      " [ 20 200]]\n",
      "Outcome Values : \n",
      " 7 73 20 200\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.09      0.13        80\n",
      "           0       0.73      0.91      0.81       220\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.50      0.50      0.47       300\n",
      "weighted avg       0.61      0.69      0.63       300\n",
      "\n",
      "Accuracy : 69.0 %\n",
      "Precision : 25.9 %\n",
      "Recall : 8.8 %\n",
      "F1 Score : 0.131\n",
      "Balanced Accuracy : 49.8 %\n",
      "MCC -0.005\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x1_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y9_pred = modelKNN.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y9_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y9_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7fe85",
   "metadata": {},
   "source": [
    "# Train the Linear Discriminant Analysis (LDA) with train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68a24a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "applyLDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "x2_train = applyLDA.fit_transform(x_train, y_train)\n",
    "x2_test = applyLDA.transform(x_test)\n",
    "\n",
    "explained_variance = applyLDA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aac97",
   "metadata": {},
   "source": [
    "# Random Forest with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "411e3765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  2  78]\n",
      " [  6 214]]\n",
      "Outcome Values : \n",
      " 2 78 6 214\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.03      0.05        80\n",
      "           0       0.73      0.97      0.84       220\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.49      0.50      0.44       300\n",
      "weighted avg       0.60      0.72      0.63       300\n",
      "\n",
      "Accuracy : 72.0 %\n",
      "Precision : 25.0 %\n",
      "Recall : 2.5 %\n",
      "F1 Score : 0.045\n",
      "Balanced Accuracy : 49.9 %\n",
      "MCC -0.006\n",
      "roc_auc_score: 0.499\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x2_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y10_pred = modelRF.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y10_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y10_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bf1af",
   "metadata": {},
   "source": [
    "# Logistic Regression with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a889cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  5  75]\n",
      " [ 16 204]]\n",
      "Outcome Values : \n",
      " 5 75 16 204\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.06      0.10        80\n",
      "           0       0.73      0.93      0.82       220\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.48      0.49      0.46       300\n",
      "weighted avg       0.60      0.70      0.63       300\n",
      "\n",
      "Accuracy : 69.7 %\n",
      "Precision : 23.8 %\n",
      "Recall : 6.2 %\n",
      "F1 Score : 0.099\n",
      "Balanced Accuracy : 49.5 %\n",
      "MCC -0.018\n",
      "roc_auc_score: 0.495\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x2_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y11_pred = modelLR.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y11_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y11_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b50b83",
   "metadata": {},
   "source": [
    "# Decision Tree with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee8d4179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 21  59]\n",
      " [ 50 170]]\n",
      "Outcome Values : \n",
      " 21 59 50 170\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.26      0.28        80\n",
      "           0       0.74      0.77      0.76       220\n",
      "\n",
      "    accuracy                           0.64       300\n",
      "   macro avg       0.52      0.52      0.52       300\n",
      "weighted avg       0.62      0.64      0.63       300\n",
      "\n",
      "Accuracy : 63.7 %\n",
      "Precision : 29.6 %\n",
      "Recall : 26.2 %\n",
      "F1 Score : 0.278\n",
      "Balanced Accuracy : 51.8 %\n",
      "MCC 0.037\n",
      "roc_auc_score: 0.518\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x2_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y12_pred = modelDT.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y12_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y12_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b0f12",
   "metadata": {},
   "source": [
    "# SVM with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6defdcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 46  34]\n",
      " [104 116]]\n",
      "Outcome Values : \n",
      " 46 34 104 116\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.57      0.40        80\n",
      "           0       0.77      0.53      0.63       220\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.54      0.55      0.51       300\n",
      "weighted avg       0.65      0.54      0.57       300\n",
      "\n",
      "Accuracy : 54.0 %\n",
      "Precision : 30.7 %\n",
      "Recall : 57.5 %\n",
      "F1 Score : 0.4\n",
      "Balanced Accuracy : 55.1 %\n",
      "MCC 0.09\n",
      "roc_auc_score: 0.551\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "\n",
    "modelSVMGaussian.fit(x2_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y13_pred = modelSVMGaussian.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y13_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y13_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61814da",
   "metadata": {},
   "source": [
    "# KNN with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34c3e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 18  62]\n",
      " [ 25 195]]\n",
      "Outcome Values : \n",
      " 18 62 25 195\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.23      0.29        80\n",
      "           0       0.76      0.89      0.82       220\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.59      0.56      0.56       300\n",
      "weighted avg       0.67      0.71      0.68       300\n",
      "\n",
      "Accuracy : 71.0 %\n",
      "Precision : 41.9 %\n",
      "Recall : 22.5 %\n",
      "F1 Score : 0.293\n",
      "Balanced Accuracy : 55.6 %\n",
      "MCC 0.141\n",
      "roc_auc_score: 0.556\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x2_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y14_pred = modelKNN.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y14_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y14_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4819720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2276856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
