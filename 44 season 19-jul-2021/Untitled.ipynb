{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9d8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Ignore harmless warnings \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandasql as psql\n",
    "\n",
    "# pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab2de299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Universal bank data\n",
    "\n",
    "bankdata = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\44 season 17-jul-2021\\Universalbank.csv\", header=0) \n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f060b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Displaying the dataset information\n",
    "\n",
    "bankdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e68f66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the columns which are not influencing the target variable\n",
    "\n",
    "del bankdata['ID']\n",
    "del bankdata['ZIP Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb3ab595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'Education']\n"
     ]
    }
   ],
   "source": [
    "# cols1 is variables - crating a dummy variables\n",
    "\n",
    "cols1 = ['Family', 'Education']\n",
    "print(cols1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14df2664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n"
     ]
    }
   ],
   "source": [
    "# cols2 variables - MinMaxScalar function\n",
    "\n",
    "cols2 = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n",
    "print(cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f55223bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Personal Loan', 'Securities Account', 'CD Account', 'Online']\n"
     ]
    }
   ],
   "source": [
    "# cols3 variables - Normalization\n",
    "\n",
    "cols3 = ['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education', 'Mortgage', \n",
    "         'Personal Loan', 'Securities Account', 'CD Account', 'Online'] \n",
    "print(cols3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "897c3b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAvg</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mortgage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Securities Account</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD Account</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditCard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0     1     2      3     4\n",
       "Age                 25.0  45.0  39.0   35.0  35.0\n",
       "Experience           1.0  19.0  15.0    9.0   8.0\n",
       "Income              49.0  34.0  11.0  100.0  45.0\n",
       "CCAvg                1.6   1.5   1.0    2.7   1.0\n",
       "Mortgage             0.0   0.0   0.0    0.0   0.0\n",
       "Personal Loan        0.0   0.0   0.0    0.0   0.0\n",
       "Securities Account   1.0   1.0   0.0    0.0   0.0\n",
       "CD Account           0.0   0.0   0.0    0.0   0.0\n",
       "Online               0.0   0.0   0.0    0.0   0.0\n",
       "CreditCard           0.0   0.0   0.0    0.0   1.0\n",
       "Family_1             0.0   0.0   1.0    1.0   0.0\n",
       "Family_2             0.0   0.0   0.0    0.0   0.0\n",
       "Family_3             0.0   1.0   0.0    0.0   0.0\n",
       "Family_4             1.0   0.0   0.0    0.0   1.0\n",
       "Education_1          1.0   1.0   1.0    0.0   0.0\n",
       "Education_2          0.0   0.0   0.0    1.0   1.0\n",
       "Education_3          0.0   0.0   0.0    0.0   0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for all range values\n",
    "\n",
    "bankdata = pd.get_dummies(bankdata, columns=cols1)\n",
    "bankdata.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8692fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in bankdata.columns:\n",
    "    if col != 'CreditCard':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'CreditCard'\n",
    "\n",
    "x = bankdata[IndepVar]\n",
    "y = bankdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "000583a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 12)\n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "893414e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train[cols2] = mmscaler.fit_transform(x_train[cols2])\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "x_test[cols2] = mmscaler.fit_transform(x_test[cols2])\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e677e03f",
   "metadata": {},
   "source": [
    "# Random Forest without LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6eb77c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1065   17]\n",
      " [ 359   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1082\n",
      "           1       0.78      0.14      0.24       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.76      0.56      0.54      1500\n",
      "weighted avg       0.76      0.75      0.68      1500\n",
      "\n",
      "Accuracy: 74.93 %\n",
      "Precision: 74.93 %\n",
      "Recall: 74.93 %\n",
      "f1-score: 74.93 %\n",
      "roc_auc_score: 0.563\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='entropy', max_depth=2, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y_pred = modelRF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007883c",
   "metadata": {},
   "source": [
    "# Logistic Regression without LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53099e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1058   24]\n",
      " [ 354   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1082\n",
      "           1       0.73      0.15      0.25       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.74      0.57      0.55      1500\n",
      "weighted avg       0.74      0.75      0.68      1500\n",
      "\n",
      "Accuracy: 74.8 %\n",
      "Precision: 74.8 %\n",
      "Recall: 74.8 %\n",
      "f1-score: 74.8 %\n",
      "roc_auc_score: 0.565\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelLR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y1_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4adc5",
   "metadata": {},
   "source": [
    "# Random Forest with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b6a9639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# Random forest with 'Linear Discriminant Analysis' technique to reduce the dimentionality\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "applyLDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "x_train = applyLDA.fit_transform(x_train, y_train)\n",
    "x_test = applyLDA.transform(x_test)\n",
    "\n",
    "explained_variance = applyLDA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79325e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1069   13]\n",
      " [ 355   63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85      1082\n",
      "           1       0.83      0.15      0.26       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.79      0.57      0.55      1500\n",
      "weighted avg       0.77      0.75      0.69      1500\n",
      "\n",
      "Accuracy: 75.47 %\n",
      "Precision: 75.47 %\n",
      "Recall: 75.47 %\n",
      "f1-score: 75.47 %\n",
      "roc_auc_score: 0.569\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='entropy', max_depth=2, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y2_pred = modelRF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y2_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1b49e",
   "metadata": {},
   "source": [
    "# Logistic Regression with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1f90fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1058   24]\n",
      " [ 354   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1082\n",
      "           1       0.73      0.15      0.25       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.74      0.57      0.55      1500\n",
      "weighted avg       0.74      0.75      0.68      1500\n",
      "\n",
      "Accuracy: 74.8 %\n",
      "Precision: 74.8 %\n",
      "Recall: 74.8 %\n",
      "f1-score: 74.8 %\n",
      "roc_auc_score: 0.565\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y3_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2483786",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec553fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.81600761e-01 1.42653194e-01 1.29344934e-01 1.15215411e-01\n",
      " 1.12554318e-01 9.82372383e-02 6.31022007e-02 5.86352423e-02\n",
      " 4.73926769e-02 1.95880336e-02 1.39285389e-02 1.13889853e-02\n",
      " 6.19540178e-03 1.63064410e-04 5.09517392e-33 3.68183753e-33]\n"
     ]
    }
   ],
   "source": [
    "# Principal component analysis (PCA) is a statistical technique to convert high dimensional data to low dimensional data\n",
    "# by selecting the most important features that capture maximum information about the dataset. The features are selected\n",
    "# on the basis of variance that they cause in the output. The feature that causes highest variance is the first principal\n",
    "# component. The feature that is responsible for second highest variance is considered the second principal component,\n",
    "# and so on. It is important to mention that principal components do not have any correlation with each other.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "applyPCA = PCA()\n",
    "\n",
    "x_train = applyPCA.fit_transform(x_train)\n",
    "x_test = applyPCA.transform(x_test)\n",
    "explained_variance = applyPCA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c55182c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1068   14]\n",
      " [ 356   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85      1082\n",
      "           1       0.82      0.15      0.25       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.78      0.57      0.55      1500\n",
      "weighted avg       0.77      0.75      0.68      1500\n",
      "\n",
      "Accuracy: 75.33 %\n",
      "Precision: 75.33 %\n",
      "Recall: 75.33 %\n",
      "f1-score: 75.33 %\n",
      "roc_auc_score: 0.568\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='entropy', max_depth=2, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y4_pred = modelRF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y4_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d198cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1058   24]\n",
      " [ 354   64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1082\n",
      "           1       0.73      0.15      0.25       418\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.74      0.57      0.55      1500\n",
      "weighted avg       0.74      0.75      0.68      1500\n",
      "\n",
      "Accuracy: 74.8 %\n",
      "Precision: 74.8 %\n",
      "Recall: 74.8 %\n",
      "f1-score: 74.8 %\n",
      "roc_auc_score: 0.565\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y5_pred = modelLR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y5_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f78396",
   "metadata": {},
   "source": [
    "# Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a92d7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[757 325]\n",
      " [256 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      1082\n",
      "           1       0.33      0.39      0.36       418\n",
      "\n",
      "    accuracy                           0.61      1500\n",
      "   macro avg       0.54      0.54      0.54      1500\n",
      "weighted avg       0.63      0.61      0.62      1500\n",
      "\n",
      "Accuracy: 61.27 %\n",
      "Precision: 33.26 %\n",
      "Recall: 38.76 %\n",
      "f1-score: 35.8 %\n",
      "roc_auc_score: 0.544\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y6_pred = modelDT.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y6_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5251985",
   "metadata": {},
   "source": [
    "# SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7625e9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[759 323]\n",
      " [243 175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      1082\n",
      "           1       0.35      0.42      0.38       418\n",
      "\n",
      "    accuracy                           0.62      1500\n",
      "   macro avg       0.55      0.56      0.56      1500\n",
      "weighted avg       0.64      0.62      0.63      1500\n",
      "\n",
      "Accuracy: 62.27 %\n",
      "Precision: 62.27 %\n",
      "Recall: 62.27 %\n",
      "f1-score: 62.27 %\n",
      "roc_auc_score: 0.56\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "bankdataSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "bankdataSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y_pred3 = bankdataSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(classification_report(y_test,y_pred3))\n",
    "\n",
    "# Evalution metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred3) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred3, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred3, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred3, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred3), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d856e5",
   "metadata": {},
   "source": [
    "# KNN With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f9306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
