{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a084202",
   "metadata": {},
   "source": [
    "# Credit_Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e66d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ignore harmful warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83139fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Defult Credit Card cilents data\n",
    "\n",
    "dccdata = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\44 season 19-jul-2021\\Default_Credit_Card_Clients_SVM.csv\",header = 0)\n",
    "dccdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afdeaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>CC_Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  CC_Default  \n",
       "0         0         0         0           1  \n",
       "1      1000         0      2000           1  \n",
       "2      1000      1000      5000           0  \n",
       "3      1100      1069      1000           0  \n",
       "4      9000       689       679           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccdata.rename({'default payment next month' : 'CC_Default'}, axis =1, inplace=True)\n",
    "dccdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab83ccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:  23364\n",
      "Class 1:  6636\n",
      "Proportion:  3.52 : 1\n",
      "Total CC Trans:  30000\n"
     ]
    }
   ],
   "source": [
    "# Count the target or dependent variable by '0' or '1' and\n",
    "# their proportion (> 10: 1, then the dataset is imbalance dataset\n",
    "\n",
    "dccdata_count = dccdata.CC_Default.value_counts()\n",
    "print('Class 0: ', dccdata_count[0])\n",
    "print('Class 1: ', dccdata_count[1])\n",
    "print('Proportion: ', round(dccdata_count[0]/dccdata_count[1], 2), ': 1')\n",
    "print('Total CC Trans: ', len(dccdata)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e84c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    14030\n",
       "1    10585\n",
       "3     4917\n",
       "5      280\n",
       "4      123\n",
       "6       51\n",
       "0       14\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of eduction variable\n",
    "\n",
    "dccdata['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f3b588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    15964\n",
       "1    13659\n",
       "3      323\n",
       "0       54\n",
       "Name: MARRIAGE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccdata['MARRIAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cc0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value data size\n",
    "\n",
    "dccdata_missing = (dccdata[(dccdata.EDUCATION == 0) | (dccdata.MARRIAGE == 0)])\n",
    "dccdata_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "068c8d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccdata_no_missing = dccdata[(dccdata.EDUCATION != 0) | (dccdata.MARRIAGE != 0)]\n",
    "dccdata_no_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2732e345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>CC_Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  CC_Default  \n",
       "0         0         0         0           1  \n",
       "1      1000         0      2000           1  \n",
       "2      1000      1000      5000           0  \n",
       "3      1100      1069      1000           0  \n",
       "4      9000       689       679           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dccdata1 = dccdata_no_missing.copy()\n",
    "dccdata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5c25fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_6_-2</th>\n",
       "      <th>PAY_6_-1</th>\n",
       "      <th>PAY_6_0</th>\n",
       "      <th>PAY_6_2</th>\n",
       "      <th>PAY_6_3</th>\n",
       "      <th>PAY_6_4</th>\n",
       "      <th>PAY_6_5</th>\n",
       "      <th>PAY_6_6</th>\n",
       "      <th>PAY_6_7</th>\n",
       "      <th>PAY_6_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>24</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>26</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>34</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>37</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>57</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0   1      20000   24       3913       3102        689          0          0   \n",
       "1   2     120000   26       2682       1725       2682       3272       3455   \n",
       "2   3      90000   34      29239      14027      13559      14331      14948   \n",
       "3   4      50000   37      46990      48233      49291      28314      28959   \n",
       "4   5      50000   57       8617       5670      35835      20940      19146   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  ...  PAY_6_-2  PAY_6_-1  PAY_6_0  PAY_6_2  PAY_6_3  \\\n",
       "0          0         0  ...         1         0        0        0        0   \n",
       "1       3261         0  ...         0         0        0        1        0   \n",
       "2      15549      1518  ...         0         0        1        0        0   \n",
       "3      29547      2000  ...         0         0        1        0        0   \n",
       "4      19131      2000  ...         0         0        1        0        0   \n",
       "\n",
       "   PAY_6_4  PAY_6_5  PAY_6_6  PAY_6_7  PAY_6_8  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert into dummies\n",
    "\n",
    "dccdata1 = pd.get_dummies(dccdata1, columns=['SEX','EDUCATION','MARRIAGE','PAY_1','PAY_2',\n",
    "                                            'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'])\n",
    "dccdata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8551721",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['LIMIT_BAL','AGE','BILL_AMT1', 'BILL_AMT2',\n",
    "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9aeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify independent and target variable\n",
    "\n",
    "x = dccdata1.drop(['CC_Default', 'ID'], axis=1)\n",
    "y = dccdata1['CC_Default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6324b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state = 4)\n",
    "x_test_f1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c46109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train[cols] = mmscaler.fit_transform(x_train[cols])\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "x_test[cols] = mmscaler.fit_transform(x_test[cols])\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a97666",
   "metadata": {},
   "source": [
    "# Random Forest without LDA & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45d1019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  38 1993]\n",
      " [   9 6960]]\n",
      "Outcome Values : \n",
      " 38 1993 9 6960\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.02      0.04      2031\n",
      "           0       0.78      1.00      0.87      6969\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.79      0.51      0.46      9000\n",
      "weighted avg       0.78      0.78      0.69      9000\n",
      "\n",
      "Accuracy : 77.8 %\n",
      "Precision : 80.9 %\n",
      "Recall : 1.9 %\n",
      "F1 Score : 0.037\n",
      "Balanced Accuracy : 50.9 %\n",
      "MCC 0.101\n",
      "roc_auc_score: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y_pred = modelRF.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436220bf",
   "metadata": {},
   "source": [
    "# Logistic Regression without LDA & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f0fe80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 683 1348]\n",
      " [ 311 6658]]\n",
      "Outcome Values : \n",
      " 683 1348 311 6658\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.34      0.45      2031\n",
      "           0       0.83      0.96      0.89      6969\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.65      0.67      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n",
      "Accuracy : 81.6 %\n",
      "Precision : 68.7 %\n",
      "Recall : 33.6 %\n",
      "F1 Score : 0.452\n",
      "Balanced Accuracy : 64.6 %\n",
      "MCC 0.389\n",
      "roc_auc_score: 0.646\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = modelLR.predict(x_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y1_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f700bd1",
   "metadata": {},
   "source": [
    "# Decision Tree without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66031a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 901 1130]\n",
      " [3592 3377]]\n",
      "Outcome Values : \n",
      " 901 1130 3592 3377\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.44      0.28      2031\n",
      "           0       0.75      0.48      0.59      6969\n",
      "\n",
      "    accuracy                           0.48      9000\n",
      "   macro avg       0.47      0.46      0.43      9000\n",
      "weighted avg       0.63      0.48      0.52      9000\n",
      "\n",
      "Accuracy : 47.5 %\n",
      "Precision : 20.1 %\n",
      "Recall : 44.4 %\n",
      "F1 Score : 0.276\n",
      "Balanced Accuracy : 46.4 %\n",
      "MCC -0.06\n",
      "roc_auc_score: 0.464\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y2_pred = modelDT.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y2_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16d17b",
   "metadata": {},
   "source": [
    "# SVM without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afcaa74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[1187  844]\n",
      " [1226 5743]]\n",
      "Outcome Values : \n",
      " 1187 844 1226 5743\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.58      0.53      2031\n",
      "           0       0.87      0.82      0.85      6969\n",
      "\n",
      "    accuracy                           0.77      9000\n",
      "   macro avg       0.68      0.70      0.69      9000\n",
      "weighted avg       0.79      0.77      0.78      9000\n",
      "\n",
      "Accuracy : 77.0 %\n",
      "Precision : 49.2 %\n",
      "Recall : 58.4 %\n",
      "F1 Score : 0.534\n",
      "Balanced Accuracy : 70.4 %\n",
      "MCC 0.386\n",
      "roc_auc_score: 0.704\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y3_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y3_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d118cc0",
   "metadata": {},
   "source": [
    "# KNN Without PCA & LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53766121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 719 1312]\n",
      " [ 601 6368]]\n",
      "Outcome Values : \n",
      " 719 1312 601 6368\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.35      0.43      2031\n",
      "           0       0.83      0.91      0.87      6969\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.69      0.63      0.65      9000\n",
      "weighted avg       0.76      0.79      0.77      9000\n",
      "\n",
      "Accuracy : 78.7 %\n",
      "Precision : 54.5 %\n",
      "Recall : 35.4 %\n",
      "F1 Score : 0.429\n",
      "Balanced Accuracy : 63.4 %\n",
      "MCC 0.316\n",
      "roc_auc_score: 0.634\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y4_pred = modelKNN.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y4_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719b86",
   "metadata": {},
   "source": [
    "# Train the Principal Component Analysis (PCA) with train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7656b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.63074743e-01 1.19175438e-01 9.49995740e-02 8.62684840e-02\n",
      " 7.79871033e-02 6.26361788e-02 4.47164916e-02 3.50003171e-02\n",
      " 2.66290656e-02 2.43307918e-02 1.88796575e-02 1.80620225e-02\n",
      " 1.42211825e-02 1.37858060e-02 1.27145548e-02 1.09042849e-02\n",
      " 8.76980766e-03 8.23317404e-03 7.13601544e-03 6.94376454e-03\n",
      " 6.12163231e-03 4.35849301e-03 3.54754844e-03 3.28083811e-03\n",
      " 2.81058076e-03 2.52939691e-03 2.41646883e-03 2.36586330e-03\n",
      " 2.12120668e-03 1.97047226e-03 1.91574688e-03 1.56381366e-03\n",
      " 1.23975531e-03 1.07095230e-03 9.83863328e-04 9.34224028e-04\n",
      " 7.62139588e-04 5.62550705e-04 4.96694519e-04 4.04452722e-04\n",
      " 3.95172688e-04 3.48325734e-04 3.20718479e-04 2.95185665e-04\n",
      " 2.86223358e-04 2.24530677e-04 2.12042977e-04 1.90053909e-04\n",
      " 1.80771219e-04 1.48981420e-04 1.38899162e-04 1.32499430e-04\n",
      " 1.20262687e-04 1.07201504e-04 1.06431318e-04 1.04477634e-04\n",
      " 9.35733486e-05 8.16416203e-05 7.46262915e-05 7.13956208e-05\n",
      " 6.96779771e-05 5.10489273e-05 4.19469611e-05 3.61923219e-05\n",
      " 3.21367166e-05 2.87061070e-05 2.56933258e-05 2.45875167e-05\n",
      " 2.39044466e-05 1.82887217e-05 1.69725217e-05 1.49045322e-05\n",
      " 1.24977273e-05 1.04524780e-05 1.00111946e-05 6.39972121e-06\n",
      " 5.65683408e-06 4.80590497e-06 3.44958806e-06 2.90273514e-06\n",
      " 1.59807067e-06 5.18823449e-32 1.80623051e-33 1.47603851e-33\n",
      " 1.47603851e-33 1.47603851e-33 1.47603851e-33 1.47603851e-33\n",
      " 1.47603851e-33 1.47603851e-33 1.47603851e-33]\n"
     ]
    }
   ],
   "source": [
    "# Principal component analysis (PCA) is a statistical technique to convert high dimensional data to low dimensional data\n",
    "# by selecting the most important features that capture maximum information about the dataset. The features are selected\n",
    "# on the basis of variance that they cause in the output. The feature that causes highest variance is the first principal\n",
    "# component. The feature that is responsible for second highest variance is considered the second principal component,\n",
    "# and so on. It is important to mention that principal components do not have any correlation with each other.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "applyPCA = PCA()\n",
    "\n",
    "x1_train = applyPCA.fit_transform(x_train)\n",
    "x1_test = applyPCA.transform(x_test)\n",
    "explained_variance = applyPCA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c782ad",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c81ef5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 180 1851]\n",
      " [  64 6905]]\n",
      "Outcome Values : \n",
      " 180 1851 64 6905\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.09      0.16      2031\n",
      "           0       0.79      0.99      0.88      6969\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.76      0.54      0.52      9000\n",
      "weighted avg       0.78      0.79      0.72      9000\n",
      "\n",
      "Accuracy : 78.7 %\n",
      "Precision : 73.8 %\n",
      "Recall : 8.9 %\n",
      "F1 Score : 0.158\n",
      "Balanced Accuracy : 54.0 %\n",
      "MCC 0.204\n",
      "roc_auc_score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x1_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y5_pred = modelRF.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y5_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c815d",
   "metadata": {},
   "source": [
    "# Logistic Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcfc6cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 680 1351]\n",
      " [ 307 6662]]\n",
      "Outcome Values : \n",
      " 680 1351 307 6662\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.33      0.45      2031\n",
      "           0       0.83      0.96      0.89      6969\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.65      0.67      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n",
      "Accuracy : 81.6 %\n",
      "Precision : 68.9 %\n",
      "Recall : 33.5 %\n",
      "F1 Score : 0.451\n",
      "Balanced Accuracy : 64.6 %\n",
      "MCC 0.389\n",
      "roc_auc_score: 0.645\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x1_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y6_pred = modelLR.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y6_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d77dfb",
   "metadata": {},
   "source": [
    "# Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91ccad3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 820 1211]\n",
      " [1840 5129]]\n",
      "Outcome Values : \n",
      " 820 1211 1840 5129\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.40      0.35      2031\n",
      "           0       0.81      0.74      0.77      6969\n",
      "\n",
      "    accuracy                           0.66      9000\n",
      "   macro avg       0.56      0.57      0.56      9000\n",
      "weighted avg       0.70      0.66      0.68      9000\n",
      "\n",
      "Accuracy : 66.1 %\n",
      "Precision : 30.8 %\n",
      "Recall : 40.4 %\n",
      "F1 Score : 0.35\n",
      "Balanced Accuracy : 57.0 %\n",
      "MCC 0.128\n",
      "roc_auc_score: 0.57\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x1_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y7_pred = modelDT.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y7_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y7_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37593c4b",
   "metadata": {},
   "source": [
    "# SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "159f974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[1201  830]\n",
      " [1285 5684]]\n",
      "Outcome Values : \n",
      " 1201 830 1285 5684\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.59      0.53      2031\n",
      "           0       0.87      0.82      0.84      6969\n",
      "\n",
      "    accuracy                           0.77      9000\n",
      "   macro avg       0.68      0.70      0.69      9000\n",
      "weighted avg       0.78      0.77      0.77      9000\n",
      "\n",
      "Accuracy : 76.5 %\n",
      "Precision : 48.3 %\n",
      "Recall : 59.1 %\n",
      "F1 Score : 0.532\n",
      "Balanced Accuracy : 70.4 %\n",
      "MCC 0.38\n",
      "roc_auc_score: 0.703\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "\n",
    "modelSVMGaussian.fit(x1_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y8_pred = modelSVMGaussian.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y8_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y8_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60053c",
   "metadata": {},
   "source": [
    "# KNN with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd314e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 719 1312]\n",
      " [ 601 6368]]\n",
      "Outcome Values : \n",
      " 719 1312 601 6368\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.35      0.43      2031\n",
      "           0       0.83      0.91      0.87      6969\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.69      0.63      0.65      9000\n",
      "weighted avg       0.76      0.79      0.77      9000\n",
      "\n",
      "Accuracy : 78.7 %\n",
      "Precision : 54.5 %\n",
      "Recall : 35.4 %\n",
      "F1 Score : 0.429\n",
      "Balanced Accuracy : 63.4 %\n",
      "MCC 0.316\n",
      "roc_auc_score: 0.634\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x1_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y9_pred = modelKNN.predict(x1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y9_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y9_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62c74e",
   "metadata": {},
   "source": [
    "# Train the Linear Discriminant Analysis (LDA) with train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a3461da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "applyLDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "x2_train = applyLDA.fit_transform(x_train, y_train)\n",
    "x2_test = applyLDA.transform(x_test)\n",
    "\n",
    "explained_variance = applyLDA.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b188e5c",
   "metadata": {},
   "source": [
    "# Random Forest with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbb6ecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 576 1455]\n",
      " [ 245 6724]]\n",
      "Outcome Values : \n",
      " 576 1455 245 6724\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.28      0.40      2031\n",
      "           0       0.82      0.96      0.89      6969\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.76      0.62      0.65      9000\n",
      "weighted avg       0.79      0.81      0.78      9000\n",
      "\n",
      "Accuracy : 81.1 %\n",
      "Precision : 70.2 %\n",
      "Recall : 28.4 %\n",
      "F1 Score : 0.404\n",
      "Balanced Accuracy : 62.4 %\n",
      "MCC 0.361\n",
      "roc_auc_score: 0.624\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest Classification model and train model using the training dataset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=2, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "                                 n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n",
    "                                 ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "modelRF = modelRF.fit(x2_train, y_train)\n",
    "\n",
    "# Predict the model with the test data set\n",
    "\n",
    "y10_pred = modelRF.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y10_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y10_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9ab3b",
   "metadata": {},
   "source": [
    "# Logistic Regression with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba4d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 680 1351]\n",
      " [ 311 6658]]\n",
      "Outcome Values : \n",
      " 680 1351 311 6658\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.33      0.45      2031\n",
      "           0       0.83      0.96      0.89      6969\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.76      0.65      0.67      9000\n",
      "weighted avg       0.80      0.82      0.79      9000\n",
      "\n",
      "Accuracy : 81.5 %\n",
      "Precision : 68.6 %\n",
      "Recall : 33.5 %\n",
      "F1 Score : 0.45\n",
      "Balanced Accuracy : 64.5 %\n",
      "MCC 0.388\n",
      "roc_auc_score: 0.645\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                            intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "                            n_jobs=None, penalty='l2', random_state=None,\n",
    "                            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x2_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y11_pred = modelLR.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y11_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y11_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5898822",
   "metadata": {},
   "source": [
    "# Decision Tree with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e656a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 669 1362]\n",
      " [1038 5931]]\n",
      "Outcome Values : \n",
      " 669 1362 1038 5931\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.33      0.36      2031\n",
      "           0       0.81      0.85      0.83      6969\n",
      "\n",
      "    accuracy                           0.73      9000\n",
      "   macro avg       0.60      0.59      0.59      9000\n",
      "weighted avg       0.72      0.73      0.72      9000\n",
      "\n",
      "Accuracy : 73.3 %\n",
      "Precision : 39.2 %\n",
      "Recall : 32.9 %\n",
      "F1 Score : 0.358\n",
      "Balanced Accuracy : 59.0 %\n",
      "MCC 0.192\n",
      "roc_auc_score: 0.59\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x2_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y12_pred = modelDT.predict(x2_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y12_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y12_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5f985",
   "metadata": {},
   "source": [
    "# SVM with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c96ccd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[1102  929]\n",
      " [ 932 6037]]\n",
      "Outcome Values : \n",
      " 1102 929 932 6037\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.54      0.54      2031\n",
      "           0       0.87      0.87      0.87      6969\n",
      "\n",
      "    accuracy                           0.79      9000\n",
      "   macro avg       0.70      0.70      0.70      9000\n",
      "weighted avg       0.79      0.79      0.79      9000\n",
      "\n",
      "Accuracy : 79.3 %\n",
      "Precision : 54.2 %\n",
      "Recall : 54.3 %\n",
      "F1 Score : 0.542\n",
      "Balanced Accuracy : 70.4 %\n",
      "MCC 0.409\n",
      "roc_auc_score: 0.704\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = 42, class_weight='balanced')\n",
    "\n",
    "modelSVMGaussian.fit(x2_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y13_pred = modelSVMGaussian.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y13_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y13_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68dc2c",
   "metadata": {},
   "source": [
    "# KNN with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f1441ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 648 1383]\n",
      " [ 458 6511]]\n",
      "Outcome Values : \n",
      " 648 1383 458 6511\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.32      0.41      2031\n",
      "           0       0.82      0.93      0.88      6969\n",
      "\n",
      "    accuracy                           0.80      9000\n",
      "   macro avg       0.71      0.63      0.64      9000\n",
      "weighted avg       0.77      0.80      0.77      9000\n",
      "\n",
      "Accuracy : 79.5 %\n",
      "Precision : 58.6 %\n",
      "Recall : 31.9 %\n",
      "F1 Score : 0.413\n",
      "Balanced Accuracy : 62.6 %\n",
      "MCC 0.323\n",
      "roc_auc_score: 0.627\n"
     ]
    }
   ],
   "source": [
    "# Build the algorithm with KNN\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "modelKNN = neighbors.KNeighborsClassifier(n_neighbors=5,weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                          metric='minkowski', metric_params=None, n_jobs=None)\n",
    "modelKNN.fit(x2_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y14_pred = modelKNN.predict(x2_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "predicted = y14_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual, predicted, labels=[1, 0], sample_weight=None, normalize=None,)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp,fn, fp, tn = confusion_matrix(actual, predicted, labels=[1,0]).reshape(-1)\n",
    "\n",
    "print('Outcome Values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report : \\n', matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision = round(tp/(tp+fp), 3)\n",
    "f1Score = round((2*tp/(2*tp + fp +fn)), 3);\n",
    "\n",
    "# Mathews Correlatin coefficient (MCC). Range of values of MCC lie between -1 to +1\n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "m = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "\n",
    "MCC = round(((tp* tn) - (fp * fn)) / sqrt(m), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2), '%')\n",
    "print('Precision :', round(precision*100, 2), '%')\n",
    "print('Recall :', round(sensitivity*100, 2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2), '%')\n",
    "print('MCC', MCC)\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y14_pred), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
