{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f5b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc145dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Num</th>\n",
       "      <th>Agent_Type</th>\n",
       "      <th>Q_Creation_DT</th>\n",
       "      <th>Q_Valid_DT</th>\n",
       "      <th>Policy_Bind_DT</th>\n",
       "      <th>Region</th>\n",
       "      <th>Agent_Num</th>\n",
       "      <th>Policy_Type</th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Range1</th>\n",
       "      <th>Sal_Range2</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Veh_Usage</th>\n",
       "      <th>Annual_Miles_Range</th>\n",
       "      <th>Vehicl_Cost_Range1</th>\n",
       "      <th>Vehicl_Cost_Range2</th>\n",
       "      <th>Re_Quote</th>\n",
       "      <th>Quoted_Premium</th>\n",
       "      <th>Policy_Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQ-C-139212</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/04/25</td>\n",
       "      <td>2020/06/23</td>\n",
       "      <td>2020/05/23</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>Car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 25 K &lt;= $ 40 K</td>\n",
       "      <td>&gt;  25 K &lt;=  40 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 55 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>693.86</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQ-F-136117</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2020/04/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2153</td>\n",
       "      <td>Van</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 7.5 K &amp; &lt;= 15 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>635.96</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ-F-126801</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/06/19</td>\n",
       "      <td>2020/08/17</td>\n",
       "      <td>2020/07/12</td>\n",
       "      <td>F</td>\n",
       "      <td>2056</td>\n",
       "      <td>Truck</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>780.64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQ-E-143467</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/05/02</td>\n",
       "      <td>2020/06/30</td>\n",
       "      <td>2020/05/24</td>\n",
       "      <td>E</td>\n",
       "      <td>2138</td>\n",
       "      <td>Car</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 90 K</td>\n",
       "      <td>&gt;  90 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&lt;= 7.5 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>723.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQ-C-143827</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/12</td>\n",
       "      <td>2020/04/11</td>\n",
       "      <td>2020/02/25</td>\n",
       "      <td>C</td>\n",
       "      <td>2327</td>\n",
       "      <td>Truck</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $ 25 K</td>\n",
       "      <td>&lt;=  25 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>738.14</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quote_Num Agent_Type Q_Creation_DT  Q_Valid_DT Policy_Bind_DT Region  \\\n",
       "0  AQ-C-139212         EA    2020/04/25  2020/06/23     2020/05/23      C   \n",
       "1  AQ-F-136117         EA    2020/02/21  2020/04/20            NaN      F   \n",
       "2  AQ-F-126801         EA    2020/06/19  2020/08/17     2020/07/12      F   \n",
       "3  AQ-E-143467         EA    2020/05/02  2020/06/30     2020/05/24      E   \n",
       "4  AQ-C-143827         EA    2020/02/12  2020/04/11     2020/02/25      C   \n",
       "\n",
       "   Agent_Num Policy_Type  HH_Vehicles  HH_Drivers  ...          Sal_Range1  \\\n",
       "0       2156         Car            3           3  ...  > $ 25 K <= $ 40 K   \n",
       "1       2153         Van            2           2  ...  > $ 40 K <= $ 60 K   \n",
       "2       2056       Truck            2           1  ...  > $ 40 K <= $ 60 K   \n",
       "3       2138         Car            1           2  ...           > $ 90 K    \n",
       "4       2327       Truck            3           1  ...           <= $ 25 K   \n",
       "\n",
       "         Sal_Range2  Coverage  Veh_Usage Annual_Miles_Range  \\\n",
       "0  >  25 K <=  40 K  Balanced    Commute             > 55 K   \n",
       "1  >  40 K <=  60 K  Balanced   Pleasure  > 7.5 K & <= 15 K   \n",
       "2  >  40 K <=  60 K     Basic    Commute   > 35 K & <= 45 K   \n",
       "3          >  90 K      Basic   Pleasure           <= 7.5 K   \n",
       "4          <=  25 K     Basic   Pleasure   > 35 K & <= 45 K   \n",
       "\n",
       "   Vehicl_Cost_Range1 Vehicl_Cost_Range2 Re_Quote Quoted_Premium Policy_Bind  \n",
       "0  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         693.86         Yes  \n",
       "1           <= $ 10 K           <=  10 K       No         635.96          No  \n",
       "2  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         780.64         Yes  \n",
       "3           <= $ 10 K           <=  10 K       No         723.15         Yes  \n",
       "4           <= $ 10 K           <=  10 K       No         738.14         Yes  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Auto Quote ins data\n",
    "\n",
    "AutoIns = pd.read_csv(r\"D:\\iiit notes\\Internship\\31 season 25th jun-2021\\Auto_Quote_Data_V2.0.csv\", header=0)\n",
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db510eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target varaible data type into integer\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('No', '0')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('Yes', '1')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbf22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 113757\n",
      "Class 1: 32502\n",
      "Proportion: 3.5 : 1\n",
      "Total Records: 146259\n"
     ]
    }
   ],
   "source": [
    "# Count the target or dependent varaible by '0' or '1' and\n",
    "# their proportion (> 10 : 1, then the dataset is imbalance dataset)\n",
    "\n",
    "Policy_Bind_count = AutoIns.Policy_Bind.value_counts()\n",
    "print('Class 0:', Policy_Bind_count[0])\n",
    "print('Class 1:', Policy_Bind_count[1])\n",
    "print('Proportion:', round(Policy_Bind_count[0]/ Policy_Bind_count[1], 2), ': 1')\n",
    "print('Total Records:', len(AutoIns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e112241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146259 entries, 0 to 146258\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Quote_Num           146259 non-null  object \n",
      " 1   Agent_Type          146259 non-null  object \n",
      " 2   Q_Creation_DT       146259 non-null  object \n",
      " 3   Q_Valid_DT          146259 non-null  object \n",
      " 4   Policy_Bind_DT      32502 non-null   object \n",
      " 5   Region              146259 non-null  object \n",
      " 6   Agent_Num           146259 non-null  int64  \n",
      " 7   Policy_Type         146259 non-null  object \n",
      " 8   HH_Vehicles         146259 non-null  int64  \n",
      " 9   HH_Drivers          146259 non-null  int64  \n",
      " 10  Driver_Age          146259 non-null  int64  \n",
      " 11  Driving_Exp         146259 non-null  int64  \n",
      " 12  Prev_Accidents      146259 non-null  int64  \n",
      " 13  Prev_Citations      146259 non-null  int64  \n",
      " 14  Gender              146259 non-null  object \n",
      " 15  Marital_Status      146259 non-null  object \n",
      " 16  Education           146259 non-null  object \n",
      " 17  Sal_Range1          146259 non-null  object \n",
      " 18  Sal_Range2          146259 non-null  object \n",
      " 19  Coverage            146259 non-null  object \n",
      " 20  Veh_Usage           146259 non-null  object \n",
      " 21  Annual_Miles_Range  146259 non-null  object \n",
      " 22  Vehicl_Cost_Range1  146259 non-null  object \n",
      " 23  Vehicl_Cost_Range2  146259 non-null  object \n",
      " 24  Re_Quote            146259 non-null  object \n",
      " 25  Quoted_Premium      146259 non-null  float64\n",
      " 26  Policy_Bind         146259 non-null  int32  \n",
      "dtypes: float64(1), int32(1), int64(7), object(18)\n",
      "memory usage: 29.6+ MB\n"
     ]
    }
   ],
   "source": [
    "AutoIns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a63e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and new column as 'QP_Range' from 'Quoted_premium'\n",
    "\n",
    "AutoIns['QP_Range'] = pd.cut(AutoIns['Quoted_Premium'], [0, 800, 1000, 1200, 9999],\n",
    "                             labels = ['0-800', '801-1000', '1001-1200', '>1200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930c5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the varaibles which are not impacting the target variable\n",
    "\n",
    "AutoIns = AutoIns.drop(['Quote_Num', 'Agent_Num', 'Q_Creation_DT',\n",
    "                        'Q_Valid_DT', 'Policy_Bind_DT', 'Sal_Range1',\n",
    "                        'Vehicl_Cost_Range1', 'Quoted_Premium'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8ddb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoIns = pd.get_dummies(AutoIns, columns=['Agent_Type','Region', 'Policy_Type', 'Gender', 'Marital_Status', 'Education',\n",
    "                                          'Sal_Range2', 'Coverage', 'Veh_Usage', 'Annual_Miles_Range', 'Vehicl_Cost_Range2',\n",
    "                                          'Re_Quote', 'QP_Range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e21019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>Driver_Age</th>\n",
       "      <th>Driving_Exp</th>\n",
       "      <th>Prev_Accidents</th>\n",
       "      <th>Prev_Citations</th>\n",
       "      <th>Policy_Bind</th>\n",
       "      <th>Agent_Type_EA</th>\n",
       "      <th>Agent_Type_IA</th>\n",
       "      <th>Region_A</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  10 K &lt;=  20 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  20 K &lt;=  30 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  30 K &lt;=  40 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  40 K</th>\n",
       "      <th>Re_Quote_No</th>\n",
       "      <th>Re_Quote_Yes</th>\n",
       "      <th>QP_Range_0-800</th>\n",
       "      <th>QP_Range_801-1000</th>\n",
       "      <th>QP_Range_1001-1200</th>\n",
       "      <th>QP_Range_&gt;1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HH_Vehicles  HH_Drivers  Driver_Age  Driving_Exp  Prev_Accidents  \\\n",
       "0            3           3          43           26               0   \n",
       "1            2           2          30           13               0   \n",
       "2            2           1          25            8               0   \n",
       "3            1           2          43           26               0   \n",
       "4            3           1          40           23               0   \n",
       "\n",
       "   Prev_Citations  Policy_Bind  Agent_Type_EA  Agent_Type_IA  Region_A  ...  \\\n",
       "0               0            1              1              0         0  ...   \n",
       "1               0            0              1              0         0  ...   \n",
       "2               0            1              1              0         0  ...   \n",
       "3               0            1              1              0         0  ...   \n",
       "4               0            1              1              0         0  ...   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  10 K <=  20 K  Vehicl_Cost_Range2_>  20 K <=  30 K  \\\n",
       "0                                    1                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    1                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  30 K <=  40 K  Vehicl_Cost_Range2_>  40 K   \\\n",
       "0                                    0                            0   \n",
       "1                                    0                            0   \n",
       "2                                    0                            0   \n",
       "3                                    0                            0   \n",
       "4                                    0                            0   \n",
       "\n",
       "   Re_Quote_No  Re_Quote_Yes  QP_Range_0-800  QP_Range_801-1000  \\\n",
       "0            1             0               1                  0   \n",
       "1            1             0               1                  0   \n",
       "2            1             0               1                  0   \n",
       "3            1             0               1                  0   \n",
       "4            1             0               1                  0   \n",
       "\n",
       "   QP_Range_1001-1200  QP_Range_>1200  \n",
       "0                   0               0  \n",
       "1                   0               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3429df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar =[]\n",
    "for col in AutoIns.columns:\n",
    "    if col != 'Policy_Bind':\n",
    "        IndepVar.append(col)\n",
    "        \n",
    "TargetVar = 'Policy_Bind'\n",
    "x = AutoIns[IndepVar]\n",
    "y = AutoIns[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7557f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1ff68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146259 entries, 0 to 146258\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                Non-Null Count   Dtype\n",
      "---  ------                                --------------   -----\n",
      " 0   HH_Vehicles                           146259 non-null  int64\n",
      " 1   HH_Drivers                            146259 non-null  int64\n",
      " 2   Driver_Age                            146259 non-null  int64\n",
      " 3   Driving_Exp                           146259 non-null  int64\n",
      " 4   Prev_Accidents                        146259 non-null  int64\n",
      " 5   Prev_Citations                        146259 non-null  int64\n",
      " 6   Policy_Bind                           146259 non-null  int32\n",
      " 7   Agent_Type_EA                         146259 non-null  uint8\n",
      " 8   Agent_Type_IA                         146259 non-null  uint8\n",
      " 9   Region_A                              146259 non-null  uint8\n",
      " 10  Region_B                              146259 non-null  uint8\n",
      " 11  Region_C                              146259 non-null  uint8\n",
      " 12  Region_D                              146259 non-null  uint8\n",
      " 13  Region_E                              146259 non-null  uint8\n",
      " 14  Region_F                              146259 non-null  uint8\n",
      " 15  Region_G                              146259 non-null  uint8\n",
      " 16  Region_H                              146259 non-null  uint8\n",
      " 17  Policy_Type_Car                       146259 non-null  uint8\n",
      " 18  Policy_Type_Truck                     146259 non-null  uint8\n",
      " 19  Policy_Type_Van                       146259 non-null  uint8\n",
      " 20  Gender_Female                         146259 non-null  uint8\n",
      " 21  Gender_Male                           146259 non-null  uint8\n",
      " 22  Marital_Status_Dirvorced              146259 non-null  uint8\n",
      " 23  Marital_Status_Married                146259 non-null  uint8\n",
      " 24  Marital_Status_Single                 146259 non-null  uint8\n",
      " 25  Marital_Status_Widow                  146259 non-null  uint8\n",
      " 26  Education_Bachelors                   146259 non-null  uint8\n",
      " 27  Education_College                     146259 non-null  uint8\n",
      " 28  Education_High School                 146259 non-null  uint8\n",
      " 29  Education_Masters                     146259 non-null  uint8\n",
      " 30  Education_Ph.D                        146259 non-null  uint8\n",
      " 31  Sal_Range2_<=  25 K                   146259 non-null  uint8\n",
      " 32  Sal_Range2_>  25 K <=  40 K           146259 non-null  uint8\n",
      " 33  Sal_Range2_>  40 K <=  60 K           146259 non-null  uint8\n",
      " 34  Sal_Range2_>  60 K <=  90 K           146259 non-null  uint8\n",
      " 35  Sal_Range2_>  90 K                    146259 non-null  uint8\n",
      " 36  Coverage_Balanced                     146259 non-null  uint8\n",
      " 37  Coverage_Basic                        146259 non-null  uint8\n",
      " 38  Coverage_Enhanced                     146259 non-null  uint8\n",
      " 39  Veh_Usage_Business                    146259 non-null  uint8\n",
      " 40  Veh_Usage_Commute                     146259 non-null  uint8\n",
      " 41  Veh_Usage_Pleasure                    146259 non-null  uint8\n",
      " 42  Annual_Miles_Range_<= 7.5 K           146259 non-null  uint8\n",
      " 43  Annual_Miles_Range_> 15 K & <= 25 K   146259 non-null  uint8\n",
      " 44  Annual_Miles_Range_> 25 K & <= 35 K   146259 non-null  uint8\n",
      " 45  Annual_Miles_Range_> 35 K & <= 45 K   146259 non-null  uint8\n",
      " 46  Annual_Miles_Range_> 45 K & <= 55 K   146259 non-null  uint8\n",
      " 47  Annual_Miles_Range_> 55 K             146259 non-null  uint8\n",
      " 48  Annual_Miles_Range_> 7.5 K & <= 15 K  146259 non-null  uint8\n",
      " 49  Vehicl_Cost_Range2_<=  10 K           146259 non-null  uint8\n",
      " 50  Vehicl_Cost_Range2_>  10 K <=  20 K   146259 non-null  uint8\n",
      " 51  Vehicl_Cost_Range2_>  20 K <=  30 K   146259 non-null  uint8\n",
      " 52  Vehicl_Cost_Range2_>  30 K <=  40 K   146259 non-null  uint8\n",
      " 53  Vehicl_Cost_Range2_>  40 K            146259 non-null  uint8\n",
      " 54  Re_Quote_No                           146259 non-null  uint8\n",
      " 55  Re_Quote_Yes                          146259 non-null  uint8\n",
      " 56  QP_Range_0-800                        146259 non-null  uint8\n",
      " 57  QP_Range_801-1000                     146259 non-null  uint8\n",
      " 58  QP_Range_1001-1200                    146259 non-null  uint8\n",
      " 59  QP_Range_>1200                        146259 non-null  uint8\n",
      "dtypes: int32(1), int64(6), uint8(53)\n",
      "memory usage: 14.6 MB\n"
     ]
    }
   ],
   "source": [
    "AutoIns.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5dfb7",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f5542",
   "metadata": {},
   "source": [
    "# Decision Tree with random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9248962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as 'Scaling'\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train['Driver_Age'] = sc.fit_transform(x_train['Driver_Age'].values.reshape(-1, 1))\n",
    "x_train['Driving_Exp'] = sc.fit_transform(x_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "x_test['Driver_Age'] = sc.fit_transform(x_test['Driver_Age'].values.reshape(-1, 1)) \n",
    "x_test['Driving_Exp'] = sc.fit_transform(x_test['Driving_Exp'].values.reshape(-1, 1)) \n",
    "# Convert to dataframe x_train = pd.DataFrame(x_train) x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3e0d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the decision tree model with random sampling \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "AutoInsDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, \n",
    "                                   max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                   min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                                   min_weight_fraction_leaf=0.0, random_state=None, splitter='best') \n",
    "AutoInsDT = AutoInsDT.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c767eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set \n",
    "\n",
    "y_pred = AutoInsDT.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a0f9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25378  8684]\n",
      " [ 7366  2450]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76     34062\n",
      "           1       0.22      0.25      0.23      9816\n",
      "\n",
      "    accuracy                           0.63     43878\n",
      "   macro avg       0.50      0.50      0.50     43878\n",
      "weighted avg       0.65      0.63      0.64     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdec641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.42 %\n",
      "Precision: 22.0 %\n",
      "Recall: 24.96 %\n",
      "f1-score: 23.39 %\n",
      "roc_auc_score: 0.497\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "# Model Accuracy: how often is the classifier correct? \n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such? \n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred) * 100, 2)), '%') \n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such? \n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall \n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred) * 100, 2)), '%') \n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d9da0",
   "metadata": {},
   "source": [
    "# Decision tree over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4197c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227514, 59)\n",
      "(227514,)\n"
     ]
    }
   ],
   "source": [
    "# Random oversampling can be implemented using the RandomOverSampler class\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "x_over, y_over = oversample.fit_resample(x, y)\n",
    "print(x_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891600a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146259, 59)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee674363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113757\n",
       "1    113757\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know the count of major and minor classes\n",
    "\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e95b997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xo_train, xo_test, yo_train, yo_test = train_test_split(x_over, y_over, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b648b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#x_train = sc.fit_transform(x_train)\n",
    "#x_test = sc.fit_transform(x_test)\n",
    "\n",
    "xo_train['Driver_Age'] = sc.fit_transform(xo_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_train['Driving_Exp'] = sc.fit_transform(xo_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xo_test['Driver_Age'] = sc.fit_transform(xo_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_test['Driving_Exp'] = sc.fit_transform(xo_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xo_train = pd.DataFrame(xo_train)\n",
    "xo_test = pd.DataFrame(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c654d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under Sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_O = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                      max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                      min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                      random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_O = AutoInsDT_O.fit(xo_train, yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a7d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yo_pred = AutoInsDT_O.predict(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f20c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23984 10093]\n",
      " [ 2052 32126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80     34077\n",
      "           1       0.76      0.94      0.84     34178\n",
      "\n",
      "    accuracy                           0.82     68255\n",
      "   macro avg       0.84      0.82      0.82     68255\n",
      "weighted avg       0.84      0.82      0.82     68255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report \n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e19c7bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.21 %\n",
      "Precision: 76.09 %\n",
      "Recall: 94.0 %\n",
      "f1-score: 84.1 %\n",
      "roc_auc_score: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f69525",
   "metadata": {},
   "source": [
    "# Combining Under & Oversampling - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a98fb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193386, 59)\n",
      "(193386,)\n",
      "(193384, 59)\n",
      "(193384,)\n"
     ]
    }
   ],
   "source": [
    "# Combining Random Oversampling and Undersampling \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define oversampling strategy\n",
    "\n",
    "over = RandomOverSampler(sampling_strategy=0.70)\n",
    "\n",
    "# fit and apply the transform\n",
    "\n",
    "x2, y2 = over.fit_resample(x,y)\n",
    "print(x2.shape)\n",
    "print(y2.shape)\n",
    "\n",
    "# define undersampling strategy\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=0.70)\n",
    "\n",
    "# fit and apply the transform\n",
    "\n",
    "x3, y3 = under.fit_resample(x2, y2)\n",
    "\n",
    "print(x3.shape)\n",
    "print(y3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c4dd20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113755\n",
       "1     79629\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6864237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xc_train, xc_test, yc_train, yc_test = train_test_split(x3, y3, test_size = 0.30, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3393c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xc_train['Driver_Age'] = sc.fit_transform(xc_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_train['Driving_Exp'] = sc.fit_transform(xc_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xc_test['Driver_Age'] = sc.fit_transform(xc_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_test['Driving_Exp'] = sc.fit_transform(xc_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xc_train = pd.DataFrame(xc_train)\n",
    "xc_test = pd.DataFrame(xc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7128b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_C = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                     max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                     min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                     random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_C = AutoInsDT_C.fit(xc_train,yc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79883e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yc_pred = AutoInsDT_C.predict(xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "885793fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24504  9500]\n",
      " [ 3568 20444]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79     34004\n",
      "           1       0.68      0.85      0.76     24012\n",
      "\n",
      "    accuracy                           0.77     58016\n",
      "   macro avg       0.78      0.79      0.77     58016\n",
      "weighted avg       0.79      0.77      0.78     58016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8669290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.48 %\n",
      "Precision: 68.27 %\n",
      "Recall: 85.14 %\n",
      "f1-score: 75.78 %\n",
      "roc_auc_score: 0.786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800229dc",
   "metadata": {},
   "source": [
    "# Under sampling -Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4c409be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65004, 59)\n",
      "(65004,)\n"
     ]
    }
   ],
   "source": [
    "# undersampling \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "x_under, y_under = under.fit_resample(x, y)\n",
    "\n",
    "print(x_under.shape)\n",
    "print(y_under.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab3682b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32502\n",
       "1    32502\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efb40edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xu_train, xu_test, yu_train, yu_test = train_test_split(x_under, y_under, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80f3ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as ‘Scaling’\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xu_train['Driver_Age'] = sc.fit_transform(xu_train['Driver_Age'].values.reshape(-1,1))\n",
    "xu_train['Driving_Exp'] = sc.fit_transform(xu_train['Driving_Exp'].values.reshape(-1,1))\n",
    "xu_train['Driver_Age'] = sc.fit_transform(xu_train['Driver_Age'].values.reshape(-1,1))\n",
    "xu_train['Driving_Exp'] = sc.fit_transform(xu_train['Driving_Exp'].values.reshape(-1,1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xu_train =  pd.DataFrame(xu_train)\n",
    "xu_test = pd.DataFrame(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "486f5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_C = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "                                     min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                     random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                     min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
    "\n",
    "AutoInsDT_C = AutoInsDT_C.fit(xu_train, yu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9142376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yu_pred = AutoInsDT_C.predict(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76f26aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4511 5242]\n",
      " [4506 5243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48      9753\n",
      "           1       0.50      0.54      0.52      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classification report \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd23a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.48 %\n",
      "Precision: 68.27 %\n",
      "Recall: 85.14 %\n",
      "f1-score: 75.78 %\n",
      "roc_auc_score: 0.786\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b01c03",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf483a7",
   "metadata": {},
   "source": [
    "# Randomforest with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46e157aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33740   337]\n",
      " [ 2904 31274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     34077\n",
      "           1       0.99      0.92      0.95     34178\n",
      "\n",
      "    accuracy                           0.95     68255\n",
      "   macro avg       0.96      0.95      0.95     68255\n",
      "weighted avg       0.96      0.95      0.95     68255\n",
      "\n",
      "Accuracy: 95.25 %\n",
      "Precision: 95.25 %\n",
      "Recall: 95.25 %\n",
      "f1-score: 95.25 %\n",
      "roc_auc_score: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_O = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_O = AutoInsRF_O.fit(xo_train, yo_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsRF_O.predict(xo_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c804ff5",
   "metadata": {},
   "source": [
    "# RandomForest with Combined Over sampling and Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a6d4755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33857   147]\n",
      " [ 5069 18943]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     34004\n",
      "           1       0.99      0.79      0.88     24012\n",
      "\n",
      "    accuracy                           0.91     58016\n",
      "   macro avg       0.93      0.89      0.90     58016\n",
      "weighted avg       0.92      0.91      0.91     58016\n",
      "\n",
      "Accuracy: 91.01 %\n",
      "Precision: 91.01 %\n",
      "Recall: 91.01 %\n",
      "f1-score: 91.01 %\n",
      "roc_auc_score: 0.892\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_C = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_C = AutoInsRF_C.fit(xc_train, yc_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsRF_C.predict(xc_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e304f2e4",
   "metadata": {},
   "source": [
    "# RandomForest with Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30ac41c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3207 6546]\n",
      " [3204 6545]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40      9753\n",
      "           1       0.50      0.67      0.57      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.48     19502\n",
      "weighted avg       0.50      0.50      0.48     19502\n",
      "\n",
      "Accuracy: 50.01 %\n",
      "Precision: 50.01 %\n",
      "Recall: 50.01 %\n",
      "f1-score: 50.01 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_C = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_C = AutoInsRF_C.fit(xu_train, yu_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yu_pred = AutoInsRF_C.predict(xu_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287a590",
   "metadata": {},
   "source": [
    "# RandomForest with randam sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da276f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34051    11]\n",
      " [ 9812     4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34062\n",
      "           1       0.27      0.00      0.00      9816\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.52      0.50      0.44     43878\n",
      "weighted avg       0.66      0.78      0.68     43878\n",
      "\n",
      "Accuracy: 77.61 %\n",
      "Precision: 77.61 %\n",
      "Recall: 77.61 %\n",
      "f1-score: 77.61 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_C = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_C = AutoInsRF_C.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "    \n",
    "y_pred = AutoInsRF_C.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model performance by mtrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd49b6c",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b493046",
   "metadata": {},
   "source": [
    "# Oversampling - Logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b48b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16977 17100]\n",
      " [16729 17449]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50     34077\n",
      "           1       0.51      0.51      0.51     34178\n",
      "\n",
      "    accuracy                           0.50     68255\n",
      "   macro avg       0.50      0.50      0.50     68255\n",
      "weighted avg       0.50      0.50      0.50     68255\n",
      "\n",
      "Accuracy: 50.44 %\n",
      "Precision: 50.44 %\n",
      "Recall: 50.44 %\n",
      "f1-score: 50.44 %\n",
      "roc_auc_score: 0.504\n"
     ]
    }
   ],
   "source": [
    "# To bulid the 'Logistic Regression' model with oversampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_O = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "AutoInsLR_O = AutoInsLR_O.fit(xo_train,yo_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsLR_O.predict(xo_test)\n",
    "\n",
    "# Display the confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2684ee",
   "metadata": {},
   "source": [
    "# Combining under - Over sampling Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e79d1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34004     0]\n",
      " [24012     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74     34004\n",
      "           1       0.00      0.00      0.00     24012\n",
      "\n",
      "    accuracy                           0.59     58016\n",
      "   macro avg       0.29      0.50      0.37     58016\n",
      "weighted avg       0.34      0.59      0.43     58016\n",
      "\n",
      "Accuracy: 58.61 %\n",
      "Precision: 58.61 %\n",
      "Recall: 58.61 %\n",
      "f1-score: 58.61 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_C = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR_C = AutoInsLR_C.fit(xc_train,yc_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsLR_C.predict(xc_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc0ad7",
   "metadata": {},
   "source": [
    "# Under sampling with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56faff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14 9739]\n",
      " [  18 9731]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.00      0.00      9753\n",
      "           1       0.50      1.00      0.67      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.47      0.50      0.33     19502\n",
      "weighted avg       0.47      0.50      0.33     19502\n",
      "\n",
      "Accuracy: 49.97 %\n",
      "Precision: 49.97 %\n",
      "Recall: 49.97 %\n",
      "f1-score: 49.97 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_U = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "AutoInsLR_U = AutoInsLR_U.fit(xu_train,yu_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yu_pred = AutoInsLR_U.predict(xu_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef5870",
   "metadata": {},
   "source": [
    "# Ramdom sampling with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "373d21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34062     0]\n",
      " [ 9816     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34062\n",
      "           1       0.00      0.00      0.00      9816\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n",
      "Accuracy: 77.63 %\n",
      "Precision: 77.63 %\n",
      "Recall: 77.63 %\n",
      "f1-score: 77.63 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR = AutoInsLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y_pred = AutoInsLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b4f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
