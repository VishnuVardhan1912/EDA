{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e94d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the labraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "# Ignore harmless warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2947da93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Num</th>\n",
       "      <th>Agent_Type</th>\n",
       "      <th>Q_Creation_DT</th>\n",
       "      <th>Q_Valid_DT</th>\n",
       "      <th>Policy_Bind_DT</th>\n",
       "      <th>Region</th>\n",
       "      <th>Agent_Num</th>\n",
       "      <th>Policy_Type</th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Range1</th>\n",
       "      <th>Sal_Range2</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Veh_Usage</th>\n",
       "      <th>Annual_Miles_Range</th>\n",
       "      <th>Vehicl_Cost_Range1</th>\n",
       "      <th>Vehicl_Cost_Range2</th>\n",
       "      <th>Re_Quote</th>\n",
       "      <th>Quoted_Premium</th>\n",
       "      <th>Policy_Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQ-C-139212</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/04/25</td>\n",
       "      <td>2020/06/23</td>\n",
       "      <td>2020/05/23</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>Car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 25 K &lt;= $ 40 K</td>\n",
       "      <td>&gt;  25 K &lt;=  40 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 55 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>693.86</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQ-F-136117</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2020/04/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2153</td>\n",
       "      <td>Van</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 7.5 K &amp; &lt;= 15 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>635.96</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ-F-126801</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/06/19</td>\n",
       "      <td>2020/08/17</td>\n",
       "      <td>2020/07/12</td>\n",
       "      <td>F</td>\n",
       "      <td>2056</td>\n",
       "      <td>Truck</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>780.64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQ-E-143467</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/05/02</td>\n",
       "      <td>2020/06/30</td>\n",
       "      <td>2020/05/24</td>\n",
       "      <td>E</td>\n",
       "      <td>2138</td>\n",
       "      <td>Car</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 90 K</td>\n",
       "      <td>&gt;  90 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&lt;= 7.5 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>723.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQ-C-143827</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/12</td>\n",
       "      <td>2020/04/11</td>\n",
       "      <td>2020/02/25</td>\n",
       "      <td>C</td>\n",
       "      <td>2327</td>\n",
       "      <td>Truck</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $ 25 K</td>\n",
       "      <td>&lt;=  25 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>738.14</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quote_Num Agent_Type Q_Creation_DT  Q_Valid_DT Policy_Bind_DT Region  \\\n",
       "0  AQ-C-139212         EA    2020/04/25  2020/06/23     2020/05/23      C   \n",
       "1  AQ-F-136117         EA    2020/02/21  2020/04/20            NaN      F   \n",
       "2  AQ-F-126801         EA    2020/06/19  2020/08/17     2020/07/12      F   \n",
       "3  AQ-E-143467         EA    2020/05/02  2020/06/30     2020/05/24      E   \n",
       "4  AQ-C-143827         EA    2020/02/12  2020/04/11     2020/02/25      C   \n",
       "\n",
       "   Agent_Num Policy_Type  HH_Vehicles  HH_Drivers  ...          Sal_Range1  \\\n",
       "0       2156         Car            3           3  ...  > $ 25 K <= $ 40 K   \n",
       "1       2153         Van            2           2  ...  > $ 40 K <= $ 60 K   \n",
       "2       2056       Truck            2           1  ...  > $ 40 K <= $ 60 K   \n",
       "3       2138         Car            1           2  ...           > $ 90 K    \n",
       "4       2327       Truck            3           1  ...           <= $ 25 K   \n",
       "\n",
       "         Sal_Range2  Coverage  Veh_Usage Annual_Miles_Range  \\\n",
       "0  >  25 K <=  40 K  Balanced    Commute             > 55 K   \n",
       "1  >  40 K <=  60 K  Balanced   Pleasure  > 7.5 K & <= 15 K   \n",
       "2  >  40 K <=  60 K     Basic    Commute   > 35 K & <= 45 K   \n",
       "3          >  90 K      Basic   Pleasure           <= 7.5 K   \n",
       "4          <=  25 K     Basic   Pleasure   > 35 K & <= 45 K   \n",
       "\n",
       "   Vehicl_Cost_Range1 Vehicl_Cost_Range2 Re_Quote Quoted_Premium Policy_Bind  \n",
       "0  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         693.86         Yes  \n",
       "1           <= $ 10 K           <=  10 K       No         635.96          No  \n",
       "2  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         780.64         Yes  \n",
       "3           <= $ 10 K           <=  10 K       No         723.15         Yes  \n",
       "4           <= $ 10 K           <=  10 K       No         738.14         Yes  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Auto Quote ins data\n",
    "\n",
    "AutoIns = pd.read_csv(r\"D:\\iiit notes\\Internship\\31 season 25th jun-2021\\Auto_Quote_Data_V2.0.csv\", header = 0)\n",
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b206204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target variable data type into interger \n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('Yes', '1') \n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('No', '0') \n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b4d4b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 113757\n",
      "Class 1: 32502\n",
      "Proportion: 3.5 : 1\n",
      "Total Records: 146259\n"
     ]
    }
   ],
   "source": [
    "# Count the target or dependent variable by '0' & '1' and\n",
    "# their proportion (> 10 : 1, then the dataset is imbalance dataset)\n",
    "\n",
    "Policy_Bind_count = AutoIns.Policy_Bind.value_counts()\n",
    "print('Class 0:', Policy_Bind_count[0])\n",
    "print('Class 1:', Policy_Bind_count[1])\n",
    "print('Proportion:', round(Policy_Bind_count[0] / Policy_Bind_count[1], 2), ': 1')\n",
    "print('Total Records:', len(AutoIns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d4fb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146259 entries, 0 to 146258\n",
      "Data columns (total 27 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Quote_Num           146259 non-null  object \n",
      " 1   Agent_Type          146259 non-null  object \n",
      " 2   Q_Creation_DT       146259 non-null  object \n",
      " 3   Q_Valid_DT          146259 non-null  object \n",
      " 4   Policy_Bind_DT      32502 non-null   object \n",
      " 5   Region              146259 non-null  object \n",
      " 6   Agent_Num           146259 non-null  int64  \n",
      " 7   Policy_Type         146259 non-null  object \n",
      " 8   HH_Vehicles         146259 non-null  int64  \n",
      " 9   HH_Drivers          146259 non-null  int64  \n",
      " 10  Driver_Age          146259 non-null  int64  \n",
      " 11  Driving_Exp         146259 non-null  int64  \n",
      " 12  Prev_Accidents      146259 non-null  int64  \n",
      " 13  Prev_Citations      146259 non-null  int64  \n",
      " 14  Gender              146259 non-null  object \n",
      " 15  Marital_Status      146259 non-null  object \n",
      " 16  Education           146259 non-null  object \n",
      " 17  Sal_Range1          146259 non-null  object \n",
      " 18  Sal_Range2          146259 non-null  object \n",
      " 19  Coverage            146259 non-null  object \n",
      " 20  Veh_Usage           146259 non-null  object \n",
      " 21  Annual_Miles_Range  146259 non-null  object \n",
      " 22  Vehicl_Cost_Range1  146259 non-null  object \n",
      " 23  Vehicl_Cost_Range2  146259 non-null  object \n",
      " 24  Re_Quote            146259 non-null  object \n",
      " 25  Quoted_Premium      146259 non-null  float64\n",
      " 26  Policy_Bind         146259 non-null  int32  \n",
      "dtypes: float64(1), int32(1), int64(7), object(18)\n",
      "memory usage: 29.6+ MB\n"
     ]
    }
   ],
   "source": [
    "AutoIns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb796e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and new column as 'QP_Range' from 'Quoted_premium' \n",
    "AutoIns['QP_Range'] = pd.cut(AutoIns['Quoted_Premium'], [0, 800, 1000, 1200, 9999], \n",
    "                             labels=['0-800', '801-1000', '1001-1200', '>1200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767da0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables which are not impacting the target variable \n",
    "\n",
    "AutoIns = AutoIns.drop(['Quote_Num', 'Agent_Num', 'Q_Creation_DT', \n",
    "                        'Q_Valid_DT', 'Policy_Bind_DT', 'Sal_Range1', \n",
    "                        'Vehicl_Cost_Range1', 'Quoted_Premium'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967e4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoIns = pd.get_dummies(AutoIns, columns=['Agent_Type', 'Region', 'Policy_Type', 'Gender', 'Marital_Status', 'Education', \n",
    "                                           'Sal_Range2', 'Coverage', 'Veh_Usage', 'Annual_Miles_Range', 'Vehicl_Cost_Range2', \n",
    "                                           'Re_Quote', 'QP_Range']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5e1080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>Driver_Age</th>\n",
       "      <th>Driving_Exp</th>\n",
       "      <th>Prev_Accidents</th>\n",
       "      <th>Prev_Citations</th>\n",
       "      <th>Policy_Bind</th>\n",
       "      <th>Agent_Type_EA</th>\n",
       "      <th>Agent_Type_IA</th>\n",
       "      <th>Region_A</th>\n",
       "      <th>...</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  10 K &lt;=  20 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  20 K &lt;=  30 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  30 K &lt;=  40 K</th>\n",
       "      <th>Vehicl_Cost_Range2_&gt;  40 K</th>\n",
       "      <th>Re_Quote_No</th>\n",
       "      <th>Re_Quote_Yes</th>\n",
       "      <th>QP_Range_0-800</th>\n",
       "      <th>QP_Range_801-1000</th>\n",
       "      <th>QP_Range_1001-1200</th>\n",
       "      <th>QP_Range_&gt;1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HH_Vehicles  HH_Drivers  Driver_Age  Driving_Exp  Prev_Accidents  \\\n",
       "0            3           3          43           26               0   \n",
       "1            2           2          30           13               0   \n",
       "2            2           1          25            8               0   \n",
       "3            1           2          43           26               0   \n",
       "4            3           1          40           23               0   \n",
       "\n",
       "   Prev_Citations  Policy_Bind  Agent_Type_EA  Agent_Type_IA  Region_A  ...  \\\n",
       "0               0            1              1              0         0  ...   \n",
       "1               0            0              1              0         0  ...   \n",
       "2               0            1              1              0         0  ...   \n",
       "3               0            1              1              0         0  ...   \n",
       "4               0            1              1              0         0  ...   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  10 K <=  20 K  Vehicl_Cost_Range2_>  20 K <=  30 K  \\\n",
       "0                                    1                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    1                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "\n",
       "   Vehicl_Cost_Range2_>  30 K <=  40 K  Vehicl_Cost_Range2_>  40 K   \\\n",
       "0                                    0                            0   \n",
       "1                                    0                            0   \n",
       "2                                    0                            0   \n",
       "3                                    0                            0   \n",
       "4                                    0                            0   \n",
       "\n",
       "   Re_Quote_No  Re_Quote_Yes  QP_Range_0-800  QP_Range_801-1000  \\\n",
       "0            1             0               1                  0   \n",
       "1            1             0               1                  0   \n",
       "2            1             0               1                  0   \n",
       "3            1             0               1                  0   \n",
       "4            1             0               1                  0   \n",
       "\n",
       "   QP_Range_1001-1200  QP_Range_>1200  \n",
       "0                   0               0  \n",
       "1                   0               0  \n",
       "2                   0               0  \n",
       "3                   0               0  \n",
       "4                   0               0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef34ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables \n",
    "IndepVar = [] \n",
    "for col in AutoIns.columns: \n",
    "    if col != 'Policy_Bind': \n",
    "        IndepVar.append(col) \n",
    "        \n",
    "TargetVar = 'Policy_Bind' \n",
    "x = AutoIns[IndepVar] \n",
    "y = AutoIns[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f1279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab94087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the \n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™ \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "\n",
    "x_train['Driver_Age'] = sc.fit_transform(x_train['Driver_Age'].values.reshape(-1, 1)) \n",
    "x_train['Driving_Exp'] = sc.fit_transform(x_train['Driving_Exp'].values.reshape(-1, 1)) \n",
    "x_test['Driver_Age'] = sc.fit_transform(x_test['Driver_Age'].values.reshape(-1, 1)) \n",
    "x_test['Driving_Exp'] = sc.fit_transform(x_test['Driving_Exp'].values.reshape(-1, 1)) \n",
    "# Convert to dataframe x_train = pd.DataFrame(x_train) x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c4d55e",
   "metadata": {},
   "source": [
    "# Decision tree over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5385f746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227514, 59)\n",
      "(227514,)\n"
     ]
    }
   ],
   "source": [
    "# Random oversampling can be implemented using the RandomOverSampler class\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "x_over, y_over = oversample.fit_resample(x, y)\n",
    "print(x_over.shape)\n",
    "print(y_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426a2c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113757\n",
       "1    113757\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know the count of major and minor classes\n",
    "\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336b81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xo_train, xo_test, yo_train, yo_test = train_test_split(x_over, y_over, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36fb59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#x_train = sc.fit_transform(x_train)\n",
    "#x_test = sc.fit_transform(x_test)\n",
    "\n",
    "xo_train['Driver_Age'] = sc.fit_transform(xo_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_train['Driving_Exp'] = sc.fit_transform(xo_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xo_test['Driver_Age'] = sc.fit_transform(xo_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xo_test['Driving_Exp'] = sc.fit_transform(xo_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xo_train = pd.DataFrame(xo_train)\n",
    "xo_test = pd.DataFrame(xo_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cce50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_O = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_O = AutoInsDT_O.fit(xo_train,yo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b93a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yo_pred = AutoInsDT_O.predict(xo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3234e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24176  9901]\n",
      " [ 2033 32145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80     34077\n",
      "           1       0.76      0.94      0.84     34178\n",
      "\n",
      "    accuracy                           0.83     68255\n",
      "   macro avg       0.84      0.82      0.82     68255\n",
      "weighted avg       0.84      0.83      0.82     68255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c019a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.52 %\n",
      "Precision: 76.45 %\n",
      "Recall: 94.05 %\n",
      "f1-score: 84.34 %\n",
      "roc_auc_score: 0.825\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8814a8e",
   "metadata": {},
   "source": [
    "# Combining Under & Oversampling - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6a359a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193386, 59)\n",
      "(193386,)\n",
      "(193384, 59)\n",
      "(193384,)\n"
     ]
    }
   ],
   "source": [
    "# Combining Random Oversampling and Undersampling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define oversampling strategy\n",
    "\n",
    "over = RandomOverSampler(sampling_strategy=0.70)\n",
    "\n",
    "# fit and apply the transform\n",
    "\n",
    "x2, y2 = over.fit_resample(x, y)\n",
    "print(x2.shape)\n",
    "print(y2.shape)\n",
    "\n",
    "# define undersampling strategy\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=0.70)\n",
    "\n",
    "# fit and apply the transform\n",
    "\n",
    "x3, y3 = under.fit_resample(x2, y2)\n",
    "\n",
    "print(x3.shape)\n",
    "print(y3.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f75e89e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113755\n",
       "1     79629\n",
       "Name: Policy_Bind, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67b7e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xc_train, xc_test, yc_train, yc_test = train_test_split(x3, y3, test_size = 0.30, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcd87ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xc_train['Driver_Age'] = sc.fit_transform(xc_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_train['Driving_Exp'] = sc.fit_transform(xc_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xc_test['Driver_Age'] = sc.fit_transform(xc_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xc_test['Driving_Exp'] = sc.fit_transform(xc_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xc_train = pd.DataFrame(xc_train)\n",
    "xc_test = pd.DataFrame(xc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "652caeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_C = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                     max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                     min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                     random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_C = AutoInsDT_C.fit(xc_train,yc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e4783b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with test data\n",
    "\n",
    "yc_pred = AutoInsDT_C.predict(xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be916360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24141  9863]\n",
      " [ 3495 20517]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78     34004\n",
      "           1       0.68      0.85      0.75     24012\n",
      "\n",
      "    accuracy                           0.77     58016\n",
      "   macro avg       0.77      0.78      0.77     58016\n",
      "weighted avg       0.79      0.77      0.77     58016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a41dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.98 %\n",
      "Precision: 67.53 %\n",
      "Recall: 85.44 %\n",
      "f1-score: 75.44 %\n",
      "roc_auc_score: 0.782\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f6cc6d",
   "metadata": {},
   "source": [
    "# Randomforest with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccce975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33711   366]\n",
      " [ 2795 31383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     34077\n",
      "           1       0.99      0.92      0.95     34178\n",
      "\n",
      "    accuracy                           0.95     68255\n",
      "   macro avg       0.96      0.95      0.95     68255\n",
      "weighted avg       0.96      0.95      0.95     68255\n",
      "\n",
      "Accuracy: 95.37 %\n",
      "Precision: 95.37 %\n",
      "Recall: 95.37 %\n",
      "f1-score: 95.37 %\n",
      "roc_auc_score: 0.954\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_O = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_O = AutoInsRF_O.fit(xo_train, yo_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsRF_O.predict(xo_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c83f5",
   "metadata": {},
   "source": [
    "# RandomForest with Combined Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e1ce486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33829   175]\n",
      " [ 4931 19081]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     34004\n",
      "           1       0.99      0.79      0.88     24012\n",
      "\n",
      "    accuracy                           0.91     58016\n",
      "   macro avg       0.93      0.89      0.91     58016\n",
      "weighted avg       0.92      0.91      0.91     58016\n",
      "\n",
      "Accuracy: 91.2 %\n",
      "Precision: 91.2 %\n",
      "Recall: 91.2 %\n",
      "f1-score: 91.2 %\n",
      "roc_auc_score: 0.895\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF_C = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=None, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF_C = AutoInsRF_C.fit(xc_train, yc_train)\n",
    "\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsRF_C.predict(xc_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eda368",
   "metadata": {},
   "source": [
    "# RandomForest with Under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d376e",
   "metadata": {},
   "source": [
    "# Oversampling - Logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1d16a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16657 17420]\n",
      " [16567 17611]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.50     34077\n",
      "           1       0.50      0.52      0.51     34178\n",
      "\n",
      "    accuracy                           0.50     68255\n",
      "   macro avg       0.50      0.50      0.50     68255\n",
      "weighted avg       0.50      0.50      0.50     68255\n",
      "\n",
      "Accuracy: 50.21 %\n",
      "Precision: 50.21 %\n",
      "Recall: 50.21 %\n",
      "f1-score: 50.21 %\n",
      "roc_auc_score: 0.502\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_O = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR_O = AutoInsLR_O.fit(xo_train,yo_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yo_pred = AutoInsLR_O.predict(xo_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yo_test, yo_pred))\n",
    "print(classification_report(yo_test, yo_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yo_test, yo_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yo_test, yo_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yo_test, yo_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yo_test, yo_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b941537",
   "metadata": {},
   "source": [
    "# Combining under - Over sampling Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358d5180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34004     0]\n",
      " [24012     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74     34004\n",
      "           1       0.00      0.00      0.00     24012\n",
      "\n",
      "    accuracy                           0.59     58016\n",
      "   macro avg       0.29      0.50      0.37     58016\n",
      "weighted avg       0.34      0.59      0.43     58016\n",
      "\n",
      "Accuracy: 58.61 %\n",
      "Precision: 58.61 %\n",
      "Recall: 58.61 %\n",
      "f1-score: 58.61 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_C = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR_C = AutoInsLR_C.fit(xc_train,yc_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yc_pred = AutoInsLR_C.predict(xc_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yc_test, yc_pred))\n",
    "print(classification_report(yc_test, yc_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yc_test, yc_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yc_test, yc_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yc_test, yc_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yc_test, yc_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc3ec2",
   "metadata": {},
   "source": [
    "# Random sampling- Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bfc3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34062     0]\n",
      " [ 9816     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34062\n",
      "           1       0.00      0.00      0.00      9816\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n",
      "Accuracy: 77.63 %\n",
      "Precision: 77.63 %\n",
      "Recall: 77.63 %\n",
      "f1-score: 77.63 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "criterion='gini', max_depth=3, max_features='auto',\n",
    "max_leaf_nodes=None, max_samples=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "warm_start=False)\n",
    "AutoInsRF = AutoInsRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y_pred = AutoInsRF.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5820c3",
   "metadata": {},
   "source": [
    "# Under sampling with Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17c4eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65004, 59)\n",
      "(65004,)\n"
     ]
    }
   ],
   "source": [
    "# Random undersampling to balance the class distribution\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "x_under, y_under = undersample.fit_resample(x, y)\n",
    "print(x_under.shape)\n",
    "print(y_under.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5457f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xu_train, xu_test, yu_train, yu_test = train_test_split(x_under, y_under, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36a648ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#x_train = sc.fit_transform(x_train)\n",
    "#x_test = sc.fit_transform(x_test)\n",
    "\n",
    "xu_train['Driver_Age'] = sc.fit_transform(xu_train['Driver_Age'].values.reshape(-1, 1))\n",
    "xu_train['Driving_Exp'] = sc.fit_transform(xu_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "xu_test['Driver_Age'] = sc.fit_transform(xu_test['Driver_Age'].values.reshape(-1, 1))\n",
    "xu_test['Driving_Exp'] = sc.fit_transform(xu_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "xu_train = pd.DataFrame(xu_train)\n",
    "xu_test = pd.DataFrame(xu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d770763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4844 4909]\n",
      " [4913 4836]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50      9753\n",
      "           1       0.50      0.50      0.50      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n",
      "Accuracy: 49.64 %\n",
      "Precision: 49.63 %\n",
      "Recall: 49.61 %\n",
      "f1-score: 49.62 %\n",
      "roc_auc_score: 0.496\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Under sampling\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "AutoInsDT_U = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "random_state=None, splitter='best')\n",
    "\n",
    "AutoInsDT_U = AutoInsDT_U.fit(xu_train,yu_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "yu_pred = AutoInsDT_U.predict(xu_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c40580c",
   "metadata": {},
   "source": [
    "# Logistic with random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1013dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34062     0]\n",
      " [ 9816     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34062\n",
      "           1       0.00      0.00      0.00      9816\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n",
      "Accuracy: 77.63 %\n",
      "Precision: 77.63 %\n",
      "Recall: 77.63 %\n",
      "f1-score: 77.63 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR = AutoInsLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y_pred = AutoInsLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b4cd0",
   "metadata": {},
   "source": [
    "# Under sampling with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9883b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4765 4988]\n",
      " [4766 4983]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.49      9753\n",
      "           1       0.50      0.51      0.51      9749\n",
      "\n",
      "    accuracy                           0.50     19502\n",
      "   macro avg       0.50      0.50      0.50     19502\n",
      "weighted avg       0.50      0.50      0.50     19502\n",
      "\n",
      "Accuracy: 49.98 %\n",
      "Precision: 49.98 %\n",
      "Recall: 49.98 %\n",
      "f1-score: 49.98 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR_U = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR_U = AutoInsLR_U.fit(xu_train,yu_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "yu_pred = AutoInsLR_U.predict(xu_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(yu_test, yu_pred))\n",
    "print(classification_report(yu_test, yu_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(yu_test, yu_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(yu_test, yu_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(yu_test, yu_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(yu_test, yu_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddea5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
