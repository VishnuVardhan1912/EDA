{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Version     :  0.26\n",
      "Scikit-Learn Version :  0.24.1\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries (Bagging to compare with other algorithms)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandasql as psql\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "import catboost\n",
    "import sklearn\n",
    "\n",
    "print(\"CatBoost Version     : \", catboost.__version__)\n",
    "print(\"Scikit-Learn Version : \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 CatBoostClassifier (Binary Classification- Breast Cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>TumorType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  TumorType  \n",
       "0                  0.11890          0  \n",
       "1                  0.08902          0  \n",
       "2                  0.08758          0  \n",
       "3                  0.17300          0  \n",
       "4                  0.07678          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the power dataset \n",
    "\n",
    "cancer = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\54 Season 06- Aug - 2021\\breast_cancer.csv\", header=0) \n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  TumorType                569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Display the informationof dataset\n",
    "\n",
    "cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                456\n",
       "mean texture               479\n",
       "mean perimeter             522\n",
       "mean area                  539\n",
       "mean smoothness            474\n",
       "mean compactness           537\n",
       "mean concavity             537\n",
       "mean concave points        542\n",
       "mean symmetry              432\n",
       "mean fractal dimension     499\n",
       "radius error               540\n",
       "texture error              519\n",
       "perimeter error            533\n",
       "area error                 528\n",
       "smoothness error           547\n",
       "compactness error          541\n",
       "concavity error            533\n",
       "concave points error       507\n",
       "symmetry error             498\n",
       "fractal dimension error    545\n",
       "worst radius               457\n",
       "worst texture              511\n",
       "worst perimeter            514\n",
       "worst area                 544\n",
       "worst smoothness           411\n",
       "worst compactness          529\n",
       "worst concavity            539\n",
       "worst concave points       492\n",
       "worst symmetry             500\n",
       "worst fractal dimension    535\n",
       "TumorType                    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the unique variables count\n",
    "\n",
    "cancer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the independent and Target (dependent) variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in cancer.columns:\n",
    "    if col != 'TumorType':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'TumorType'\n",
    "\n",
    "x = cancer[IndepVar]\n",
    "y = cancer[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test (random sampling)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.071029\n",
      "0:\tlearn: 0.5802440\ttest: 0.5747794\tbest: 0.5747794 (0)\ttotal: 163ms\tremaining: 16.1s\n",
      "10:\tlearn: 0.1660307\ttest: 0.2030804\tbest: 0.2030804 (10)\ttotal: 223ms\tremaining: 1.81s\n",
      "20:\tlearn: 0.0828724\ttest: 0.1386198\tbest: 0.1386198 (20)\ttotal: 264ms\tremaining: 991ms\n",
      "30:\tlearn: 0.0526912\ttest: 0.1200316\tbest: 0.1189766 (29)\ttotal: 303ms\tremaining: 674ms\n",
      "40:\tlearn: 0.0370860\ttest: 0.1182461\tbest: 0.1177638 (38)\ttotal: 343ms\tremaining: 494ms\n",
      "50:\tlearn: 0.0286951\ttest: 0.1141475\tbest: 0.1141475 (50)\ttotal: 385ms\tremaining: 370ms\n",
      "60:\tlearn: 0.0225550\ttest: 0.1108169\tbest: 0.1108169 (60)\ttotal: 432ms\tremaining: 276ms\n",
      "70:\tlearn: 0.0177588\ttest: 0.1057340\tbest: 0.1054750 (69)\ttotal: 473ms\tremaining: 193ms\n",
      "80:\tlearn: 0.0147118\ttest: 0.1048690\tbest: 0.1034080 (75)\ttotal: 516ms\tremaining: 121ms\n",
      "90:\tlearn: 0.0117803\ttest: 0.1026150\tbest: 0.1026150 (90)\ttotal: 556ms\tremaining: 55ms\n",
      "99:\tlearn: 0.0098104\ttest: 0.1016773\tbest: 0.1016773 (99)\ttotal: 592ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1016772593\n",
      "bestIteration = 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier is used for classification problems\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import eval_metric\n",
    "\n",
    "modelCBC = CatBoostClassifier(iterations=100, verbose=10)\n",
    "modelCBC.fit(x_train, y_train, eval_set=(x_test, y_test))\n",
    "modelCBC.set_feature_names(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[71  1]\n",
      " [ 4 38]]\n",
      "Outcome values : \n",
      " 71 1 4 38\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.99      0.97        72\n",
      "           0       0.97      0.90      0.94        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy : 95.6 %\n",
      "Precision : 94.7 %\n",
      "Recall : 98.6 %\n",
      "F1 Score : 0.966\n",
      "Balanced Accuracy : 94.6 %\n",
      "MCC : 0.906\n",
      "roc_auc_score: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Predict the model with test data\n",
    "\n",
    "y_pred = modelCBC.predict(x_test, prediction_type=\"Class\")\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998874</td>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.999116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991099</td>\n",
       "      <td>0.008901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.798194</td>\n",
       "      <td>0.201806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998459</td>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.998874  0.001126\n",
       "1  0.000884  0.999116\n",
       "2  0.991099  0.008901\n",
       "3  0.798194  0.201806\n",
       "4  0.998459  0.001541"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelCBC.predict(x_test, prediction_type=\"Probability\")\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 CatBoostClassifier (Binary Classification- Universal Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Universal bank data\n",
    "\n",
    "bankdata = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\54 Season 06- Aug - 2021\\Universalbank.csv\", header=0) \n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the columns which are not influencing the target variable\n",
    "\n",
    "del bankdata['ID']\n",
    "del bankdata['ZIP Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'Education']\n"
     ]
    }
   ],
   "source": [
    "# cols1 is variables - crating a dummy variables\n",
    "\n",
    "cols1 = ['Family', 'Education']\n",
    "print(cols1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n"
     ]
    }
   ],
   "source": [
    "# cols2 variables - MinMaxScalar function\n",
    "\n",
    "cols2 = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n",
    "print(cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAvg</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mortgage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Securities Account</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD Account</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditCard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0     1     2      3     4\n",
       "Age                 25.0  45.0  39.0   35.0  35.0\n",
       "Experience           1.0  19.0  15.0    9.0   8.0\n",
       "Income              49.0  34.0  11.0  100.0  45.0\n",
       "CCAvg                1.6   1.5   1.0    2.7   1.0\n",
       "Mortgage             0.0   0.0   0.0    0.0   0.0\n",
       "Personal Loan        0.0   0.0   0.0    0.0   0.0\n",
       "Securities Account   1.0   1.0   0.0    0.0   0.0\n",
       "CD Account           0.0   0.0   0.0    0.0   0.0\n",
       "Online               0.0   0.0   0.0    0.0   0.0\n",
       "CreditCard           0.0   0.0   0.0    0.0   1.0\n",
       "Family_1             0.0   0.0   1.0    1.0   0.0\n",
       "Family_2             0.0   0.0   0.0    0.0   0.0\n",
       "Family_3             0.0   1.0   0.0    0.0   0.0\n",
       "Family_4             1.0   0.0   0.0    0.0   1.0\n",
       "Education_1          1.0   1.0   1.0    0.0   0.0\n",
       "Education_2          0.0   0.0   0.0    1.0   1.0\n",
       "Education_3          0.0   0.0   0.0    0.0   0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for all range values\n",
    "\n",
    "bankdata = pd.get_dummies(bankdata, columns=cols1)\n",
    "bankdata.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in bankdata.columns:\n",
    "    if col != 'CreditCard':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'CreditCard'\n",
    "\n",
    "x = bankdata[IndepVar]\n",
    "y = bankdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)\n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train[cols2] = mmscaler.fit_transform(x_train[cols2])\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "x_test[cols2] = mmscaler.fit_transform(x_test[cols2])\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.117569\n",
      "0:\tlearn: 0.6688767\ttest: 0.6689791\tbest: 0.6689791 (0)\ttotal: 11.3ms\tremaining: 1.12s\n",
      "10:\tlearn: 0.5752120\ttest: 0.5741743\tbest: 0.5741743 (10)\ttotal: 51.7ms\tremaining: 418ms\n",
      "20:\tlearn: 0.5559594\ttest: 0.5587001\tbest: 0.5587001 (20)\ttotal: 75.1ms\tremaining: 283ms\n",
      "30:\tlearn: 0.5458331\ttest: 0.5522780\tbest: 0.5522780 (30)\ttotal: 97.8ms\tremaining: 218ms\n",
      "40:\tlearn: 0.5382652\ttest: 0.5508575\tbest: 0.5508575 (40)\ttotal: 122ms\tremaining: 175ms\n",
      "50:\tlearn: 0.5325087\ttest: 0.5509150\tbest: 0.5505809 (43)\ttotal: 144ms\tremaining: 139ms\n",
      "60:\tlearn: 0.5274023\ttest: 0.5506267\tbest: 0.5504443 (59)\ttotal: 168ms\tremaining: 107ms\n",
      "70:\tlearn: 0.5211665\ttest: 0.5493396\tbest: 0.5492185 (69)\ttotal: 192ms\tremaining: 78.3ms\n",
      "80:\tlearn: 0.5163161\ttest: 0.5482259\tbest: 0.5482259 (80)\ttotal: 214ms\tremaining: 50.1ms\n",
      "90:\tlearn: 0.5115173\ttest: 0.5480243\tbest: 0.5477751 (83)\ttotal: 235ms\tremaining: 23.3ms\n",
      "99:\tlearn: 0.5084671\ttest: 0.5482613\tbest: 0.5476852 (94)\ttotal: 254ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5476852198\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier is used for classification problems\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import eval_metric\n",
    "\n",
    "modelCBC = CatBoostClassifier(iterations=100, verbose=10)\n",
    "modelCBC.fit(x_train, y_train, eval_set=(x_test, y_test))\n",
    "modelCBC.set_feature_names(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  69  358]\n",
      " [  11 1062]]\n",
      "Outcome values : \n",
      " 69 358 11 1062\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.16      0.27       427\n",
      "           0       0.75      0.99      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.81      0.58      0.56      1500\n",
      "weighted avg       0.78      0.75      0.69      1500\n",
      "\n",
      "Accuracy : 75.4 %\n",
      "Precision : 86.2 %\n",
      "Recall : 16.2 %\n",
      "F1 Score : 0.272\n",
      "Balanced Accuracy : 57.6 %\n",
      "MCC : 0.304\n",
      "roc_auc_score: 0.576\n"
     ]
    }
   ],
   "source": [
    "# Predict the model with test data\n",
    "\n",
    "y1_pred = modelCBC.predict(x_test, prediction_type=\"Class\")\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y1_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[112 315]\n",
      " [109 964]]\n",
      "Outcome values : \n",
      " 112 315 109 964\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.26      0.35       427\n",
      "           0       0.75      0.90      0.82      1073\n",
      "\n",
      "    accuracy                           0.72      1500\n",
      "   macro avg       0.63      0.58      0.58      1500\n",
      "weighted avg       0.68      0.72      0.68      1500\n",
      "\n",
      "Accuracy : 71.7 %\n",
      "Precision : 50.7 %\n",
      "Recall : 26.2 %\n",
      "F1 Score : 0.346\n",
      "Balanced Accuracy : 58.0 %\n",
      "MCC : 0.205\n",
      "roc_auc_score: 0.58\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                 criterion='entropy', max_depth=None, max_features='auto',\n",
    "                                 max_leaf_nodes=None, max_samples=None,\n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                 min_samples_leaf=1, min_samples_split=2,\n",
    "                                 min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                                 n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                 warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y2_pred = modelRF.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y2_pred \n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  71  356]\n",
      " [  17 1056]]\n",
      "Outcome values : \n",
      " 71 356 17 1056\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.17      0.28       427\n",
      "           0       0.75      0.98      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.78      0.58      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy : 75.1 %\n",
      "Precision : 80.7 %\n",
      "Recall : 16.6 %\n",
      "F1 Score : 0.276\n",
      "Balanced Accuracy : 57.5 %\n",
      "MCC : 0.289\n",
      "roc_auc_score: 0.575\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                             intercept_scaling=1, max_iter=100, multi_class='auto', \n",
    "                             n_jobs=None, penalty='l2', random_state=None,\n",
    "                             solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y3_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[127 300]\n",
      " [161 912]]\n",
      "Outcome values : \n",
      " 127 300 161 912\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.30      0.36       427\n",
      "           0       0.75      0.85      0.80      1073\n",
      "\n",
      "    accuracy                           0.69      1500\n",
      "   macro avg       0.60      0.57      0.58      1500\n",
      "weighted avg       0.66      0.69      0.67      1500\n",
      "\n",
      "Accuracy : 69.3 %\n",
      "Precision : 44.1 %\n",
      "Recall : 29.7 %\n",
      "F1 Score : 0.355\n",
      "Balanced Accuracy : 57.4 %\n",
      "MCC : 0.169\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To build the 'KNN' model \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "modelKNN = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                                p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "\n",
    "modelKNN = modelKNN.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y4_pred = modelKNN.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y4_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC Algorithm - Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  67  360]\n",
      " [  10 1063]]\n",
      "Outcome values : \n",
      " 67 360 10 1063\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.16      0.27       427\n",
      "           0       0.75      0.99      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.81      0.57      0.56      1500\n",
      "weighted avg       0.78      0.75      0.68      1500\n",
      "\n",
      "Accuracy : 75.3 %\n",
      "Precision : 87.0 %\n",
      "Recall : 15.7 %\n",
      "F1 Score : 0.266\n",
      "Balanced Accuracy : 57.4 %\n",
      "MCC : 0.302\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = None, class_weight=None,probability=True)\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y5_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y5_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3))\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[180 247]\n",
      " [298 775]]\n",
      "Outcome values : \n",
      " 180 247 298 775\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.42      0.40       427\n",
      "           0       0.76      0.72      0.74      1073\n",
      "\n",
      "    accuracy                           0.64      1500\n",
      "   macro avg       0.57      0.57      0.57      1500\n",
      "weighted avg       0.65      0.64      0.64      1500\n",
      "\n",
      "Accuracy : 63.7 %\n",
      "Precision : 37.7 %\n",
      "Recall : 42.2 %\n",
      "F1 Score : 0.398\n",
      "Balanced Accuracy : 57.2 %\n",
      "MCC : 0.139\n",
      "roc_auc_score: 0.572\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                 max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                 min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                 random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y6_pred = modelDT.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test\n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y6_pred\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "# calculating the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3);\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "precision = round(tp/(tp+fp), 3);\n",
    "f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "print('Precision :', round(precision*100, 2),'%')\n",
    "print('Recall :', round(sensitivity*100,2), '%')\n",
    "print('F1 Score :', f1Score)\n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "print('MCC :', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3))\n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 CatBoostClassifier (Multi-Class Classification- Wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>WineType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6        127           2.80   \n",
       "1    13.20        1.78  2.14               11.2        100           2.65   \n",
       "2    13.16        2.36  2.67               18.6        101           2.80   \n",
       "3    14.37        1.95  2.50               16.8        113           3.85   \n",
       "4    13.24        2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  WineType  \n",
       "0                          3.92     1065         0  \n",
       "1                          3.40     1050         0  \n",
       "2                          3.17     1185         0  \n",
       "3                          3.45     1480         0  \n",
       "4                          2.93      735         0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the power dataset \n",
    "\n",
    "wine = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\54 Season 06- Aug - 2021\\wine.csv\", header=0) \n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    int64  \n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    int64  \n",
      " 13  WineType                      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "# display the dataset information\n",
    "\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         126\n",
       "malic_acid                      133\n",
       "ash                              79\n",
       "alcalinity_of_ash                63\n",
       "magnesium                        53\n",
       "total_phenols                    97\n",
       "flavanoids                      132\n",
       "nonflavanoid_phenols             39\n",
       "proanthocyanins                 101\n",
       "color_intensity                 132\n",
       "hue                              78\n",
       "od280/od315_of_diluted_wines    122\n",
       "proline                         121\n",
       "WineType                          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of unique values count in each variable\n",
    "\n",
    "wine.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the independent and Target (dependent) variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in wine.columns:\n",
    "    if col != 'WineType':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'WineType'\n",
    "\n",
    "x = wine[IndepVar]\n",
    "y = wine[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (36, 13), (142,), (36,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test (random sampling)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train = mmscaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "x_test = mmscaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.25025\n",
      "0:\tlearn: 0.8960927\ttest: 0.9271398\tbest: 0.9271398 (0)\ttotal: 10.6ms\tremaining: 1.05s\n",
      "10:\tlearn: 0.2251739\ttest: 0.3357200\tbest: 0.3357200 (10)\ttotal: 52ms\tremaining: 421ms\n",
      "20:\tlearn: 0.1054355\ttest: 0.2135149\tbest: 0.2135149 (20)\ttotal: 76.3ms\tremaining: 287ms\n",
      "30:\tlearn: 0.0607644\ttest: 0.1503188\tbest: 0.1503188 (30)\ttotal: 98.8ms\tremaining: 220ms\n",
      "40:\tlearn: 0.0414391\ttest: 0.1245208\tbest: 0.1245208 (40)\ttotal: 122ms\tremaining: 176ms\n",
      "50:\tlearn: 0.0313093\ttest: 0.1109000\tbest: 0.1109000 (50)\ttotal: 144ms\tremaining: 138ms\n",
      "60:\tlearn: 0.0243438\ttest: 0.0967912\tbest: 0.0967912 (60)\ttotal: 169ms\tremaining: 108ms\n",
      "70:\tlearn: 0.0202625\ttest: 0.0896527\tbest: 0.0896527 (70)\ttotal: 191ms\tremaining: 78ms\n",
      "80:\tlearn: 0.0173385\ttest: 0.0857718\tbest: 0.0857718 (80)\ttotal: 213ms\tremaining: 50ms\n",
      "90:\tlearn: 0.0151734\ttest: 0.0793006\tbest: 0.0793006 (90)\ttotal: 233ms\tremaining: 23.1ms\n",
      "99:\tlearn: 0.0136719\ttest: 0.0774022\tbest: 0.0774022 (99)\ttotal: 251ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.07740218118\n",
      "bestIteration = 99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoostClassifier is used for multiclass classification problems\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost.utils import eval_metric\n",
    "\n",
    "modelCBMC = CatBoostClassifier(iterations=100, verbose=10)\n",
    "modelCBMC.fit(x_train, y_train, eval_set=(x_test, y_test))\n",
    "modelCBMC.set_feature_names(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 10]]\n",
      "Print Class: 0\n",
      "TP=11, FP=0, TN=24, FN=1\n",
      "Accuracy: 0.972\n",
      "Precision: 1.0\n",
      "Sensitivity: 0.917\n",
      "F1-Score: 0.957\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.958\n",
      "MCC: 0.938\n",
      "\n",
      "Print Class: 1\n",
      "TP=14, FP=1, TN=21, FN=0\n",
      "Accuracy: 0.972\n",
      "Precision: 0.933\n",
      "Sensitivity: 1.0\n",
      "F1-Score: 0.966\n",
      "Specificity: 0.955\n",
      "Balanced Accuracy: 0.978\n",
      "MCC: 0.944\n",
      "\n",
      "Print Class: 2\n",
      "TP=10, FP=0, TN=26, FN=0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Sensitivity: 1.0\n",
      "F1-Score: 1.0\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 1.0\n",
      "MCC: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict model with test data \n",
    "\n",
    "y7_pred = modelCBMC.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "\n",
    "print(confusion_matrix(y7_pred, y_test)) # Verticle is actual values & horizontal is predicted values\n",
    "\n",
    "# Actual and predicted classes\n",
    "\n",
    "lst_actual_class = y_test\n",
    "lst_predicted_class = y7_pred\n",
    "\n",
    "# Class = Label 0-3\n",
    "\n",
    "lst_classes = [0, 1, 2]\n",
    "\n",
    "# Compute multi-class confusion matrix\n",
    "\n",
    "arr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n",
    "\n",
    "# Temp store results\n",
    "\n",
    "model_acc = [];\n",
    "model_recall = [];\n",
    "model_prec = [];\n",
    "model_fscore = [];\n",
    "model_spec = [];\n",
    "model_bal_acc = [];\n",
    "model_mcc = [];\n",
    "for no_class in range(len(lst_classes)):\n",
    "    arr_data = arr_out_matrix[no_class];\n",
    "    print(\"Print Class: {0}\".format(no_class));\n",
    "\n",
    "    tp = arr_data[1][1]\n",
    "    fp = arr_data[0][1]\n",
    "    tn = arr_data[0][0]\n",
    "    fn = arr_data[1][0]\n",
    "    \n",
    "    sensitivity = round(tp/(tp+fn), 3);\n",
    "    specificity = round(tn/(tn+fp), 3);\n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "    precision = round(tp/(tp+fp), 3);\n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "    \n",
    "    x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "    model_acc.append(accuracy);\n",
    "    model_prec.append(precision);\n",
    "    model_recall.append(sensitivity);\n",
    "    model_fscore.append(f1Score);\n",
    "    model_spec.append(specificity);\n",
    "    model_bal_acc.append(balanced_accuracy);\n",
    "    model_mcc.append(MCC);\n",
    "    \n",
    "    print(\"TP={0}, FP={1}, TN={2}, FN={3}\".format(tp, fp, tn, fn));\n",
    "    print(\"Accuracy: {0}\".format(accuracy));    # Accuracy score\n",
    "    print(\"Precision: {0}\".format(precision)); # Precision score\n",
    "    print(\"Sensitivity: {0}\".format(sensitivity)); # Recall score\n",
    "    print(\"F1-Score: {0}\".format(f1Score)); # F1 score\n",
    "    print(\"Specificity: {0}\".format(specificity)); # True Nagative Rate\n",
    "    print(\"Balanced Accuracy: {0}\".format(balanced_accuracy)); # Balance accuracy score\n",
    "    print(\"MCC: {0}\\n\".format(MCC)); # Matthews Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Prediction:\n",
      "Accuracy: 98.1333%\n",
      "Precision: 97.7667%\n",
      "Recall or Sensitivity: 97.2333%\n",
      "F1-Score: 0.9743\n",
      "Specificity or True Nagative Rate: 98.5%\n",
      "Balanced Accuracy: 97.8667%\n",
      "\n",
      "MCC: 0.9607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OVERALL - FINAL PREDICTION PERFORMANCE\n",
    "\n",
    "# importing mean() \n",
    "\n",
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "print(\"Overall Performance Prediction:\");\n",
    "print(\"Accuracy: {0}%\".format(round(mean(model_acc)*100, 4)));\n",
    "print(\"Precision: {0}%\".format(round(mean(model_prec)*100, 4)));\n",
    "print(\"Recall or Sensitivity: {0}%\".format(round(mean(model_recall)*100, 4)));\n",
    "print(\"F1-Score: {0}\".format(round(mean(model_fscore), 4)));\n",
    "print(\"Specificity or True Nagative Rate: {0}%\".format(round(mean(model_spec)*100, 4)));\n",
    "print(\"Balanced Accuracy: {0}%\\n\".format(round(mean(model_bal_acc)*100, 4)));\n",
    "print(\"MCC: {0}\\n\".format(round(mean(model_mcc), 4)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 1 14  0]\n",
      " [ 0  0 10]]\n",
      "Print Class: 0\n",
      "TP=11, FP=0, TN=24, FN=1\n",
      "Accuracy: 0.972\n",
      "Precision: 1.0\n",
      "Sensitivity: 0.917\n",
      "F1-Score: 0.957\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 0.958\n",
      "MCC: 0.938\n",
      "\n",
      "Print Class: 1\n",
      "TP=14, FP=1, TN=21, FN=0\n",
      "Accuracy: 0.972\n",
      "Precision: 0.933\n",
      "Sensitivity: 1.0\n",
      "F1-Score: 0.966\n",
      "Specificity: 0.955\n",
      "Balanced Accuracy: 0.978\n",
      "MCC: 0.944\n",
      "\n",
      "Print Class: 2\n",
      "TP=10, FP=0, TN=26, FN=0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Sensitivity: 1.0\n",
      "F1-Score: 1.0\n",
      "Specificity: 1.0\n",
      "Balanced Accuracy: 1.0\n",
      "MCC: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelRF = RandomForestClassifier(criterion='gini', n_estimators=100, random_state=0)\n",
    "\n",
    "modelRF.fit(x_train,y_train)\n",
    "\n",
    "# Predict model with test data \n",
    "\n",
    "y8_pred =modelRF.predict(x_test)\n",
    "y8_pred_proba = modelRF.predict_proba(x_test)\n",
    "\n",
    "# confusion matrix in sklearn\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from math import sqrt\n",
    "\n",
    "print(confusion_matrix(y8_pred, y_test)) # Verticle is actual values & horizontal is predicted values\n",
    "\n",
    "# Actual and predicted classes\n",
    "\n",
    "lst_actual_class = y_test\n",
    "lst_predicted_class = y8_pred\n",
    "\n",
    "# Class = Label 0-3\n",
    "\n",
    "lst_classes = [0, 1, 2]\n",
    "\n",
    "# Compute multi-class confusion matrix\n",
    "\n",
    "arr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n",
    "\n",
    "# Temp store results\n",
    "\n",
    "model_acc = [];\n",
    "model_recall = [];\n",
    "model_prec = [];\n",
    "model_fscore = [];\n",
    "model_spec = [];\n",
    "model_bal_acc = [];\n",
    "model_mcc = [];\n",
    "for no_class in range(len(lst_classes)):\n",
    "    arr_data = arr_out_matrix[no_class];\n",
    "    print(\"Print Class: {0}\".format(no_class));\n",
    "\n",
    "    tp = arr_data[1][1]\n",
    "    fp = arr_data[0][1]\n",
    "    tn = arr_data[0][0]\n",
    "    fn = arr_data[1][0]\n",
    "    \n",
    "    sensitivity = round(tp/(tp+fn), 3);\n",
    "    specificity = round(tn/(tn+fp), 3);\n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "    precision = round(tp/(tp+fp), 3);\n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "    \n",
    "    x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n",
    "    model_acc.append(accuracy);\n",
    "    model_prec.append(precision);\n",
    "    model_recall.append(sensitivity);\n",
    "    model_fscore.append(f1Score);\n",
    "    model_spec.append(specificity);\n",
    "    model_bal_acc.append(balanced_accuracy);\n",
    "    model_mcc.append(MCC);\n",
    "    \n",
    "    print(\"TP={0}, FP={1}, TN={2}, FN={3}\".format(tp, fp, tn, fn));\n",
    "    print(\"Accuracy: {0}\".format(accuracy));    # Accuracy score\n",
    "    print(\"Precision: {0}\".format(precision)); # Precision score\n",
    "    print(\"Sensitivity: {0}\".format(sensitivity)); # Recall score\n",
    "    print(\"F1-Score: {0}\".format(f1Score)); # F1 score\n",
    "    print(\"Specificity: {0}\".format(specificity)); # True Nagative Rate\n",
    "    print(\"Balanced Accuracy: {0}\".format(balanced_accuracy)); # Balance accuracy score\n",
    "    print(\"MCC: {0}\\n\".format(MCC)); # Matthews Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Prediction:\n",
      "Accuracy: 98.1333%\n",
      "Precision: 97.7667%\n",
      "Recall or Sensitivity: 97.2333%\n",
      "F1-Score: 0.9743\n",
      "Specificity or True Nagative Rate: 98.5%\n",
      "Balanced Accuracy: 97.8667%\n",
      "\n",
      "MCC: 0.9607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OVERALL - FINAL PREDICTION PERFORMANCE\n",
    "\n",
    "# importing mean() \n",
    "\n",
    "from statistics import mean\n",
    "import math\n",
    "\n",
    "print(\"Overall Performance Prediction:\");\n",
    "print(\"Accuracy: {0}%\".format(round(mean(model_acc)*100, 4)));\n",
    "print(\"Precision: {0}%\".format(round(mean(model_prec)*100, 4)));\n",
    "print(\"Recall or Sensitivity: {0}%\".format(round(mean(model_recall)*100, 4)));\n",
    "print(\"F1-Score: {0}\".format(round(mean(model_fscore), 4)));\n",
    "print(\"Specificity or True Nagative Rate: {0}%\".format(round(mean(model_spec)*100, 4)));\n",
    "print(\"Balanced Accuracy: {0}%\\n\".format(round(mean(model_bal_acc)*100, 4)));\n",
    "print(\"MCC: {0}\\n\".format(round(mean(model_mcc), 4)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
