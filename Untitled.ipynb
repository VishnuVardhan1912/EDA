{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6eb35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore harmless warnings\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d0c09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Num</th>\n",
       "      <th>Agent_Type</th>\n",
       "      <th>Q_Creation_DT</th>\n",
       "      <th>Q_Valid_DT</th>\n",
       "      <th>Policy_Bind_DT</th>\n",
       "      <th>Region</th>\n",
       "      <th>Agent_Num</th>\n",
       "      <th>Policy_Type</th>\n",
       "      <th>HH_Vehicles</th>\n",
       "      <th>HH_Drivers</th>\n",
       "      <th>...</th>\n",
       "      <th>Sal_Range1</th>\n",
       "      <th>Sal_Range2</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Veh_Usage</th>\n",
       "      <th>Annual_Miles_Range</th>\n",
       "      <th>Vehicl_Cost_Range1</th>\n",
       "      <th>Vehicl_Cost_Range2</th>\n",
       "      <th>Re_Quote</th>\n",
       "      <th>Quoted_Premium</th>\n",
       "      <th>Policy_Bind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQ-C-139212</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/04/25</td>\n",
       "      <td>2020/06/23</td>\n",
       "      <td>2020/05/23</td>\n",
       "      <td>C</td>\n",
       "      <td>2156</td>\n",
       "      <td>Car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 25 K &lt;= $ 40 K</td>\n",
       "      <td>&gt;  25 K &lt;=  40 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 55 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>693.86</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQ-F-136117</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2020/04/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>2153</td>\n",
       "      <td>Van</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Balanced</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 7.5 K &amp; &lt;= 15 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>635.96</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ-F-126801</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/06/19</td>\n",
       "      <td>2020/08/17</td>\n",
       "      <td>2020/07/12</td>\n",
       "      <td>F</td>\n",
       "      <td>2056</td>\n",
       "      <td>Truck</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 40 K &lt;= $ 60 K</td>\n",
       "      <td>&gt;  40 K &lt;=  60 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Commute</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&gt; $ 10 K &lt;= $ 20 K</td>\n",
       "      <td>&gt;  10 K &lt;=  20 K</td>\n",
       "      <td>No</td>\n",
       "      <td>780.64</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQ-E-143467</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/05/02</td>\n",
       "      <td>2020/06/30</td>\n",
       "      <td>2020/05/24</td>\n",
       "      <td>E</td>\n",
       "      <td>2138</td>\n",
       "      <td>Car</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>&gt; $ 90 K</td>\n",
       "      <td>&gt;  90 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&lt;= 7.5 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>723.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQ-C-143827</td>\n",
       "      <td>EA</td>\n",
       "      <td>2020/02/12</td>\n",
       "      <td>2020/04/11</td>\n",
       "      <td>2020/02/25</td>\n",
       "      <td>C</td>\n",
       "      <td>2327</td>\n",
       "      <td>Truck</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $ 25 K</td>\n",
       "      <td>&lt;=  25 K</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Pleasure</td>\n",
       "      <td>&gt; 35 K &amp; &lt;= 45 K</td>\n",
       "      <td>&lt;= $ 10 K</td>\n",
       "      <td>&lt;=  10 K</td>\n",
       "      <td>No</td>\n",
       "      <td>738.14</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quote_Num Agent_Type Q_Creation_DT  Q_Valid_DT Policy_Bind_DT Region  \\\n",
       "0  AQ-C-139212         EA    2020/04/25  2020/06/23     2020/05/23      C   \n",
       "1  AQ-F-136117         EA    2020/02/21  2020/04/20            NaN      F   \n",
       "2  AQ-F-126801         EA    2020/06/19  2020/08/17     2020/07/12      F   \n",
       "3  AQ-E-143467         EA    2020/05/02  2020/06/30     2020/05/24      E   \n",
       "4  AQ-C-143827         EA    2020/02/12  2020/04/11     2020/02/25      C   \n",
       "\n",
       "   Agent_Num Policy_Type  HH_Vehicles  HH_Drivers  ...          Sal_Range1  \\\n",
       "0       2156         Car            3           3  ...  > $ 25 K <= $ 40 K   \n",
       "1       2153         Van            2           2  ...  > $ 40 K <= $ 60 K   \n",
       "2       2056       Truck            2           1  ...  > $ 40 K <= $ 60 K   \n",
       "3       2138         Car            1           2  ...           > $ 90 K    \n",
       "4       2327       Truck            3           1  ...           <= $ 25 K   \n",
       "\n",
       "         Sal_Range2  Coverage  Veh_Usage Annual_Miles_Range  \\\n",
       "0  >  25 K <=  40 K  Balanced    Commute             > 55 K   \n",
       "1  >  40 K <=  60 K  Balanced   Pleasure  > 7.5 K & <= 15 K   \n",
       "2  >  40 K <=  60 K     Basic    Commute   > 35 K & <= 45 K   \n",
       "3          >  90 K      Basic   Pleasure           <= 7.5 K   \n",
       "4          <=  25 K     Basic   Pleasure   > 35 K & <= 45 K   \n",
       "\n",
       "   Vehicl_Cost_Range1 Vehicl_Cost_Range2 Re_Quote Quoted_Premium Policy_Bind  \n",
       "0  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         693.86         Yes  \n",
       "1           <= $ 10 K           <=  10 K       No         635.96          No  \n",
       "2  > $ 10 K <= $ 20 K   >  10 K <=  20 K       No         780.64         Yes  \n",
       "3           <= $ 10 K           <=  10 K       No         723.15         Yes  \n",
       "4           <= $ 10 K           <=  10 K       No         738.14         Yes  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Auto Quote Ins data\n",
    "\n",
    "AutoIns = pd.read_csv(r\"D:\\iiit notes\\Internship\\31 season 25th jun-2021\\Auto_Quote_Data_V2.0.csv\", header=0)\n",
    "AutoIns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77bfd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target varaible data type into integer\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('No', '0')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].str.replace('Yes', '1')\n",
    "AutoIns['Policy_Bind'] = AutoIns['Policy_Bind'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfe09c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 113757\n",
      "Class 1: 32502\n",
      "Proportion: 3.5 : 1\n",
      "Total Records: 146259\n"
     ]
    }
   ],
   "source": [
    "# Count the target or dependent variable by '0' & '1' and \n",
    "# their proportion (> 10 : 1, then the dataset is imbalance dataset)\n",
    "\n",
    "Policy_Bind_count = AutoIns.Policy_Bind.value_counts()\n",
    "print('Class 0:', Policy_Bind_count[0])\n",
    "print('Class 1:', Policy_Bind_count[1])\n",
    "print('Proportion:', round(Policy_Bind_count[0] / Policy_Bind_count[1], 2), ': 1')\n",
    "print('Total Records:', len(AutoIns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ced1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and new column as 'QP_Range' from 'Quoted_premium'\n",
    "AutoIns['QP_Range'] = pd.cut(AutoIns['Quoted_Premium'], [0, 800, 1000, 1200, 9999], \n",
    " labels=['0-800', '801-1000', '1001-1200', '>1200'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f893c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the varaibles which are not impacting the target variable\n",
    "\n",
    "AutoIns = AutoIns.drop(['Quote_Num', 'Agent_Num', 'Q_Creation_DT',\n",
    "                        'Q_Valid_DT', 'Policy_Bind_DT', 'Sal_Range1',\n",
    "                        'Vehicl_Cost_Range1', 'Quoted_Premium'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27450f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoIns = pd.get_dummies(AutoIns, columns=['Agent_Type','Region', 'Policy_Type', 'Gender', 'Marital_Status', 'Education',\n",
    "                                          'Sal_Range2', 'Coverage', 'Veh_Usage', 'Annual_Miles_Range', 'Vehicl_Cost_Range2',\n",
    "                                          'Re_Quote', 'QP_Range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7212aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar =[]\n",
    "for col in AutoIns.columns:\n",
    "    if col != 'Policy_Bind':\n",
    "        IndepVar.append(col)\n",
    "        \n",
    "TargetVar = 'Policy_Bind'\n",
    "x = AutoIns[IndepVar]\n",
    "y = AutoIns[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe0ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x, y, test_size = 0.30, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813c6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Each independent variable is in different range. The process of transforming all the\n",
    "# features in the given data set to a fixed range is known as â€˜Scalingâ€™\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "x1_train['Driver_Age'] = sc.fit_transform(x1_train['Driver_Age'].values.reshape(-1, 1))\n",
    "x1_train['Driving_Exp'] = sc.fit_transform(x1_train['Driving_Exp'].values.reshape(-1, 1))\n",
    "x1_test['Driver_Age'] = sc.fit_transform(x1_test['Driver_Age'].values.reshape(-1, 1))\n",
    "x1_test['Driving_Exp'] = sc.fit_transform(x1_test['Driving_Exp'].values.reshape(-1, 1))\n",
    "\n",
    "# convert to dataframe\n",
    "\n",
    "x1_train = pd.DataFrame(x1_train)\n",
    "x1_test = pd.DataFrame(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b557989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "AutoInsRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                     criterion='gini', max_depth=None, max_features='auto',\n",
    "                                     max_leaf_nodes=None, max_samples=None,\n",
    "                                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                     min_samples_leaf=1, min_samples_split=2,\n",
    "                                     min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "                                     n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                     warm_start=False)\n",
    "\n",
    "AutoInsRF = AutoInsRF.fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea9f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = AutoInsRF.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ba4d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34111    16]\n",
      " [ 9749     2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34127\n",
      "           1       0.11      0.00      0.00      9751\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.44      0.50      0.44     43878\n",
      "weighted avg       0.63      0.78      0.68     43878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee8067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.75 %\n",
      "Precision: 77.75 %\n",
      "Recall: 77.75 %\n",
      "f1-score: 77.75 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y1_test, y1_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y1_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y1_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y1_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y1_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dcec7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25307  8820]\n",
      " [ 7275  2476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76     34127\n",
      "           1       0.22      0.25      0.24      9751\n",
      "\n",
      "    accuracy                           0.63     43878\n",
      "   macro avg       0.50      0.50      0.50     43878\n",
      "weighted avg       0.65      0.63      0.64     43878\n",
      "\n",
      "Accuracy: 63.32 %\n",
      "Precision: 21.92 %\n",
      "Recall: 25.39 %\n",
      "f1-score: 23.53 %\n",
      "roc_auc_score: 0.498\n"
     ]
    }
   ],
   "source": [
    "# Build the decision tree model with random sampling \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "AutoInsDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, \n",
    "                                   max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                   min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
    "                                   min_weight_fraction_leaf=0.0, random_state=None, splitter='best') \n",
    "AutoInsDT = AutoInsDT.fit(x1_train,y1_train)\n",
    "\n",
    "# Predict the model with test data set \n",
    "\n",
    "y1_pred = AutoInsDT.predict(x1_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "print(confusion_matrix(y1_test, y1_pred)) \n",
    "print(classification_report(y1_test, y1_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "# Model Accuracy: how often is the classifier correct? \n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y1_test, y1_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such? \n",
    "print(\"Precision:\", (round(metrics.precision_score(y1_test, y1_pred) * 100, 2)), '%') \n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such? \n",
    "print(\"Recall:\", (round(metrics.recall_score(y1_test, y1_pred) * 100, 2)), \"%\") \n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall \n",
    "print(\"f1-score:\", (round(metrics.f1_score(y1_test, y1_pred) * 100, 2)), '%') \n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y1_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b4bd9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34127     0]\n",
      " [ 9751     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87     34127\n",
      "           1       0.00      0.00      0.00      9751\n",
      "\n",
      "    accuracy                           0.78     43878\n",
      "   macro avg       0.39      0.50      0.44     43878\n",
      "weighted avg       0.60      0.78      0.68     43878\n",
      "\n",
      "Accuracy: 77.78 %\n",
      "Precision: 77.78 %\n",
      "Recall: 77.78 %\n",
      "f1-score: 77.78 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "AutoInsLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "intercept_scaling=1, max_iter=100, multi_class='auto',\n",
    "n_jobs=None, penalty='l2', random_state=None,\n",
    "solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "AutoInsLR = AutoInsLR.fit(x1_train,y1_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y1_pred = AutoInsLR.predict(x1_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "print(classification_report(y1_test, y1_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y1_test, y1_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y1_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y1_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y1_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve\n",
    "print('roc_auc_score:', round(roc_auc_score(y1_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a5ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
