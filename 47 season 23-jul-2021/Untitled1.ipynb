{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97569a7e",
   "metadata": {},
   "source": [
    "# Second Problem - Universal Bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b25dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignoring the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a054cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the loans data\n",
    "\n",
    "bankdata = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\46 season 22-jul-2021\\Universalbank.csv\", header=0)\n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e2b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the columns which are not influencing the target variable\n",
    "\n",
    "del bankdata['ID']\n",
    "del bankdata['ZIP Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3a6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'Education']\n"
     ]
    }
   ],
   "source": [
    "# cols1 is variables - crating a dummy variables\n",
    "\n",
    "cols1 = ['Family', 'Education']\n",
    "print(cols1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e650583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n"
     ]
    }
   ],
   "source": [
    "# cols2 variables - MinMaxScalar function\n",
    "\n",
    "cols2 = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n",
    "print(cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a35789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAvg</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mortgage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Securities Account</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD Account</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditCard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0     1     2      3     4\n",
       "Age                 25.0  45.0  39.0   35.0  35.0\n",
       "Experience           1.0  19.0  15.0    9.0   8.0\n",
       "Income              49.0  34.0  11.0  100.0  45.0\n",
       "CCAvg                1.6   1.5   1.0    2.7   1.0\n",
       "Mortgage             0.0   0.0   0.0    0.0   0.0\n",
       "Personal Loan        0.0   0.0   0.0    0.0   0.0\n",
       "Securities Account   1.0   1.0   0.0    0.0   0.0\n",
       "CD Account           0.0   0.0   0.0    0.0   0.0\n",
       "Online               0.0   0.0   0.0    0.0   0.0\n",
       "CreditCard           0.0   0.0   0.0    0.0   1.0\n",
       "Family_1             0.0   0.0   1.0    1.0   0.0\n",
       "Family_2             0.0   0.0   0.0    0.0   0.0\n",
       "Family_3             0.0   1.0   0.0    0.0   0.0\n",
       "Family_4             1.0   0.0   0.0    0.0   1.0\n",
       "Education_1          1.0   1.0   1.0    0.0   0.0\n",
       "Education_2          0.0   0.0   0.0    1.0   1.0\n",
       "Education_3          0.0   0.0   0.0    0.0   0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variable for all range values\n",
    "\n",
    "bankdata = pd.get_dummies(bankdata, columns=cols1)\n",
    "bankdata.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8037c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and Target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in bankdata.columns:\n",
    "    if col != 'CreditCard':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'CreditCard'\n",
    "\n",
    "x = bankdata[IndepVar]\n",
    "y = bankdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32eb31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)\n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9958de13",
   "metadata": {},
   "source": [
    "# SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a46ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1073    0]\n",
      " [ 427    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.83      1073\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.72      1500\n",
      "   macro avg       0.36      0.50      0.42      1500\n",
      "weighted avg       0.51      0.72      0.60      1500\n",
      "\n",
      "Accuracy: 71.53 %\n",
      "Precision: 71.53 %\n",
      "Recall: 71.53 %\n",
      "f1-score: 71.53 %\n",
      "roc_auc_score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Training the SVM algorithm \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = None, class_weight=None,probability=True)\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the values\n",
    "\n",
    "y1_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y1_pred))\n",
    "print(classification_report(y_test,y1_pred))\n",
    "\n",
    "# Evalution metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y1_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y1_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y1_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c514167",
   "metadata": {},
   "source": [
    "# RandomForest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b23651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1054   19]\n",
      " [ 356   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1073\n",
      "           1       0.79      0.17      0.27       427\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.77      0.57      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy: 75.0 %\n",
      "Precision: 75.0 %\n",
      "Recall: 75.0 %\n",
      "f1-score: 75.0 %\n",
      "roc_auc_score: 0.574\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                                 criterion='entropy', max_depth=3, max_features='auto',\n",
    "                                 max_leaf_nodes=None, max_samples=None,\n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                 min_samples_leaf=1, min_samples_split=2,\n",
    "                                 min_weight_fraction_leaf=0.0, n_estimators=300,\n",
    "                                 n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                                 warm_start=False)\n",
    "\n",
    "modelRF = modelRF.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y2_pred = modelRF.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y2_pred))\n",
    "print(classification_report(y_test, y2_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y2_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y2_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y2_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y2_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee690e",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d727867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[786 287]\n",
      " [244 183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75      1073\n",
      "           1       0.39      0.43      0.41       427\n",
      "\n",
      "    accuracy                           0.65      1500\n",
      "   macro avg       0.58      0.58      0.58      1500\n",
      "weighted avg       0.66      0.65      0.65      1500\n",
      "\n",
      "Accuracy: 64.6 %\n",
      "Precision: 38.94 %\n",
      "Recall: 42.86 %\n",
      "f1-score: 40.8 %\n",
      "roc_auc_score: 0.581\n"
     ]
    }
   ],
   "source": [
    "# To build the decision tree model with Over sampling \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "modelDT = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                 max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                 min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0,\n",
    "                                 random_state=None, splitter='best')\n",
    "\n",
    "modelDT = modelDT.fit(x_train,y_train)\n",
    "\n",
    "# Predict with test data\n",
    "\n",
    "y3_pred = modelDT.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y3_pred))\n",
    "print(classification_report(y_test, y3_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y3_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y3_pred) * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y3_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y3_pred) * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63bbba",
   "metadata": {},
   "source": [
    "# Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "666dface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1053   20]\n",
      " [ 356   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1073\n",
      "           1       0.78      0.17      0.27       427\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.76      0.57      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy: 74.93 %\n",
      "Precision: 74.93 %\n",
      "Recall: 74.93 %\n",
      "f1-score: 74.93 %\n",
      "roc_auc_score: 0.574\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Logistic Regression' model with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                             intercept_scaling=1, max_iter=100, multi_class='auto', \n",
    "                             n_jobs=None, penalty='l2', random_state=None,\n",
    "                             solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "modelLR = modelLR.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y4_pred = modelLR.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y4_pred))\n",
    "print(classification_report(y_test, y4_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y4_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y4_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y4_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a6f63",
   "metadata": {},
   "source": [
    "# Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2a9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1053   20]\n",
      " [ 356   71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85      1073\n",
      "           1       0.78      0.17      0.27       427\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.76      0.57      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy: 74.93 %\n",
      "Precision: 74.93 %\n",
      "Recall: 74.93 %\n",
      "f1-score: 74.93 %\n",
      "roc_auc_score: 0.574\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Naive Bayes' model with random sampling\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "modelGNB = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "\n",
    "modelGNB = modelGNB.fit(x_train,y_train)\n",
    "\n",
    "# Predict the model with test data set\n",
    "\n",
    "y5_pred = modelGNB.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y5_pred))\n",
    "print(classification_report(y_test, y5_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y5_pred) * 100, 2)), \"%\")\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y5_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y5_pred, average='micro') * 100, 2)), \"%\")\n",
    "\n",
    "# Model f1-score: weighted average of Precision & Recall\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y5_pred, average='micro') * 100, 2)), '%')\n",
    "\n",
    "# Area under ROC curve \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150676b",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f10479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.07 %\n",
      "Precision: 64.07 %\n",
      "Recall: 64.07 %\n",
      "f1-score: 64.07 %\n",
      "roc_auc_score: 0.5\n",
      "[[887 186]\n",
      " [353  74]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an array that stores the Accuracy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "modelKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "modelKNN.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test data\n",
    "\n",
    "y6_pred = modelKNN.predict(x_test)\n",
    "\n",
    "# Display confusion matrix and classifiction report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y5_pred))\n",
    "print(classification_report(y_test, y5_pred))\n",
    "\n",
    "# Evaluate the model performance by metrics\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y6_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y6_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y6_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y6_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3))\n",
    "print(confusion_matrix(y_test, y6_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c2fd3",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5f1166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1057   16]\n",
      " [ 357   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85      1073\n",
      "           1       0.81      0.16      0.27       427\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.78      0.57      0.56      1500\n",
      "weighted avg       0.77      0.75      0.69      1500\n",
      "\n",
      "Accuracy: 75.13 %\n",
      "Precision: 75.13 %\n",
      "Recall: 75.13 %\n",
      "f1-score: 75.13 %\n",
      "roc_auc_score: 0.575\n"
     ]
    }
   ],
   "source": [
    "# Build the model with Gradient Boosting Classifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "modelGBC = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, \n",
    "                                                                subsample=1.0, criterion='friedman_mse', min_samples_split=2, \n",
    "                                                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, \n",
    "                                                                min_impurity_decrease=0.0, min_impurity_split=None, init=None, \n",
    "                                                                random_state=None, max_features=None, verbose=0, \n",
    "                                                                max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                                                n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "modelGBC.fit(x_train, y_train)\n",
    "\n",
    "# predict the model with test data\n",
    "\n",
    "y7_pred = modelGBC.predict(x_test)\n",
    "\n",
    "# Display the classification report and confusion matrix\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y7_pred))\n",
    "print(classification_report(y_test, y7_pred))\n",
    "\n",
    "# Evaluate the model performance\n",
    "\n",
    "print(\"Accuracy:\", (round(metrics.accuracy_score(y_test, y7_pred) * 100, 2)), \"%\")\n",
    "print(\"Precision:\", (round(metrics.precision_score(y_test, y7_pred, average='micro') * 100, 2)), '%')\n",
    "print(\"Recall:\", (round(metrics.recall_score(y_test, y7_pred, average='micro') * 100, 2)), \"%\")\n",
    "print(\"f1-score:\", (round(metrics.f1_score(y_test, y7_pred, average='micro') * 100, 2)), '%')\n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y7_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70532e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
