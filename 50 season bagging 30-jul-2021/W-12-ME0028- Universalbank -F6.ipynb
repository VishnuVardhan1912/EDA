{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698c6f52",
   "metadata": {},
   "source": [
    "# Universalbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32252935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandasql as psql \n",
    "\n",
    "# Ignore Harmfull warnings\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc234396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Universal Bank dataset\n",
    "\n",
    "bankdata = pd.read_csv(r\"D:\\iiit notes\\Programming\\AI\\Internship practice\\50 season bagging 30-jul-2021\\Universalbank.csv\",header= 0)\n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c629b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Display the information of dataset\n",
    "\n",
    "bankdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6e90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the varaiables which are not impacting the target variable\n",
    "del bankdata['ID']\n",
    "del bankdata['ZIP Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a0a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols is varaiables- creating a dummy variables\n",
    "\n",
    "cols1 = ['Family', 'Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83024eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n"
     ]
    }
   ],
   "source": [
    "# cols2 variable -MinMaxScaler function\n",
    "\n",
    "cols2 = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage']\n",
    "print(cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653919e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAvg</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mortgage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Loan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Securities Account</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD Account</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Online</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditCard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0     1     2      3     4\n",
       "Age                 25.0  45.0  39.0   35.0  35.0\n",
       "Experience           1.0  19.0  15.0    9.0   8.0\n",
       "Income              49.0  34.0  11.0  100.0  45.0\n",
       "CCAvg                1.6   1.5   1.0    2.7   1.0\n",
       "Mortgage             0.0   0.0   0.0    0.0   0.0\n",
       "Personal Loan        0.0   0.0   0.0    0.0   0.0\n",
       "Securities Account   1.0   1.0   0.0    0.0   0.0\n",
       "CD Account           0.0   0.0   0.0    0.0   0.0\n",
       "Online               0.0   0.0   0.0    0.0   0.0\n",
       "CreditCard           0.0   0.0   0.0    0.0   1.0\n",
       "Family_1             0.0   0.0   1.0    1.0   0.0\n",
       "Family_2             0.0   0.0   0.0    0.0   0.0\n",
       "Family_3             0.0   1.0   0.0    0.0   0.0\n",
       "Family_4             1.0   0.0   0.0    0.0   1.0\n",
       "Education_1          1.0   1.0   1.0    0.0   0.0\n",
       "Education_2          0.0   0.0   0.0    1.0   1.0\n",
       "Education_3          0.0   0.0   0.0    0.0   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy variable for all range values\n",
    "\n",
    "bankdata = pd.get_dummies(bankdata, columns=cols1)\n",
    "bankdata.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b95e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the dependent and target variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in bankdata.columns:\n",
    "    if col != 'CreditCard':\n",
    "        IndepVar.append(col)\n",
    "        \n",
    "TargetVar = 'CreditCard'\n",
    "\n",
    "x = bankdata[IndepVar]\n",
    "y = bankdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b85f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42) \n",
    "x_test_F1 = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b73b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "\n",
    "x_train[cols2] = mmscaler.fit_transform(x_train[cols2]) \n",
    "x_train = pd.DataFrame(x_train) \n",
    "\n",
    "x_test[cols2] = mmscaler.fit_transform(x_test[cols2]) \n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a296c9f",
   "metadata": {},
   "source": [
    "# Bagging Classifier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b5c56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[112 315]\n",
      " [117 956]]\n",
      "Outcome values : \n",
      " 112 315 117 956\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.26      0.34       427\n",
      "           0       0.75      0.89      0.82      1073\n",
      "\n",
      "    accuracy                           0.71      1500\n",
      "   macro avg       0.62      0.58      0.58      1500\n",
      "weighted avg       0.68      0.71      0.68      1500\n",
      "\n",
      "Accuracy : 71.2 %\n",
      "Precision : 48.9 %\n",
      "Recall : 26.2 %\n",
      "F1 Score : 0.341\n",
      "Balanced Accuracy : 57.6 %\n",
      "MCC : 0.192\n",
      "roc_auc_score: 0.577\n"
     ]
    }
   ],
   "source": [
    "# Training bagging classifier - BaggingClassifier class of 'sklearn.ensemble' packages to build bagging classifier model. \n",
    "# We set DecisionTreeClassifier class as a base estimator and set 100 to the number of estimators, then train the model \n",
    "# with train data. \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "modelDT = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0) \n",
    "\n",
    "modelBAG = BaggingClassifier(base_estimator=modelDT, n_estimators=100, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "                             bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, \n",
    "                             verbose=0) \n",
    "\n",
    "modelBAG.fit(x_train,y_train) \n",
    "\n",
    "# Predict model with test data \n",
    "y_pred = modelBAG.predict(x_test)\n",
    "\n",
    "# confusion matrix in sklearn \n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "\n",
    "actual = y_test \n",
    "\n",
    "# predicted values\n",
    "\n",
    "predicted = y_pred\n",
    "\n",
    "# confusion matrix \n",
    "matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None) \n",
    "\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# outcome values order in sklearn \n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1) \n",
    "\n",
    "print('Outcome values : \\n', tp, fn, fp, tn) \n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy \n",
    "\n",
    "matrix = classification_report(actual,predicted,labels=[1,0]) \n",
    "print('Classification report : \\n',matrix) \n",
    "\n",
    "# calculating the metrics \n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3) \n",
    "specificity = round(tn/(tn+fp), 3); \n",
    "\n",
    "accuracy = round((tp+tn)/(tp+fp+tn+fn), 3); \n",
    "\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3); \n",
    "\n",
    "precision = round(tp/(tp+fp), 3); f1Score = round((2*tp/(2*tp + fp + fn)), 3); \n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model \n",
    "\n",
    "from math import sqrt \n",
    "\n",
    "x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn) \n",
    "\n",
    "MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3) \n",
    "\n",
    "print('Accuracy :', round(accuracy*100, 2),'%') \n",
    "print('Precision :', round(precision*100, 2),'%') \n",
    "print('Recall :', round(sensitivity*100,2), '%') \n",
    "print('F1 Score :', f1Score) \n",
    "print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%') \n",
    "print('MCC :', MCC) \n",
    "\n",
    "# Area under ROC curve \n",
    "\n",
    "from sklearn.metrics  import roc_curve, roc_auc_score \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y_pred), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004a5ab",
   "metadata": {},
   "source": [
    "# Using Bagging Classifier for All out Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1418f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method:  None\n",
      "Confusion matrix : \n",
      " [[115 312]\n",
      " [119 954]]\n",
      "Outcome values : \n",
      " 115 312 119 954\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.27      0.35       427\n",
      "           0       0.75      0.89      0.82      1073\n",
      "\n",
      "    accuracy                           0.71      1500\n",
      "   macro avg       0.62      0.58      0.58      1500\n",
      "weighted avg       0.68      0.71      0.68      1500\n",
      "\n",
      "Accuracy : 71.3 %\n",
      "Precision : 49.1 %\n",
      "Recall : 26.9 %\n",
      "F1 Score : 0.348\n",
      "Balanced Accuracy : 57.9 %\n",
      "MCC : 0.197\n",
      "roc_auc_score: 0.579\n",
      "-----------------------------------------------------------------------\n",
      "Method:  LogisticRegression()\n",
      "Confusion matrix : \n",
      " [[  71  356]\n",
      " [  17 1056]]\n",
      "Outcome values : \n",
      " 71 356 17 1056\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.17      0.28       427\n",
      "           0       0.75      0.98      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.78      0.58      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy : 75.1 %\n",
      "Precision : 80.7 %\n",
      "Recall : 16.6 %\n",
      "F1 Score : 0.276\n",
      "Balanced Accuracy : 57.5 %\n",
      "MCC : 0.289\n",
      "roc_auc_score: 0.575\n",
      "-----------------------------------------------------------------------\n",
      "Method:  RandomForestClassifier(n_estimators=500, random_state=0)\n",
      "Confusion matrix : \n",
      " [[  93  334]\n",
      " [  56 1017]]\n",
      "Outcome values : \n",
      " 93 334 56 1017\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.22      0.32       427\n",
      "           0       0.75      0.95      0.84      1073\n",
      "\n",
      "    accuracy                           0.74      1500\n",
      "   macro avg       0.69      0.58      0.58      1500\n",
      "weighted avg       0.72      0.74      0.69      1500\n",
      "\n",
      "Accuracy : 74.0 %\n",
      "Precision : 62.4 %\n",
      "Recall : 21.8 %\n",
      "F1 Score : 0.323\n",
      "Balanced Accuracy : 58.3 %\n",
      "MCC : 0.25\n",
      "roc_auc_score: 0.583\n",
      "-----------------------------------------------------------------------\n",
      "Method:  DecisionTreeClassifier(criterion='entropy')\n",
      "Confusion matrix : \n",
      " [[115 312]\n",
      " [108 965]]\n",
      "Outcome values : \n",
      " 115 312 108 965\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.27      0.35       427\n",
      "           0       0.76      0.90      0.82      1073\n",
      "\n",
      "    accuracy                           0.72      1500\n",
      "   macro avg       0.64      0.58      0.59      1500\n",
      "weighted avg       0.69      0.72      0.69      1500\n",
      "\n",
      "Accuracy : 72.0 %\n",
      "Precision : 51.6 %\n",
      "Recall : 26.9 %\n",
      "F1 Score : 0.354\n",
      "Balanced Accuracy : 58.4 %\n",
      "MCC : 0.214\n",
      "roc_auc_score: 0.584\n",
      "-----------------------------------------------------------------------\n",
      "Method:  SVC(probability=True)\n",
      "Confusion matrix : \n",
      " [[  68  359]\n",
      " [  12 1061]]\n",
      "Outcome values : \n",
      " 68 359 12 1061\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.16      0.27       427\n",
      "           0       0.75      0.99      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.80      0.57      0.56      1500\n",
      "weighted avg       0.78      0.75      0.69      1500\n",
      "\n",
      "Accuracy : 75.3 %\n",
      "Precision : 85.0 %\n",
      "Recall : 15.9 %\n",
      "F1 Score : 0.268\n",
      "Balanced Accuracy : 57.4 %\n",
      "MCC : 0.297\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n",
      "Method:  KNeighborsClassifier()\n",
      "Confusion matrix : \n",
      " [[120 307]\n",
      " [148 925]]\n",
      "Outcome values : \n",
      " 120 307 148 925\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.28      0.35       427\n",
      "           0       0.75      0.86      0.80      1073\n",
      "\n",
      "    accuracy                           0.70      1500\n",
      "   macro avg       0.60      0.57      0.57      1500\n",
      "weighted avg       0.66      0.70      0.67      1500\n",
      "\n",
      "Accuracy : 69.7 %\n",
      "Precision : 44.8 %\n",
      "Recall : 28.1 %\n",
      "F1 Score : 0.345\n",
      "Balanced Accuracy : 57.2 %\n",
      "MCC : 0.169\n",
      "roc_auc_score: 0.572\n",
      "-----------------------------------------------------------------------\n",
      "Method:  GradientBoostingClassifier()\n",
      "Confusion matrix : \n",
      " [[  69  358]\n",
      " [  14 1059]]\n",
      "Outcome values : \n",
      " 69 358 14 1059\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.16      0.27       427\n",
      "           0       0.75      0.99      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.79      0.57      0.56      1500\n",
      "weighted avg       0.77      0.75      0.69      1500\n",
      "\n",
      "Accuracy : 75.2 %\n",
      "Precision : 83.1 %\n",
      "Recall : 16.2 %\n",
      "F1 Score : 0.271\n",
      "Balanced Accuracy : 57.4 %\n",
      "MCC : 0.293\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy by changing base estimator - \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "\n",
    "modelLR = LogisticRegression() \n",
    "modelRF = RandomForestClassifier(criterion='gini', n_estimators=500, random_state=0) \n",
    "modelDT = DecisionTreeClassifier(criterion=\"entropy\") \n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = None, class_weight=None,probability=True) \n",
    "modelKNN = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', \n",
    "                                metric_params=None, n_jobs=None) \n",
    "modelXGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                      min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "                                      min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "                                      verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                      n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "base_methods=[None, modelLR, modelRF, modelDT, modelSVMGaussian, modelKNN, modelXGB] \n",
    "for bm in base_methods: \n",
    "    print(\"Method: \", bm) \n",
    "    modelBAG = BaggingClassifier(base_estimator=bm,n_estimators=100,bootstrap=True) \n",
    "    modelBAG.fit(x_train, y_train) \n",
    "    y1_pred = modelBAG.predict(x_test)\n",
    "    \n",
    "    # confusion matrix in sklearn \n",
    "    from sklearn.metrics import confusion_matrix \n",
    "    from sklearn.metrics import classification_report \n",
    "    \n",
    "    # actual values \n",
    "    \n",
    "    actual = y_test \n",
    "    \n",
    "    # predicted values\n",
    "    \n",
    "    predicted = y1_pred \n",
    "    \n",
    "    # confusion matrix\n",
    "    \n",
    "    matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "    print('Confusion matrix : \\n', matrix) \n",
    "    \n",
    "    # outcome values order in sklearn \n",
    "    \n",
    "    tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1) \n",
    "    print('Outcome values : \\n', tp, fn, fp, tn) \n",
    "    # classification report for precision, recall f1-score and accuracy \n",
    "    \n",
    "    matrix = classification_report(actual,predicted,labels=[1,0]) \n",
    "    \n",
    "    print('Classification report : \\n',matrix) \n",
    "    \n",
    "    # calculating the metrics \n",
    "    \n",
    "    sensitivity = round(tp/(tp+fn), 3) \n",
    "    specificity = round(tn/(tn+fp), 3); \n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3); \n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3); \n",
    "    precision = round(tp/(tp+fp), 3); \n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3); \n",
    "    \n",
    "    # Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "    # A model with a score of +1 is a perfect model and -1 is a poor model \n",
    "    \n",
    "    from math import sqrt \n",
    "    \n",
    "    x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn) \n",
    "\n",
    "    MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3) \n",
    "    \n",
    "    print('Accuracy :', round(accuracy*100, 2),'%') \n",
    "    print('Precision :', round(precision*100, 2),'%') \n",
    "    print('Recall :', round(sensitivity*100,2), '%') \n",
    "    print('F1 Score :', f1Score) \n",
    "    print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%') \n",
    "    print('MCC :', MCC) \n",
    "    \n",
    "    # Area under ROC curve \n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print('roc_auc_score:', round(roc_auc_score(y_test, y1_pred), 3)) \n",
    "    print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb7063",
   "metadata": {},
   "source": [
    "# SVM Algorithm - Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef50c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  67  360]\n",
      " [  10 1063]]\n",
      "Outcome values : \n",
      " 67 360 10 1063\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.16      0.27       427\n",
      "           0       0.75      0.99      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.81      0.57      0.56      1500\n",
      "weighted avg       0.78      0.75      0.68      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  15.7 %\n",
      "Precision:  87.0 %\n",
      "f1score:  0.266\n",
      "Balanced Accuracy:  57.4 %\n",
      "MCC:  104.578\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train the SVM algorithm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "modelSVMGaussian = SVC(kernel='rbf', random_state = None, class_weight=None, probability=True)\n",
    "\n",
    "modelSVMGaussian.fit(x_train, y_train)\n",
    "\n",
    "# Predict the values\n",
    "\n",
    "y2_pred = modelSVMGaussian.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y2_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y2_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03d97c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ad850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  71  356]\n",
      " [  17 1056]]\n",
      "Outcome values : \n",
      " 71 356 17 1056\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.17      0.28       427\n",
      "           0       0.75      0.98      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.78      0.58      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  16.6 %\n",
      "Precision:  80.7 %\n",
      "f1score:  0.276\n",
      "Balanced Accuracy:  57.49999999999999 %\n",
      "MCC:  106.305\n",
      "roc_auc_score: 0.575\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the data with Logistic Regression and with random sampling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                             class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
    "                             verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "modelLR.fit(x_train, y_train)\n",
    "\n",
    "# Predice the model with test dataset\n",
    "\n",
    "y3_pred = modelLR.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y3_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y3_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fb60e",
   "metadata": {},
   "source": [
    "# Decision Tree with gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021a5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[173 254]\n",
      " [291 782]]\n",
      "Outcome values : \n",
      " 173 254 291 782\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.41      0.39       427\n",
      "           0       0.75      0.73      0.74      1073\n",
      "\n",
      "    accuracy                           0.64      1500\n",
      "   macro avg       0.56      0.57      0.56      1500\n",
      "weighted avg       0.65      0.64      0.64      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  40.5 %\n",
      "Precision:  37.3 %\n",
      "f1score:  0.388\n",
      "Balanced Accuracy:  56.699999999999996 %\n",
      "MCC:  85.069\n",
      "roc_auc_score: 0.567\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the model and build the 'Decision Tree' Algorithm\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelDTC = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "                                  min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                  min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)\n",
    "# Train the model\n",
    "\n",
    "modelDTC.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model with test dataset\n",
    "\n",
    "y4_pred = modelDTC.predict(x_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y4_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y4_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee5bdd",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ef316ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[112 315]\n",
      " [109 964]]\n",
      "Outcome values : \n",
      " 112 315 109 964\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.26      0.35       427\n",
      "           0       0.75      0.90      0.82      1073\n",
      "\n",
      "    accuracy                           0.72      1500\n",
      "   macro avg       0.63      0.58      0.58      1500\n",
      "weighted avg       0.68      0.72      0.68      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  26.200000000000003 %\n",
      "Precision:  50.7 %\n",
      "f1score:  0.346\n",
      "Balanced Accuracy:  57.99999999999999 %\n",
      "MCC:  109.014\n",
      "roc_auc_score: 0.58\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model and Train the model using the training sets \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "modelRF = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='entropy', max_depth=None, \n",
    "                                 max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, \n",
    "                                 min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, \n",
    "                                 min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, \n",
    "                                 random_state=0, verbose=0, warm_start=False) \n",
    "modelRF = modelRF.fit(x_train, y_train) \n",
    "\n",
    "# Predict the model with test data set \n",
    "\n",
    "y5_pred = modelRF.predict(x_test) \n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y5_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y5_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f5684",
   "metadata": {},
   "source": [
    "# KNN ALgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f260826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[127 300]\n",
      " [161 912]]\n",
      "Outcome values : \n",
      " 127 300 161 912\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.30      0.36       427\n",
      "           0       0.75      0.85      0.80      1073\n",
      "\n",
      "    accuracy                           0.69      1500\n",
      "   macro avg       0.60      0.57      0.58      1500\n",
      "weighted avg       0.66      0.69      0.67      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  29.7 %\n",
      "Precision:  44.1 %\n",
      "f1score:  0.355\n",
      "Balanced Accuracy:  57.4 %\n",
      "MCC:  97.566\n",
      "roc_auc_score: 0.574\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To build the 'KNN' model \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "modelKNN = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', \n",
    "                                metric_params=None, n_jobs=None) \n",
    "modelKNN = modelKNN.fit(x_train, y_train) \n",
    "\n",
    "# Predict the model with test data set \n",
    "y6_pred = modelKNN.predict(x_test) \n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y6_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y6_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0c8207",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9770893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  72  355]\n",
      " [  19 1054]]\n",
      "Outcome values : \n",
      " 72 355 19 1054\n",
      "Classifiction_report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.17      0.28       427\n",
      "           0       0.75      0.98      0.85      1073\n",
      "\n",
      "    accuracy                           0.75      1500\n",
      "   macro avg       0.77      0.58      0.56      1500\n",
      "weighted avg       0.76      0.75      0.69      1500\n",
      "\n",
      "Accuracy:  75.2 %\n",
      "Recall:  16.900000000000002 %\n",
      "Precision:  79.10000000000001 %\n",
      "f1score:  0.278\n",
      "Balanced Accuracy:  57.599999999999994 %\n",
      "MCC:  106.547\n",
      "roc_auc_score: 0.575\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# To build the 'Gradient Boosting' model \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "modelXGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "                                      criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                      min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "                                      min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "                                      verbose=0, max_leaf_nodes=None, warm_start=False, \n",
    "                                      validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0) \n",
    "modelXGB = modelXGB.fit(x_train,y_train) \n",
    "\n",
    "# Predict the model with test data set \n",
    "\n",
    "y7_pred = modelXGB.predict(x_test) \n",
    "\n",
    "# Confusion matrix and classification report\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Actual values\n",
    "\n",
    "Actual = y_test\n",
    "\n",
    "# Predicted Values\n",
    "\n",
    "Predicted = y7_pred\n",
    "\n",
    "# confusion matrix \n",
    "\n",
    "matrix = confusion_matrix(Actual,Predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "print('Confusion matrix : \\n', matrix) \n",
    "\n",
    "# Outcome values in order\n",
    "\n",
    "tp, fn, fp, tn = confusion_matrix(Actual,Predicted,labels=[1,0]).reshape(-1) \n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall, f1-score\n",
    "\n",
    "matrix = classification_report(Actual,Predicted,labels=[1,0]) \n",
    "print('Classifiction_report : \\n', matrix)\n",
    "\n",
    "# Calculate the metrics\n",
    "\n",
    "sensitivity = round(tp/(tp+fn), 3)\n",
    "specificity = round(tn/(tn+fp), 3)\n",
    "accuarcy = round((tp+tn)/(tp+fn+fp+tn), 3)\n",
    "balanced_accuracy = round((sensitivity+specificity)/2, 3)\n",
    "precision =round(tp/(tp+fp), 3)\n",
    "f1score = round((2*tp/(2*tp + fp + fn)), 3)\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "# A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "x = (tp*fn) + (tp*fp) + (tn*fn) + (tn*fp)\n",
    "\n",
    "MCC = round(((tp*tn) - (fp*fn))/sqrt(x), 3)\n",
    "\n",
    "print('Accuracy: ', accuracy*100, '%')\n",
    "print('Recall: ', sensitivity*100, '%')\n",
    "print('Precision: ', precision*100, '%')\n",
    "print('f1score: ', f1score)\n",
    "print('Balanced Accuracy: ', balanced_accuracy*100, '%')\n",
    "print('MCC: ', MCC)\n",
    "\n",
    "# Area under ROC curve \n",
    "    \n",
    "print('roc_auc_score:', round(roc_auc_score(y_test, y7_pred), 3)) \n",
    "print('-----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0511e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0606c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
